{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now loss =  4.642259340952595  accuracy =  0.515625\n",
      "now loss =  0.3865099265390489  accuracy =  0.578125\n",
      "now loss =  0.2484604555247138  accuracy =  0.5\n",
      "now loss =  0.29575697608978624  accuracy =  0.328125\n",
      "now loss =  0.1893005413623505  accuracy =  0.609375\n",
      "now loss =  0.23189932347117662  accuracy =  0.578125\n",
      "now loss =  0.20217222416537894  accuracy =  0.578125\n",
      "now loss =  0.21108512996125114  accuracy =  0.59375\n",
      "now loss =  0.19167221908533827  accuracy =  0.59375\n",
      "now loss =  0.179966105537176  accuracy =  0.640625\n",
      "now loss =  0.17710635048244894  accuracy =  0.625\n",
      "now loss =  0.163467624309098  accuracy =  0.6875\n",
      "now loss =  0.19674254096935326  accuracy =  0.609375\n",
      "now loss =  0.1785076810836867  accuracy =  0.65625\n",
      "now loss =  0.12924733702743074  accuracy =  0.75\n",
      "now loss =  0.19864210965298407  accuracy =  0.6\n",
      "now loss =  0.15454475305833465  accuracy =  0.71875\n",
      "now loss =  0.13652865997496244  accuracy =  0.75\n",
      "now loss =  0.17075315364513124  accuracy =  0.6875\n",
      "now loss =  0.16732509868894274  accuracy =  0.6875\n",
      "now loss =  0.14359389419517127  accuracy =  0.734375\n",
      "now loss =  0.14582341604013282  accuracy =  0.671875\n",
      "now loss =  0.15392675572183773  accuracy =  0.671875\n",
      "now loss =  0.1248847418544109  accuracy =  0.796875\n",
      "now loss =  0.12095088800707246  accuracy =  0.78125\n",
      "now loss =  0.1407305184465441  accuracy =  0.765625\n",
      "now loss =  0.11985669268451968  accuracy =  0.8125\n",
      "now loss =  0.12117676988099531  accuracy =  0.796875\n",
      "now loss =  0.14060130125403755  accuracy =  0.75\n",
      "now loss =  0.13655870666069692  accuracy =  0.71875\n",
      "now loss =  0.0968084572481271  accuracy =  0.859375\n",
      "now loss =  0.1583408295586565  accuracy =  0.7\n",
      "now loss =  0.10922230912690348  accuracy =  0.828125\n",
      "now loss =  0.10456016208911717  accuracy =  0.8125\n",
      "now loss =  0.12848595254845704  accuracy =  0.796875\n",
      "now loss =  0.12050440202750158  accuracy =  0.796875\n",
      "now loss =  0.09190240769114251  accuracy =  0.859375\n",
      "now loss =  0.12850971478275092  accuracy =  0.75\n",
      "now loss =  0.10983090950369478  accuracy =  0.78125\n",
      "now loss =  0.1130990531658695  accuracy =  0.8125\n",
      "now loss =  0.12486708675091884  accuracy =  0.765625\n",
      "now loss =  0.10153953881067088  accuracy =  0.8125\n",
      "now loss =  0.10330733900150181  accuracy =  0.84375\n",
      "now loss =  0.15225471975126353  accuracy =  0.71875\n",
      "now loss =  0.0754826214501523  accuracy =  0.921875\n",
      "now loss =  0.09428537648965829  accuracy =  0.84375\n",
      "now loss =  0.10705873372321152  accuracy =  0.796875\n",
      "now loss =  0.10109362115818628  accuracy =  0.875\n",
      "now loss =  0.08905852370992304  accuracy =  0.875\n",
      "now loss =  0.12484836311722755  accuracy =  0.78125\n",
      "now loss =  0.1115230337534705  accuracy =  0.8125\n",
      "now loss =  0.10727431907184708  accuracy =  0.859375\n",
      "now loss =  0.08975633238382028  accuracy =  0.84375\n",
      "now loss =  0.09320591637623693  accuracy =  0.859375\n",
      "now loss =  0.07897159316830994  accuracy =  0.890625\n",
      "now loss =  0.10155157112389636  accuracy =  0.78125\n",
      "now loss =  0.10026397361493274  accuracy =  0.828125\n",
      "now loss =  0.1054013052131596  accuracy =  0.8125\n",
      "now loss =  0.11798018777905553  accuracy =  0.78125\n",
      "now loss =  0.06889123903039604  accuracy =  0.90625\n",
      "now loss =  0.09698806014165873  accuracy =  0.875\n",
      "now loss =  0.08514656475687916  accuracy =  0.828125\n",
      "now loss =  0.07827350569424699  accuracy =  0.890625\n",
      "now loss =  0.11155320307163748  accuracy =  0.875\n",
      "now loss =  0.06285991081086559  accuracy =  0.890625\n",
      "now loss =  0.09019095057917179  accuracy =  0.84375\n",
      "now loss =  0.06798330660068413  accuracy =  0.90625\n",
      "now loss =  0.07383541232488461  accuracy =  0.890625\n",
      "now loss =  0.0818006933101365  accuracy =  0.84375\n",
      "now loss =  0.09650870572248786  accuracy =  0.859375\n",
      "now loss =  0.08058828542047183  accuracy =  0.875\n",
      "now loss =  0.1080936736700385  accuracy =  0.84375\n",
      "now loss =  0.0939280020907523  accuracy =  0.859375\n",
      "now loss =  0.11051573487421286  accuracy =  0.765625\n",
      "now loss =  0.10389855387456069  accuracy =  0.8125\n",
      "now loss =  0.08419352510167721  accuracy =  0.875\n",
      "now loss =  0.09177855865249461  accuracy =  0.890625\n",
      "now loss =  0.08297892377706698  accuracy =  0.875\n",
      "now loss =  0.10007880554424041  accuracy =  0.84375\n",
      "now loss =  0.13032991481965786  accuracy =  0.825\n",
      "now loss =  0.11885200216975329  accuracy =  0.796875\n",
      "now loss =  0.1043990423714522  accuracy =  0.84375\n",
      "now loss =  0.11321638921497881  accuracy =  0.828125\n",
      "now loss =  0.07105015556439917  accuracy =  0.921875\n",
      "now loss =  0.10135684095634359  accuracy =  0.796875\n",
      "now loss =  0.09146356959560331  accuracy =  0.859375\n",
      "now loss =  0.07764581347457089  accuracy =  0.90625\n",
      "now loss =  0.10197216088294966  accuracy =  0.8125\n",
      "now loss =  0.07254611692222354  accuracy =  0.890625\n",
      "now loss =  0.08763627439751862  accuracy =  0.859375\n",
      "now loss =  0.0655722023240292  accuracy =  0.90625\n",
      "now loss =  0.05907364778525795  accuracy =  0.90625\n",
      "now loss =  0.10508682251899125  accuracy =  0.859375\n",
      "now loss =  0.0749651896453804  accuracy =  0.90625\n",
      "now loss =  0.0808698812861396  accuracy =  0.890625\n",
      "now loss =  0.07919165804043311  accuracy =  0.925\n",
      "now loss =  0.06978522829087755  accuracy =  0.890625\n",
      "now loss =  0.10036175010484365  accuracy =  0.859375\n",
      "now loss =  0.09023748856960426  accuracy =  0.890625\n",
      "now loss =  0.11432915678109337  accuracy =  0.796875\n",
      "now loss =  0.08751094386278929  accuracy =  0.875\n",
      "now loss =  0.08446695888688177  accuracy =  0.859375\n",
      "now loss =  0.08275095826438411  accuracy =  0.890625\n",
      "now loss =  0.11146357598880358  accuracy =  0.84375\n",
      "now loss =  0.07485247378454835  accuracy =  0.90625\n",
      "now loss =  0.11945920220127419  accuracy =  0.796875\n",
      "now loss =  0.07268759998253907  accuracy =  0.9375\n",
      "now loss =  0.07806879342276074  accuracy =  0.890625\n",
      "now loss =  0.07254893829695103  accuracy =  0.90625\n",
      "now loss =  0.06692587665963509  accuracy =  0.90625\n",
      "now loss =  0.09288969249786064  accuracy =  0.859375\n",
      "now loss =  0.08197011370055078  accuracy =  0.9\n",
      "now loss =  0.09334107982933156  accuracy =  0.90625\n",
      "now loss =  0.09631799298831412  accuracy =  0.828125\n",
      "now loss =  0.05932674580793908  accuracy =  0.9375\n",
      "now loss =  0.0804627122152161  accuracy =  0.90625\n",
      "now loss =  0.11693524067078513  accuracy =  0.84375\n",
      "now loss =  0.07734018556679909  accuracy =  0.921875\n",
      "now loss =  0.08996199757377868  accuracy =  0.859375\n",
      "now loss =  0.07585867070726252  accuracy =  0.921875\n",
      "now loss =  0.09360378984381237  accuracy =  0.859375\n",
      "now loss =  0.12577741608109  accuracy =  0.75\n",
      "now loss =  0.08727711843646396  accuracy =  0.90625\n",
      "now loss =  0.06958035957920514  accuracy =  0.890625\n",
      "now loss =  0.08381971798766752  accuracy =  0.890625\n",
      "now loss =  0.07985775771887482  accuracy =  0.859375\n",
      "now loss =  0.06877473483704723  accuracy =  0.90625\n",
      "now loss =  0.07626723078986566  accuracy =  0.875\n",
      "now loss =  0.10157675899706042  accuracy =  0.875\n",
      "now loss =  0.0929262706140664  accuracy =  0.859375\n",
      "now loss =  0.08810977064152883  accuracy =  0.890625\n",
      "now loss =  0.08308675979904975  accuracy =  0.859375\n",
      "now loss =  0.063816410395719  accuracy =  0.890625\n",
      "now loss =  0.10740046999198198  accuracy =  0.859375\n",
      "now loss =  0.07952300273630888  accuracy =  0.890625\n",
      "now loss =  0.06084559096456734  accuracy =  0.9375\n",
      "now loss =  0.11047517030266563  accuracy =  0.8125\n",
      "now loss =  0.07496563653981683  accuracy =  0.9375\n",
      "now loss =  0.09929737444865108  accuracy =  0.84375\n",
      "now loss =  0.09042443031413348  accuracy =  0.859375\n",
      "now loss =  0.06356213141458886  accuracy =  0.953125\n",
      "now loss =  0.08564730708128636  accuracy =  0.859375\n",
      "now loss =  0.09886899930843412  accuracy =  0.859375\n",
      "now loss =  0.07551223048798628  accuracy =  0.9\n",
      "now loss =  0.08389233210659588  accuracy =  0.84375\n",
      "now loss =  0.08552006914834623  accuracy =  0.90625\n",
      "now loss =  0.06197766865627012  accuracy =  0.9375\n",
      "now loss =  0.09075727915432151  accuracy =  0.90625\n",
      "now loss =  0.08106216774005495  accuracy =  0.890625\n",
      "now loss =  0.13055236644721774  accuracy =  0.765625\n",
      "now loss =  0.11650040511826079  accuracy =  0.859375\n",
      "now loss =  0.10770299393986418  accuracy =  0.84375\n",
      "now loss =  0.0801341909681777  accuracy =  0.890625\n",
      "now loss =  0.10292993711253655  accuracy =  0.84375\n",
      "now loss =  0.05427768967485979  accuracy =  0.953125\n",
      "now loss =  0.07270027361004089  accuracy =  0.921875\n",
      "now loss =  0.08384366998788731  accuracy =  0.875\n",
      "now loss =  0.049876020570560106  accuracy =  0.96875\n",
      "now loss =  0.09552148900243873  accuracy =  0.84375\n",
      "now loss =  0.09337895448445972  accuracy =  0.85\n",
      "now loss =  0.0634008345597121  accuracy =  0.9375\n",
      "now loss =  0.08335677601296804  accuracy =  0.875\n",
      "now loss =  0.07973776901355527  accuracy =  0.859375\n",
      "now loss =  0.0729818210785487  accuracy =  0.890625\n",
      "now loss =  0.10343803222562842  accuracy =  0.84375\n",
      "now loss =  0.09502476625099796  accuracy =  0.890625\n",
      "now loss =  0.09724165966003734  accuracy =  0.875\n",
      "now loss =  0.07710616114127189  accuracy =  0.921875\n",
      "now loss =  0.08320466628526951  accuracy =  0.921875\n",
      "now loss =  0.08042202605308107  accuracy =  0.921875\n",
      "now loss =  0.09036244213229788  accuracy =  0.875\n",
      "now loss =  0.08904486206260478  accuracy =  0.90625\n",
      "now loss =  0.0989315828722839  accuracy =  0.859375\n",
      "now loss =  0.09273757609585377  accuracy =  0.859375\n",
      "now loss =  0.08527965940101556  accuracy =  0.84375\n",
      "now loss =  0.07502172594824497  accuracy =  0.9\n",
      "now loss =  0.059737277875316006  accuracy =  0.953125\n",
      "now loss =  0.0812525789985856  accuracy =  0.90625\n",
      "now loss =  0.1041479349913709  accuracy =  0.84375\n",
      "now loss =  0.0650921996893815  accuracy =  0.9375\n",
      "now loss =  0.1129135805637679  accuracy =  0.828125\n",
      "now loss =  0.07401771386535533  accuracy =  0.90625\n",
      "now loss =  0.0889966823234109  accuracy =  0.890625\n",
      "now loss =  0.07857821531695164  accuracy =  0.921875\n",
      "now loss =  0.08834936159659038  accuracy =  0.859375\n",
      "now loss =  0.07930160484927018  accuracy =  0.90625\n",
      "now loss =  0.09992504768155441  accuracy =  0.828125\n",
      "now loss =  0.07936875531018375  accuracy =  0.859375\n",
      "now loss =  0.0945287066892973  accuracy =  0.859375\n",
      "now loss =  0.08328157203291275  accuracy =  0.890625\n",
      "now loss =  0.0975588555858732  accuracy =  0.84375\n",
      "now loss =  0.09299426112833946  accuracy =  0.9\n",
      "now loss =  0.08504694238302839  accuracy =  0.890625\n",
      "now loss =  0.0654944291032705  accuracy =  0.921875\n",
      "now loss =  0.06743315518658174  accuracy =  0.953125\n",
      "now loss =  0.09064435411054543  accuracy =  0.875\n",
      "now loss =  0.12221339081388419  accuracy =  0.859375\n",
      "now loss =  0.08951271733978404  accuracy =  0.859375\n",
      "now loss =  0.09125362345163941  accuracy =  0.875\n",
      "now loss =  0.10245259419208466  accuracy =  0.828125\n",
      "now loss =  0.05821992447860533  accuracy =  0.953125\n",
      "now loss =  0.08262469391598506  accuracy =  0.90625\n",
      "now loss =  0.07075019375184896  accuracy =  0.875\n",
      "now loss =  0.08447426856728021  accuracy =  0.90625\n",
      "now loss =  0.0978634077615851  accuracy =  0.859375\n",
      "now loss =  0.09270610467920035  accuracy =  0.875\n",
      "now loss =  0.07790129324250947  accuracy =  0.921875\n",
      "now loss =  0.09694858577120899  accuracy =  0.85\n",
      "now loss =  0.07108132944492085  accuracy =  0.921875\n",
      "now loss =  0.09525661480967065  accuracy =  0.875\n",
      "now loss =  0.054601189914206136  accuracy =  0.921875\n",
      "now loss =  0.07250850717503901  accuracy =  0.9375\n",
      "now loss =  0.08989031271718828  accuracy =  0.890625\n",
      "now loss =  0.06990492957848644  accuracy =  0.890625\n",
      "now loss =  0.08760902383319374  accuracy =  0.875\n",
      "now loss =  0.06197494283179386  accuracy =  0.921875\n",
      "now loss =  0.11225372314549067  accuracy =  0.84375\n",
      "now loss =  0.08209835216982679  accuracy =  0.859375\n",
      "now loss =  0.1187765858035626  accuracy =  0.8125\n",
      "now loss =  0.11784011229897963  accuracy =  0.828125\n",
      "now loss =  0.09638554784314333  accuracy =  0.859375\n",
      "now loss =  0.10131722148059649  accuracy =  0.828125\n",
      "now loss =  0.06808445198824631  accuracy =  0.9375\n",
      "now loss =  0.07493589956016315  accuracy =  0.95\n",
      "now loss =  0.11171240219500307  accuracy =  0.8125\n",
      "now loss =  0.11052897849498008  accuracy =  0.84375\n",
      "now loss =  0.06892441969168608  accuracy =  0.90625\n",
      "now loss =  0.07392879387376185  accuracy =  0.90625\n",
      "now loss =  0.06448352134980657  accuracy =  0.921875\n",
      "now loss =  0.07115758014076451  accuracy =  0.953125\n",
      "now loss =  0.0972989395032679  accuracy =  0.84375\n",
      "now loss =  0.07210771323083402  accuracy =  0.921875\n",
      "now loss =  0.09301294543602945  accuracy =  0.890625\n",
      "now loss =  0.07941159195581785  accuracy =  0.890625\n",
      "now loss =  0.06698579881844265  accuracy =  0.90625\n",
      "now loss =  0.10225378366719667  accuracy =  0.84375\n",
      "now loss =  0.07603898316186544  accuracy =  0.90625\n",
      "now loss =  0.11919637328675309  accuracy =  0.8125\n",
      "now loss =  0.08601630629461907  accuracy =  0.890625\n",
      "now loss =  0.0831797404473049  accuracy =  0.9\n",
      "now loss =  0.0922618154417836  accuracy =  0.890625\n",
      "now loss =  0.0755758426548294  accuracy =  0.921875\n",
      "now loss =  0.07807144658263769  accuracy =  0.875\n",
      "now loss =  0.08602359049623981  accuracy =  0.859375\n",
      "now loss =  0.06799893499692483  accuracy =  0.921875\n",
      "now loss =  0.10748428821992582  accuracy =  0.828125\n",
      "now loss =  0.08259154930224351  accuracy =  0.875\n",
      "now loss =  0.06942925888724105  accuracy =  0.9375\n",
      "now loss =  0.0787590889328467  accuracy =  0.90625\n",
      "now loss =  0.08175602818972175  accuracy =  0.90625\n",
      "now loss =  0.07331339054735596  accuracy =  0.90625\n",
      "now loss =  0.09544983970853077  accuracy =  0.8125\n",
      "now loss =  0.11093336291372038  accuracy =  0.828125\n",
      "now loss =  0.09208180994874399  accuracy =  0.90625\n",
      "now loss =  0.09671301254337047  accuracy =  0.859375\n",
      "now loss =  0.08710139494494572  accuracy =  0.9\n",
      "now loss =  0.05899239042417694  accuracy =  0.921875\n",
      "now loss =  0.08315226886235699  accuracy =  0.859375\n",
      "now loss =  0.06994176806638705  accuracy =  0.90625\n",
      "now loss =  0.06807011394292936  accuracy =  0.953125\n",
      "now loss =  0.11877437691790907  accuracy =  0.78125\n",
      "now loss =  0.08570053229772177  accuracy =  0.859375\n",
      "now loss =  0.076785064034945  accuracy =  0.890625\n",
      "now loss =  0.07634219678984756  accuracy =  0.90625\n",
      "now loss =  0.0704894887976088  accuracy =  0.90625\n",
      "now loss =  0.10362387813519285  accuracy =  0.875\n",
      "now loss =  0.10521312401330077  accuracy =  0.8125\n",
      "now loss =  0.08732165566331299  accuracy =  0.890625\n",
      "now loss =  0.10048147345813074  accuracy =  0.84375\n",
      "now loss =  0.08138312888126906  accuracy =  0.9375\n",
      "now loss =  0.093971301921773  accuracy =  0.875\n",
      "now loss =  0.10424100012938511  accuracy =  0.825\n",
      "now loss =  0.07528747241648164  accuracy =  0.875\n",
      "now loss =  0.075870195321904  accuracy =  0.9375\n",
      "now loss =  0.07945106802004152  accuracy =  0.890625\n",
      "now loss =  0.09173816844573096  accuracy =  0.859375\n",
      "now loss =  0.06414302086273727  accuracy =  0.953125\n",
      "now loss =  0.05783225267085842  accuracy =  0.921875\n",
      "now loss =  0.08026454873856469  accuracy =  0.90625\n",
      "now loss =  0.0918240282653397  accuracy =  0.875\n",
      "now loss =  0.0870817062456002  accuracy =  0.890625\n",
      "now loss =  0.07448768337622641  accuracy =  0.90625\n",
      "now loss =  0.06450805015523717  accuracy =  0.921875\n",
      "now loss =  0.09049538798601098  accuracy =  0.890625\n",
      "now loss =  0.14286158148251155  accuracy =  0.75\n",
      "now loss =  0.10926719868910995  accuracy =  0.875\n",
      "now loss =  0.0749078228216854  accuracy =  0.90625\n",
      "now loss =  0.1322407023862971  accuracy =  0.775\n",
      "now loss =  0.07200871515277406  accuracy =  0.9375\n",
      "now loss =  0.10329331607245625  accuracy =  0.859375\n",
      "now loss =  0.06030514421075107  accuracy =  0.96875\n",
      "now loss =  0.09645521891109887  accuracy =  0.859375\n",
      "now loss =  0.09595220772103404  accuracy =  0.859375\n",
      "now loss =  0.09537097751903406  accuracy =  0.84375\n",
      "now loss =  0.07892040923816068  accuracy =  0.890625\n",
      "now loss =  0.07106431794655221  accuracy =  0.9375\n",
      "now loss =  0.11422541417717735  accuracy =  0.8125\n",
      "now loss =  0.11175686066180551  accuracy =  0.8125\n",
      "now loss =  0.09524392472631339  accuracy =  0.859375\n",
      "now loss =  0.0799096281872208  accuracy =  0.890625\n",
      "now loss =  0.07077599487812147  accuracy =  0.9375\n",
      "now loss =  0.07875143478389897  accuracy =  0.890625\n",
      "now loss =  0.08965264663658046  accuracy =  0.890625\n",
      "now loss =  0.04514387432782862  accuracy =  0.975\n",
      "now loss =  0.07926809301486652  accuracy =  0.890625\n",
      "now loss =  0.09738737576266207  accuracy =  0.875\n",
      "now loss =  0.08905231791491923  accuracy =  0.875\n",
      "now loss =  0.0613928006907328  accuracy =  0.953125\n",
      "now loss =  0.08238353434172277  accuracy =  0.875\n",
      "now loss =  0.09433171372305478  accuracy =  0.859375\n",
      "now loss =  0.07109839339602445  accuracy =  0.921875\n",
      "now loss =  0.11948078258527935  accuracy =  0.8125\n",
      "now loss =  0.08814943479417629  accuracy =  0.859375\n",
      "now loss =  0.07860408685727546  accuracy =  0.890625\n",
      "now loss =  0.10631771827171264  accuracy =  0.875\n",
      "now loss =  0.09804977547771905  accuracy =  0.84375\n",
      "now loss =  0.10418226629701818  accuracy =  0.828125\n",
      "now loss =  0.06335968265099123  accuracy =  0.953125\n",
      "now loss =  0.06797683481952639  accuracy =  0.9375\n",
      "now loss =  0.06283572516424166  accuracy =  0.9\n",
      "now loss =  0.07592318480463686  accuracy =  0.890625\n",
      "now loss =  0.08582922266066573  accuracy =  0.890625\n",
      "now loss =  0.07980207378374286  accuracy =  0.921875\n",
      "now loss =  0.09981841341285558  accuracy =  0.875\n",
      "now loss =  0.0865177175762039  accuracy =  0.875\n",
      "now loss =  0.07952329649593637  accuracy =  0.890625\n",
      "now loss =  0.11677478218831268  accuracy =  0.828125\n",
      "now loss =  0.08469268811825445  accuracy =  0.921875\n",
      "now loss =  0.05573776139565729  accuracy =  0.9375\n",
      "now loss =  0.08450236916671588  accuracy =  0.890625\n",
      "now loss =  0.11549182392502996  accuracy =  0.765625\n",
      "now loss =  0.06390750304635509  accuracy =  0.921875\n",
      "now loss =  0.061721257413262204  accuracy =  0.9375\n",
      "now loss =  0.08312812873541764  accuracy =  0.90625\n",
      "now loss =  0.10389427269570155  accuracy =  0.84375\n",
      "now loss =  0.10601790805852947  accuracy =  0.85\n",
      "now loss =  0.08626371284313794  accuracy =  0.875\n",
      "now loss =  0.07272745001457298  accuracy =  0.90625\n",
      "now loss =  0.05587150958800156  accuracy =  0.90625\n",
      "now loss =  0.07405386314864976  accuracy =  0.921875\n",
      "now loss =  0.10314531041550956  accuracy =  0.859375\n",
      "now loss =  0.09052134202076173  accuracy =  0.890625\n",
      "now loss =  0.10059248933772139  accuracy =  0.859375\n",
      "now loss =  0.09353950293553903  accuracy =  0.875\n",
      "now loss =  0.07090426059523722  accuracy =  0.921875\n",
      "now loss =  0.09254920231223909  accuracy =  0.875\n",
      "now loss =  0.13133511127783654  accuracy =  0.8125\n",
      "now loss =  0.08945383468590523  accuracy =  0.875\n",
      "now loss =  0.06870157406455984  accuracy =  0.921875\n",
      "now loss =  0.0738163639371358  accuracy =  0.90625\n",
      "now loss =  0.08715886401337372  accuracy =  0.90625\n",
      "now loss =  0.09065735714314561  accuracy =  0.9\n",
      "now loss =  0.09818777390417693  accuracy =  0.84375\n",
      "now loss =  0.11391500999088737  accuracy =  0.859375\n",
      "now loss =  0.07537693193688338  accuracy =  0.921875\n",
      "now loss =  0.08779524766696271  accuracy =  0.890625\n",
      "now loss =  0.06871468664611874  accuracy =  0.921875\n",
      "now loss =  0.10160909541826432  accuracy =  0.875\n",
      "now loss =  0.08414705486640815  accuracy =  0.890625\n",
      "now loss =  0.09279856791707669  accuracy =  0.84375\n",
      "now loss =  0.09426364295872884  accuracy =  0.890625\n",
      "now loss =  0.08160836942203102  accuracy =  0.90625\n",
      "now loss =  0.06497931508132186  accuracy =  0.875\n",
      "now loss =  0.09656406512740336  accuracy =  0.875\n",
      "now loss =  0.07283474830673548  accuracy =  0.875\n",
      "now loss =  0.07224195857280503  accuracy =  0.890625\n",
      "now loss =  0.09321640779300752  accuracy =  0.84375\n",
      "now loss =  0.06522949200968926  accuracy =  0.95\n",
      "now loss =  0.08541117618887602  accuracy =  0.859375\n",
      "now loss =  0.06725920767562227  accuracy =  0.90625\n",
      "now loss =  0.06202850309805251  accuracy =  0.921875\n",
      "now loss =  0.13275301467521947  accuracy =  0.796875\n",
      "now loss =  0.059933078073123106  accuracy =  0.96875\n",
      "now loss =  0.10619255524981107  accuracy =  0.859375\n",
      "now loss =  0.11201743763848047  accuracy =  0.84375\n",
      "now loss =  0.06841127289471155  accuracy =  0.921875\n",
      "now loss =  0.11473104163717426  accuracy =  0.84375\n",
      "now loss =  0.06071685054092496  accuracy =  0.921875\n",
      "now loss =  0.07116874921085906  accuracy =  0.90625\n",
      "now loss =  0.09708098078244086  accuracy =  0.859375\n",
      "now loss =  0.08274422694346817  accuracy =  0.875\n",
      "now loss =  0.10531170161323775  accuracy =  0.859375\n",
      "now loss =  0.06391024855437939  accuracy =  0.921875\n",
      "now loss =  0.07730194435747892  accuracy =  0.85\n",
      "now loss =  0.1013598750993975  accuracy =  0.828125\n",
      "now loss =  0.091073856489438  accuracy =  0.84375\n",
      "now loss =  0.0963922419025607  accuracy =  0.859375\n",
      "now loss =  0.09929254557997277  accuracy =  0.828125\n",
      "now loss =  0.07365385434438315  accuracy =  0.9375\n",
      "now loss =  0.09460352362963446  accuracy =  0.859375\n",
      "now loss =  0.08152157455649404  accuracy =  0.890625\n",
      "now loss =  0.09728000872030909  accuracy =  0.890625\n",
      "now loss =  0.0898746459301554  accuracy =  0.84375\n",
      "now loss =  0.0967153850047203  accuracy =  0.859375\n",
      "now loss =  0.06234859892692099  accuracy =  0.9375\n",
      "now loss =  0.0760370620581598  accuracy =  0.90625\n",
      "now loss =  0.08086195741759108  accuracy =  0.890625\n",
      "now loss =  0.07138356650570865  accuracy =  0.9375\n",
      "now loss =  0.07788036117846903  accuracy =  0.90625\n",
      "now loss =  0.0808385932869258  accuracy =  0.9\n",
      "now loss =  0.0646962328989748  accuracy =  0.921875\n",
      "now loss =  0.08882113498062744  accuracy =  0.90625\n",
      "now loss =  0.10740566463297871  accuracy =  0.84375\n",
      "now loss =  0.08425585919284617  accuracy =  0.921875\n",
      "now loss =  0.0574770945919444  accuracy =  0.96875\n",
      "now loss =  0.10346143553882739  accuracy =  0.828125\n",
      "now loss =  0.10765768366962736  accuracy =  0.890625\n",
      "now loss =  0.09804788139058665  accuracy =  0.8125\n",
      "now loss =  0.09025789064392131  accuracy =  0.828125\n",
      "now loss =  0.09338616336909047  accuracy =  0.875\n",
      "now loss =  0.05032734420501135  accuracy =  0.953125\n",
      "now loss =  0.06816310992683926  accuracy =  0.921875\n",
      "now loss =  0.09120151471204138  accuracy =  0.859375\n",
      "now loss =  0.1008095630103205  accuracy =  0.859375\n",
      "now loss =  0.07075943538930113  accuracy =  0.90625\n",
      "now loss =  0.11561473018792086  accuracy =  0.8\n",
      "now loss =  0.07248328459004029  accuracy =  0.9375\n",
      "now loss =  0.07172515913958065  accuracy =  0.9375\n",
      "now loss =  0.08365864498314032  accuracy =  0.890625\n",
      "now loss =  0.05720440239154134  accuracy =  0.921875\n",
      "now loss =  0.10657702884747339  accuracy =  0.890625\n",
      "now loss =  0.08148150566840923  accuracy =  0.890625\n",
      "now loss =  0.08262110983189944  accuracy =  0.921875\n",
      "now loss =  0.08930027852795362  accuracy =  0.875\n",
      "now loss =  0.11091516356390484  accuracy =  0.796875\n",
      "now loss =  0.05553544472483519  accuracy =  0.9375\n",
      "now loss =  0.08808754553791057  accuracy =  0.859375\n",
      "now loss =  0.07818430452033356  accuracy =  0.90625\n",
      "now loss =  0.09363105651045613  accuracy =  0.890625\n",
      "now loss =  0.10229507372337657  accuracy =  0.84375\n",
      "now loss =  0.09409247190294757  accuracy =  0.875\n",
      "now loss =  0.11189111257620885  accuracy =  0.775\n",
      "now loss =  0.09709775809834867  accuracy =  0.890625\n",
      "now loss =  0.06518022855082176  accuracy =  0.9375\n",
      "now loss =  0.09865732896999818  accuracy =  0.890625\n",
      "now loss =  0.07136735493744795  accuracy =  0.90625\n",
      "now loss =  0.08580881764074592  accuracy =  0.875\n",
      "now loss =  0.08437359363588472  accuracy =  0.875\n",
      "now loss =  0.08139231208581452  accuracy =  0.890625\n",
      "now loss =  0.11099810062397612  accuracy =  0.828125\n",
      "now loss =  0.08040393872167192  accuracy =  0.875\n",
      "now loss =  0.06540663139586224  accuracy =  0.921875\n",
      "now loss =  0.10025786081559418  accuracy =  0.84375\n",
      "now loss =  0.09242056349530639  accuracy =  0.875\n",
      "now loss =  0.06801025516955005  accuracy =  0.921875\n",
      "now loss =  0.1037900456740884  accuracy =  0.84375\n",
      "now loss =  0.07556345346667459  accuracy =  0.90625\n",
      "now loss =  0.10756998078207827  accuracy =  0.85\n",
      "now loss =  0.09614804536307113  accuracy =  0.859375\n",
      "now loss =  0.1001181084767178  accuracy =  0.84375\n",
      "now loss =  0.06133537700333768  accuracy =  0.921875\n",
      "now loss =  0.09026939365717171  accuracy =  0.875\n",
      "now loss =  0.10245890338657013  accuracy =  0.859375\n",
      "now loss =  0.061832296230017555  accuracy =  0.9375\n",
      "now loss =  0.09975684052469364  accuracy =  0.828125\n",
      "now loss =  0.07387140946963594  accuracy =  0.875\n",
      "now loss =  0.06674725007219046  accuracy =  0.953125\n",
      "now loss =  0.11247551553032162  accuracy =  0.796875\n",
      "now loss =  0.09818655224617315  accuracy =  0.859375\n",
      "now loss =  0.08333313310493323  accuracy =  0.890625\n",
      "now loss =  0.08441711034337951  accuracy =  0.890625\n",
      "now loss =  0.049908813498995994  accuracy =  0.96875\n",
      "now loss =  0.08208770723483427  accuracy =  0.875\n",
      "now loss =  0.12872405164681336  accuracy =  0.825\n",
      "now loss =  0.08112186583238679  accuracy =  0.859375\n",
      "now loss =  0.09016836063389905  accuracy =  0.84375\n",
      "now loss =  0.08563063420264722  accuracy =  0.90625\n",
      "now loss =  0.06384568118128739  accuracy =  0.953125\n",
      "now loss =  0.13017813924967464  accuracy =  0.78125\n",
      "now loss =  0.08151224983325503  accuracy =  0.90625\n",
      "now loss =  0.08717676244483394  accuracy =  0.859375\n",
      "now loss =  0.06288219452423052  accuracy =  0.9375\n",
      "now loss =  0.08878830635732812  accuracy =  0.921875\n",
      "now loss =  0.08863612371417665  accuracy =  0.859375\n",
      "now loss =  0.11345926872128549  accuracy =  0.8125\n",
      "now loss =  0.0895073713755425  accuracy =  0.875\n",
      "now loss =  0.07366932483188388  accuracy =  0.921875\n",
      "now loss =  0.09112686683885193  accuracy =  0.90625\n",
      "now loss =  0.06447286834337748  accuracy =  0.921875\n",
      "now loss =  0.10024970191122924  accuracy =  0.85\n",
      "now loss =  0.06602129639498885  accuracy =  0.921875\n",
      "now loss =  0.08434601099579056  accuracy =  0.90625\n",
      "now loss =  0.06610060782818847  accuracy =  0.875\n",
      "now loss =  0.0916600727125174  accuracy =  0.875\n",
      "now loss =  0.11798282567734875  accuracy =  0.84375\n",
      "now loss =  0.08796051565401622  accuracy =  0.84375\n",
      "now loss =  0.07722309846015711  accuracy =  0.9375\n",
      "now loss =  0.08891282780138804  accuracy =  0.875\n",
      "now loss =  0.07313832380481862  accuracy =  0.9375\n",
      "now loss =  0.06516573260864708  accuracy =  0.9375\n",
      "now loss =  0.08330238799333209  accuracy =  0.890625\n",
      "now loss =  0.1074307739864707  accuracy =  0.84375\n",
      "now loss =  0.0708049259650195  accuracy =  0.890625\n",
      "now loss =  0.1187401815117399  accuracy =  0.828125\n",
      "now loss =  0.09122253531048352  accuracy =  0.828125\n",
      "now loss =  0.09418058641663922  accuracy =  0.875\n",
      "now loss =  0.08269911476033026  accuracy =  0.875\n",
      "now loss =  0.09028411162397383  accuracy =  0.859375\n",
      "now loss =  0.07227670497954643  accuracy =  0.921875\n",
      "now loss =  0.08291117307047112  accuracy =  0.921875\n",
      "now loss =  0.11600165959713864  accuracy =  0.8125\n",
      "now loss =  0.086182823884171  accuracy =  0.890625\n",
      "now loss =  0.06935978535338529  accuracy =  0.9375\n",
      "now loss =  0.10448362854640456  accuracy =  0.828125\n",
      "now loss =  0.12080864861148582  accuracy =  0.78125\n",
      "now loss =  0.0807492889398505  accuracy =  0.875\n",
      "now loss =  0.09214445449222392  accuracy =  0.90625\n",
      "now loss =  0.07458740315797557  accuracy =  0.90625\n",
      "now loss =  0.08438410715759406  accuracy =  0.890625\n",
      "now loss =  0.062102867442646766  accuracy =  0.921875\n",
      "now loss =  0.08991281299341147  accuracy =  0.890625\n",
      "now loss =  0.05238648791518803  accuracy =  0.975\n",
      "now loss =  0.08257013306508065  accuracy =  0.890625\n",
      "now loss =  0.05973350783375948  accuracy =  0.953125\n",
      "now loss =  0.0724903478198674  accuracy =  0.890625\n",
      "now loss =  0.06659749638837523  accuracy =  0.921875\n",
      "now loss =  0.08528322715524878  accuracy =  0.859375\n",
      "now loss =  0.10174559206701089  accuracy =  0.828125\n",
      "now loss =  0.076633925921516  accuracy =  0.9375\n",
      "now loss =  0.11523953301088559  accuracy =  0.828125\n",
      "now loss =  0.09599782273141928  accuracy =  0.84375\n",
      "now loss =  0.07031879142458439  accuracy =  0.921875\n",
      "now loss =  0.04609938308913023  accuracy =  0.96875\n",
      "now loss =  0.12284893472534571  accuracy =  0.828125\n",
      "now loss =  0.12393077387047234  accuracy =  0.78125\n",
      "now loss =  0.09091379750233235  accuracy =  0.859375\n",
      "now loss =  0.09596521704297137  accuracy =  0.90625\n",
      "now loss =  0.05612497981421351  accuracy =  0.975\n",
      "now loss =  0.08782661534736241  accuracy =  0.875\n",
      "now loss =  0.06524470964948527  accuracy =  0.921875\n",
      "now loss =  0.09862482389799765  accuracy =  0.859375\n",
      "now loss =  0.07773394671584956  accuracy =  0.90625\n",
      "now loss =  0.07108925042940897  accuracy =  0.921875\n",
      "now loss =  0.07909390164898035  accuracy =  0.890625\n",
      "now loss =  0.098581724787879  accuracy =  0.84375\n",
      "now loss =  0.0833832867755212  accuracy =  0.890625\n",
      "now loss =  0.08181490281454906  accuracy =  0.890625\n",
      "now loss =  0.12052967583110716  accuracy =  0.8125\n",
      "now loss =  0.07521753851344942  accuracy =  0.90625\n",
      "now loss =  0.0909193559139762  accuracy =  0.859375\n",
      "now loss =  0.0912003632325751  accuracy =  0.90625\n",
      "now loss =  0.11151972030910709  accuracy =  0.859375\n",
      "now loss =  0.0499170307937597  accuracy =  0.921875\n",
      "now loss =  0.09384784642969404  accuracy =  0.85\n",
      "now loss =  0.10718602762325552  accuracy =  0.84375\n",
      "now loss =  0.11431780565024599  accuracy =  0.828125\n",
      "now loss =  0.10044188972608528  accuracy =  0.890625\n",
      "now loss =  0.08680741120255411  accuracy =  0.890625\n",
      "now loss =  0.08401560272759276  accuracy =  0.890625\n",
      "now loss =  0.06430365683959283  accuracy =  0.90625\n",
      "now loss =  0.11156838376676687  accuracy =  0.828125\n",
      "now loss =  0.06739311971982771  accuracy =  0.9375\n",
      "now loss =  0.07035806488699656  accuracy =  0.921875\n",
      "now loss =  0.0900648060746796  accuracy =  0.828125\n",
      "now loss =  0.06563012799601625  accuracy =  0.9375\n",
      "now loss =  0.07079030054916556  accuracy =  0.921875\n",
      "now loss =  0.10014125280810586  accuracy =  0.84375\n",
      "now loss =  0.08432206320780075  accuracy =  0.859375\n",
      "now loss =  0.08359436653849805  accuracy =  0.890625\n",
      "now loss =  0.08320638974520969  accuracy =  0.9\n",
      "now loss =  0.1091692788100309  accuracy =  0.859375\n",
      "now loss =  0.08815033937023745  accuracy =  0.90625\n",
      "now loss =  0.10211794133053513  accuracy =  0.84375\n",
      "now loss =  0.084686239273249  accuracy =  0.875\n",
      "now loss =  0.06673177868757246  accuracy =  0.921875\n",
      "now loss =  0.07159650659751393  accuracy =  0.90625\n",
      "now loss =  0.12418873934172947  accuracy =  0.796875\n",
      "now loss =  0.06691940112482478  accuracy =  0.953125\n",
      "now loss =  0.07717550112722192  accuracy =  0.90625\n",
      "now loss =  0.08134844193346566  accuracy =  0.875\n",
      "now loss =  0.0836497502406431  accuracy =  0.875\n",
      "now loss =  0.08383434099505357  accuracy =  0.921875\n",
      "now loss =  0.11933693699164495  accuracy =  0.78125\n",
      "now loss =  0.06561439841837491  accuracy =  0.9375\n",
      "now loss =  0.06861304549404762  accuracy =  0.9375\n",
      "now loss =  0.08387418756091376  accuracy =  0.875\n",
      "now loss =  0.07005611312949217  accuracy =  0.890625\n",
      "now loss =  0.09788952127854295  accuracy =  0.84375\n",
      "now loss =  0.10080032190949681  accuracy =  0.84375\n",
      "now loss =  0.10691556725448537  accuracy =  0.828125\n",
      "now loss =  0.0893566558648545  accuracy =  0.90625\n",
      "now loss =  0.08132986175693882  accuracy =  0.90625\n",
      "now loss =  0.08429692069702294  accuracy =  0.875\n",
      "now loss =  0.08158975015466272  accuracy =  0.875\n",
      "now loss =  0.07472253554729663  accuracy =  0.90625\n",
      "now loss =  0.07611752453100357  accuracy =  0.921875\n",
      "now loss =  0.1101478832185897  accuracy =  0.84375\n",
      "now loss =  0.08883009014489163  accuracy =  0.90625\n",
      "now loss =  0.0870469003849227  accuracy =  0.875\n",
      "now loss =  0.055657055169407145  accuracy =  0.953125\n",
      "now loss =  0.06354329441746412  accuracy =  0.921875\n",
      "now loss =  0.11256722902908349  accuracy =  0.85\n",
      "now loss =  0.06648790916444952  accuracy =  0.9375\n",
      "now loss =  0.0896738796528997  accuracy =  0.859375\n",
      "now loss =  0.10239312300977957  accuracy =  0.859375\n",
      "now loss =  0.11752109781840162  accuracy =  0.84375\n",
      "now loss =  0.07713156774250052  accuracy =  0.90625\n",
      "now loss =  0.0825860072343586  accuracy =  0.90625\n",
      "now loss =  0.09187713662556571  accuracy =  0.859375\n",
      "now loss =  0.06475337106693779  accuracy =  0.90625\n",
      "now loss =  0.11229002765868921  accuracy =  0.828125\n",
      "now loss =  0.08759119030928231  accuracy =  0.84375\n",
      "now loss =  0.057589237973586976  accuracy =  0.9375\n",
      "now loss =  0.07084528070310206  accuracy =  0.890625\n",
      "now loss =  0.09480854401297864  accuracy =  0.875\n",
      "now loss =  0.08653065940567267  accuracy =  0.90625\n",
      "now loss =  0.0774166600693475  accuracy =  0.90625\n",
      "now loss =  0.10072837154161626  accuracy =  0.825\n",
      "now loss =  0.0890814504539076  accuracy =  0.875\n",
      "now loss =  0.07880493945593972  accuracy =  0.90625\n",
      "now loss =  0.07491301545352541  accuracy =  0.890625\n",
      "now loss =  0.123953604632856  accuracy =  0.78125\n",
      "now loss =  0.08337417950905862  accuracy =  0.890625\n",
      "now loss =  0.0763805087368744  accuracy =  0.90625\n",
      "now loss =  0.10431216432059988  accuracy =  0.828125\n",
      "now loss =  0.10218007424092138  accuracy =  0.84375\n",
      "now loss =  0.08619851982901104  accuracy =  0.921875\n",
      "now loss =  0.08254284061424726  accuracy =  0.875\n",
      "now loss =  0.0634357732490494  accuracy =  0.9375\n",
      "now loss =  0.08274053003264667  accuracy =  0.921875\n",
      "now loss =  0.09425199689443939  accuracy =  0.828125\n",
      "now loss =  0.063745908732838  accuracy =  0.921875\n",
      "now loss =  0.07921438785295895  accuracy =  0.890625\n",
      "now loss =  0.10695221506660293  accuracy =  0.825\n",
      "now loss =  0.0954049097169623  accuracy =  0.890625\n",
      "now loss =  0.09398215578773923  accuracy =  0.84375\n",
      "now loss =  0.09840033470715791  accuracy =  0.859375\n",
      "now loss =  0.0704177394718169  accuracy =  0.921875\n",
      "now loss =  0.07350389293592467  accuracy =  0.921875\n",
      "now loss =  0.06937248293365833  accuracy =  0.90625\n",
      "now loss =  0.07704986555563181  accuracy =  0.859375\n",
      "now loss =  0.10329438218625601  accuracy =  0.859375\n",
      "now loss =  0.09705127849408414  accuracy =  0.890625\n",
      "now loss =  0.10323255626551832  accuracy =  0.875\n",
      "now loss =  0.07738671765503738  accuracy =  0.890625\n",
      "now loss =  0.07596124905082334  accuracy =  0.921875\n",
      "now loss =  0.08341764622841641  accuracy =  0.875\n",
      "now loss =  0.10695380284863182  accuracy =  0.828125\n",
      "now loss =  0.059095913328343394  accuracy =  0.9375\n",
      "now loss =  0.0990146059677781  accuracy =  0.875\n",
      "now loss =  0.09345996676587064  accuracy =  0.875\n",
      "now loss =  0.08509952099916272  accuracy =  0.859375\n",
      "now loss =  0.10004365873991039  accuracy =  0.84375\n",
      "now loss =  0.09797253347400187  accuracy =  0.828125\n",
      "now loss =  0.09430453723262874  accuracy =  0.890625\n",
      "now loss =  0.07288656047423604  accuracy =  0.921875\n",
      "now loss =  0.08883778813898308  accuracy =  0.875\n",
      "now loss =  0.08894350258130893  accuracy =  0.890625\n",
      "now loss =  0.06339122096352169  accuracy =  0.90625\n",
      "now loss =  0.07480177297931562  accuracy =  0.953125\n",
      "now loss =  0.11790497128512603  accuracy =  0.828125\n",
      "now loss =  0.054990211513968344  accuracy =  0.9375\n",
      "now loss =  0.06504065850798374  accuracy =  0.921875\n",
      "now loss =  0.10801385617942552  accuracy =  0.828125\n",
      "now loss =  0.07478260666536372  accuracy =  0.90625\n",
      "now loss =  0.09678486350575573  accuracy =  0.875\n",
      "now loss =  0.08503809255087318  accuracy =  0.890625\n",
      "now loss =  0.10795792513490646  accuracy =  0.859375\n",
      "now loss =  0.08595409962703529  accuracy =  0.875\n",
      "now loss =  0.0813777489415996  accuracy =  0.875\n",
      "now loss =  0.09380999570684313  accuracy =  0.875\n",
      "now loss =  0.06803334142425821  accuracy =  0.890625\n",
      "now loss =  0.07139613699958307  accuracy =  0.921875\n",
      "now loss =  0.06474364639709632  accuracy =  0.921875\n",
      "now loss =  0.06287897820855365  accuracy =  0.90625\n",
      "now loss =  0.08480722443154008  accuracy =  0.90625\n",
      "now loss =  0.10351231192862104  accuracy =  0.84375\n",
      "now loss =  0.08362463023986913  accuracy =  0.90625\n",
      "now loss =  0.09196448034812744  accuracy =  0.890625\n",
      "now loss =  0.08779454020900095  accuracy =  0.875\n",
      "now loss =  0.10941743758292198  accuracy =  0.8125\n",
      "now loss =  0.08930617810333116  accuracy =  0.825\n",
      "now loss =  0.11111276176701006  accuracy =  0.8125\n",
      "now loss =  0.0923198239643584  accuracy =  0.890625\n",
      "now loss =  0.07773950943248667  accuracy =  0.859375\n",
      "now loss =  0.09371778776188722  accuracy =  0.859375\n",
      "now loss =  0.0865713050250436  accuracy =  0.890625\n",
      "now loss =  0.09087740844291492  accuracy =  0.875\n",
      "now loss =  0.07206944972849921  accuracy =  0.921875\n",
      "now loss =  0.08343308361686845  accuracy =  0.875\n",
      "now loss =  0.09375588560832927  accuracy =  0.875\n",
      "now loss =  0.08044944701986179  accuracy =  0.90625\n",
      "now loss =  0.07281335590017313  accuracy =  0.921875\n",
      "now loss =  0.05577877748424799  accuracy =  0.953125\n",
      "now loss =  0.09615053550235775  accuracy =  0.84375\n",
      "now loss =  0.09642028319865667  accuracy =  0.859375\n",
      "now loss =  0.08945935988342942  accuracy =  0.890625\n",
      "now loss =  0.06977720850549005  accuracy =  0.95\n",
      "now loss =  0.06535447023245991  accuracy =  0.890625\n",
      "now loss =  0.1044769048602244  accuracy =  0.875\n",
      "now loss =  0.06970337978053012  accuracy =  0.90625\n",
      "now loss =  0.08443871559373958  accuracy =  0.890625\n",
      "now loss =  0.11876862566258224  accuracy =  0.8125\n",
      "now loss =  0.0763414748569954  accuracy =  0.875\n",
      "now loss =  0.08595539248963352  accuracy =  0.890625\n",
      "now loss =  0.08187029570253769  accuracy =  0.890625\n",
      "now loss =  0.08904670706680896  accuracy =  0.859375\n",
      "now loss =  0.10848180089492018  accuracy =  0.828125\n",
      "now loss =  0.08806481776991323  accuracy =  0.890625\n",
      "now loss =  0.08876162910924694  accuracy =  0.875\n",
      "now loss =  0.07903176818655078  accuracy =  0.9375\n",
      "now loss =  0.07025305167274051  accuracy =  0.9375\n",
      "now loss =  0.0764045284397699  accuracy =  0.90625\n",
      "now loss =  0.08846345715458584  accuracy =  0.875\n",
      "now loss =  0.10489384179602149  accuracy =  0.828125\n",
      "now loss =  0.08287373550313691  accuracy =  0.921875\n",
      "now loss =  0.10393654565104642  accuracy =  0.890625\n",
      "now loss =  0.0922512926553354  accuracy =  0.890625\n",
      "now loss =  0.101397678602978  accuracy =  0.828125\n",
      "now loss =  0.07079685225057673  accuracy =  0.90625\n",
      "now loss =  0.08981417733382081  accuracy =  0.875\n",
      "now loss =  0.08233794022969002  accuracy =  0.890625\n",
      "now loss =  0.0864222662100119  accuracy =  0.890625\n",
      "now loss =  0.06928805922239117  accuracy =  0.90625\n",
      "now loss =  0.08803888683969567  accuracy =  0.90625\n",
      "now loss =  0.07593307451420772  accuracy =  0.90625\n",
      "now loss =  0.11332904598093743  accuracy =  0.828125\n",
      "now loss =  0.09364771192658206  accuracy =  0.828125\n",
      "now loss =  0.05038699877217882  accuracy =  0.9375\n",
      "now loss =  0.07028123102340378  accuracy =  0.95\n",
      "now loss =  0.1185902906523488  accuracy =  0.8125\n",
      "now loss =  0.08999994679940894  accuracy =  0.90625\n",
      "now loss =  0.09314129019950435  accuracy =  0.875\n",
      "now loss =  0.08887797391197945  accuracy =  0.859375\n",
      "now loss =  0.07742802897358354  accuracy =  0.875\n",
      "now loss =  0.07350891151186043  accuracy =  0.921875\n",
      "now loss =  0.08298834337621029  accuracy =  0.921875\n",
      "now loss =  0.11727496536141657  accuracy =  0.859375\n",
      "now loss =  0.08588812183455558  accuracy =  0.921875\n",
      "now loss =  0.07799480839320036  accuracy =  0.890625\n",
      "now loss =  0.05783261079878581  accuracy =  0.953125\n",
      "now loss =  0.08518362986579214  accuracy =  0.875\n",
      "now loss =  0.09775302511100946  accuracy =  0.859375\n",
      "now loss =  0.10160502926196481  accuracy =  0.828125\n",
      "now loss =  0.07902870461226362  accuracy =  0.890625\n",
      "now loss =  0.0490025601448411  accuracy =  0.95\n",
      "now loss =  0.07022445410380757  accuracy =  0.921875\n",
      "now loss =  0.0631219972512231  accuracy =  0.90625\n",
      "now loss =  0.09188311523515008  accuracy =  0.890625\n",
      "now loss =  0.11522707827230208  accuracy =  0.84375\n",
      "now loss =  0.06890520297124826  accuracy =  0.90625\n",
      "now loss =  0.07133526475443944  accuracy =  0.9375\n",
      "now loss =  0.10318070121815949  accuracy =  0.84375\n",
      "now loss =  0.0771075662649193  accuracy =  0.90625\n",
      "now loss =  0.08834679919000693  accuracy =  0.875\n",
      "now loss =  0.09493615630392493  accuracy =  0.875\n",
      "now loss =  0.08344745007889895  accuracy =  0.875\n",
      "now loss =  0.08229225685282965  accuracy =  0.921875\n",
      "now loss =  0.08820164109445926  accuracy =  0.890625\n",
      "now loss =  0.1125543146979068  accuracy =  0.875\n",
      "now loss =  0.0827267351417803  accuracy =  0.859375\n",
      "now loss =  0.08113890129559692  accuracy =  0.9\n",
      "now loss =  0.08247770762142237  accuracy =  0.84375\n",
      "now loss =  0.07437792498491039  accuracy =  0.9375\n",
      "now loss =  0.08685063928060542  accuracy =  0.875\n",
      "now loss =  0.08404731997722893  accuracy =  0.890625\n",
      "now loss =  0.0957358293266128  accuracy =  0.84375\n",
      "now loss =  0.06808626411117302  accuracy =  0.90625\n",
      "now loss =  0.09255551313348737  accuracy =  0.890625\n",
      "now loss =  0.111189968737768  accuracy =  0.859375\n",
      "now loss =  0.07146415916152343  accuracy =  0.921875\n",
      "now loss =  0.08748650653126201  accuracy =  0.890625\n",
      "now loss =  0.10643448997374072  accuracy =  0.828125\n",
      "now loss =  0.08803634500829469  accuracy =  0.890625\n",
      "now loss =  0.06467460129633537  accuracy =  0.921875\n",
      "now loss =  0.07909390991966476  accuracy =  0.875\n",
      "now loss =  0.09833131035082421  accuracy =  0.875\n",
      "now loss =  0.084703995981934  accuracy =  0.9\n",
      "now loss =  0.07152199455483775  accuracy =  0.9375\n",
      "now loss =  0.08542819881979967  accuracy =  0.875\n",
      "now loss =  0.08717388838563017  accuracy =  0.859375\n",
      "now loss =  0.07498817019146203  accuracy =  0.90625\n",
      "now loss =  0.07880138003030462  accuracy =  0.9375\n",
      "now loss =  0.09332986725647091  accuracy =  0.859375\n",
      "now loss =  0.09483306749291705  accuracy =  0.890625\n",
      "now loss =  0.0733852079210523  accuracy =  0.921875\n",
      "now loss =  0.09112634242926498  accuracy =  0.859375\n",
      "now loss =  0.07378969782048625  accuracy =  0.90625\n",
      "now loss =  0.08447126182242909  accuracy =  0.859375\n",
      "now loss =  0.07723528669962469  accuracy =  0.859375\n",
      "now loss =  0.10404221247849263  accuracy =  0.84375\n",
      "now loss =  0.09941193627759598  accuracy =  0.84375\n",
      "now loss =  0.09654577388937244  accuracy =  0.890625\n",
      "now loss =  0.07739941171370901  accuracy =  0.9\n",
      "now loss =  0.07079239668577553  accuracy =  0.90625\n",
      "now loss =  0.09859586906574098  accuracy =  0.875\n",
      "now loss =  0.05470380625023537  accuracy =  0.9375\n",
      "now loss =  0.09809593206526016  accuracy =  0.90625\n",
      "now loss =  0.0706119431604328  accuracy =  0.90625\n",
      "now loss =  0.09096085147453498  accuracy =  0.90625\n",
      "now loss =  0.10167994580848513  accuracy =  0.828125\n",
      "now loss =  0.08094184915503422  accuracy =  0.90625\n",
      "now loss =  0.09298794800121174  accuracy =  0.859375\n",
      "now loss =  0.08248265736280047  accuracy =  0.875\n",
      "now loss =  0.09192544492680423  accuracy =  0.875\n",
      "now loss =  0.08861107845490585  accuracy =  0.875\n",
      "now loss =  0.08633586125519202  accuracy =  0.84375\n",
      "now loss =  0.06711144499069502  accuracy =  0.9375\n",
      "now loss =  0.10790836567150883  accuracy =  0.84375\n",
      "now loss =  0.09946863801172241  accuracy =  0.9\n",
      "now loss =  0.09662656040537032  accuracy =  0.84375\n",
      "now loss =  0.07790451800417277  accuracy =  0.921875\n",
      "now loss =  0.09274727471033622  accuracy =  0.875\n",
      "now loss =  0.08519266666056724  accuracy =  0.90625\n",
      "now loss =  0.08507728603547753  accuracy =  0.859375\n",
      "now loss =  0.06932292869925075  accuracy =  0.9375\n",
      "now loss =  0.08682953603242244  accuracy =  0.859375\n",
      "now loss =  0.06730822379562214  accuracy =  0.9375\n",
      "now loss =  0.09016998407485816  accuracy =  0.890625\n",
      "now loss =  0.10246495693416532  accuracy =  0.828125\n",
      "now loss =  0.09081129371610035  accuracy =  0.875\n",
      "now loss =  0.10055953706788907  accuracy =  0.875\n",
      "now loss =  0.06873688620683144  accuracy =  0.921875\n",
      "now loss =  0.082460732307106  accuracy =  0.890625\n",
      "now loss =  0.09537876180681382  accuracy =  0.84375\n",
      "now loss =  0.0849278279019119  accuracy =  0.875\n",
      "now loss =  0.09000149871405536  accuracy =  0.890625\n",
      "now loss =  0.07399037022170171  accuracy =  0.875\n",
      "now loss =  0.06486980942517073  accuracy =  0.9375\n",
      "now loss =  0.048465127301158  accuracy =  0.96875\n",
      "now loss =  0.07776525822793942  accuracy =  0.890625\n",
      "now loss =  0.09388578616353047  accuracy =  0.84375\n",
      "now loss =  0.10878997955091367  accuracy =  0.84375\n",
      "now loss =  0.1041087878736548  accuracy =  0.890625\n",
      "now loss =  0.10478147021592932  accuracy =  0.859375\n",
      "now loss =  0.07510166009497461  accuracy =  0.921875\n",
      "now loss =  0.10829177658448175  accuracy =  0.828125\n",
      "now loss =  0.09068709665228014  accuracy =  0.890625\n",
      "now loss =  0.0942029567858285  accuracy =  0.859375\n",
      "now loss =  0.06475474065757578  accuracy =  0.921875\n",
      "now loss =  0.07662623931827237  accuracy =  0.90625\n",
      "now loss =  0.11174465257952707  accuracy =  0.8\n",
      "now loss =  0.09207531028817584  accuracy =  0.84375\n",
      "now loss =  0.08324803271040868  accuracy =  0.890625\n",
      "now loss =  0.08659530556374251  accuracy =  0.875\n",
      "now loss =  0.08298691542262507  accuracy =  0.890625\n",
      "now loss =  0.08934180763622238  accuracy =  0.859375\n",
      "now loss =  0.06503653565600664  accuracy =  0.953125\n",
      "now loss =  0.11327420700483795  accuracy =  0.796875\n",
      "now loss =  0.0843205029506805  accuracy =  0.890625\n",
      "now loss =  0.08580894744754175  accuracy =  0.90625\n",
      "now loss =  0.08132745951589052  accuracy =  0.921875\n",
      "now loss =  0.10859525039485535  accuracy =  0.84375\n",
      "now loss =  0.07662672287921232  accuracy =  0.90625\n",
      "now loss =  0.07082317767544949  accuracy =  0.921875\n",
      "now loss =  0.07889720424723284  accuracy =  0.921875\n",
      "now loss =  0.08665400072211556  accuracy =  0.875\n",
      "now loss =  0.08674452552643677  accuracy =  0.875\n",
      "now loss =  0.06855827172435675  accuracy =  0.921875\n",
      "now loss =  0.09424972477169744  accuracy =  0.859375\n",
      "now loss =  0.0858504107546823  accuracy =  0.90625\n",
      "now loss =  0.09932627125890535  accuracy =  0.875\n",
      "now loss =  0.08476656972583839  accuracy =  0.875\n",
      "now loss =  0.09874004499271774  accuracy =  0.875\n",
      "now loss =  0.06809963229443353  accuracy =  0.921875\n",
      "now loss =  0.06302894235877686  accuracy =  0.90625\n",
      "now loss =  0.09502655818452664  accuracy =  0.875\n",
      "now loss =  0.09102265087660912  accuracy =  0.84375\n",
      "now loss =  0.0637377807148024  accuracy =  0.9375\n",
      "now loss =  0.13407468631877076  accuracy =  0.78125\n",
      "now loss =  0.07033494027990794  accuracy =  0.90625\n",
      "now loss =  0.08280368982742245  accuracy =  0.90625\n",
      "now loss =  0.09368454199933503  accuracy =  0.875\n",
      "now loss =  0.08346291172805338  accuracy =  0.85\n",
      "now loss =  0.09169109080775824  accuracy =  0.84375\n",
      "now loss =  0.08498277060237222  accuracy =  0.890625\n",
      "now loss =  0.09330062596000264  accuracy =  0.890625\n",
      "now loss =  0.09256457829133574  accuracy =  0.890625\n",
      "now loss =  0.08638379185816956  accuracy =  0.890625\n",
      "now loss =  0.07937384666335784  accuracy =  0.859375\n",
      "now loss =  0.09521674544748447  accuracy =  0.875\n",
      "now loss =  0.0958852638325547  accuracy =  0.859375\n",
      "now loss =  0.08879153610781912  accuracy =  0.90625\n",
      "now loss =  0.08496224093692525  accuracy =  0.875\n",
      "now loss =  0.07766785160061421  accuracy =  0.890625\n",
      "now loss =  0.07039987848987718  accuracy =  0.890625\n",
      "now loss =  0.10550278571544895  accuracy =  0.84375\n",
      "now loss =  0.07880337849498252  accuracy =  0.921875\n",
      "now loss =  0.0861809616401377  accuracy =  0.90625\n",
      "now loss =  0.05407537468778403  accuracy =  0.95\n",
      "now loss =  0.1164180100690415  accuracy =  0.828125\n",
      "now loss =  0.08814476190056625  accuracy =  0.875\n",
      "now loss =  0.09411362037783544  accuracy =  0.859375\n",
      "now loss =  0.08452672814399603  accuracy =  0.875\n",
      "now loss =  0.07287985512161922  accuracy =  0.9375\n",
      "now loss =  0.07039176604543707  accuracy =  0.921875\n",
      "now loss =  0.06234293854591694  accuracy =  0.90625\n",
      "now loss =  0.06018603805514961  accuracy =  0.953125\n",
      "now loss =  0.10509514474158595  accuracy =  0.8125\n",
      "now loss =  0.07198974722559981  accuracy =  0.90625\n",
      "now loss =  0.08998198436265563  accuracy =  0.890625\n",
      "now loss =  0.09054953425705406  accuracy =  0.875\n",
      "now loss =  0.09507187731699168  accuracy =  0.859375\n",
      "now loss =  0.10233653654925949  accuracy =  0.828125\n",
      "now loss =  0.0928612018065271  accuracy =  0.890625\n",
      "now loss =  0.08546713347482815  accuracy =  0.9\n",
      "now loss =  0.10775479489189371  accuracy =  0.84375\n",
      "now loss =  0.052627383797478756  accuracy =  0.9375\n",
      "now loss =  0.10007884643453815  accuracy =  0.890625\n",
      "now loss =  0.09695043110075957  accuracy =  0.859375\n",
      "now loss =  0.10344084935588208  accuracy =  0.8125\n",
      "now loss =  0.08509406792584759  accuracy =  0.875\n",
      "now loss =  0.0754924392018175  accuracy =  0.921875\n",
      "now loss =  0.06246026559599649  accuracy =  0.921875\n",
      "now loss =  0.101927493280482  accuracy =  0.84375\n",
      "now loss =  0.07887954888083039  accuracy =  0.90625\n",
      "now loss =  0.09884586877771229  accuracy =  0.859375\n",
      "now loss =  0.08558210992791115  accuracy =  0.890625\n",
      "now loss =  0.07808066083785015  accuracy =  0.890625\n",
      "now loss =  0.10491181501189702  accuracy =  0.84375\n",
      "now loss =  0.07993688055560697  accuracy =  0.90625\n",
      "now loss =  0.0746326365556919  accuracy =  0.9\n",
      "now loss =  0.08090605350352088  accuracy =  0.921875\n",
      "now loss =  0.08482308459864235  accuracy =  0.890625\n",
      "now loss =  0.0710914346100132  accuracy =  0.90625\n",
      "now loss =  0.09534053712081587  accuracy =  0.90625\n",
      "now loss =  0.08575306969167357  accuracy =  0.90625\n",
      "now loss =  0.09873349436807191  accuracy =  0.84375\n",
      "now loss =  0.09554505537784869  accuracy =  0.875\n",
      "now loss =  0.0928088238582433  accuracy =  0.875\n",
      "now loss =  0.072028064315671  accuracy =  0.90625\n",
      "now loss =  0.09484214460104654  accuracy =  0.859375\n",
      "now loss =  0.07973931733529012  accuracy =  0.875\n",
      "now loss =  0.09002283134131918  accuracy =  0.859375\n",
      "now loss =  0.09457148926944983  accuracy =  0.875\n",
      "now loss =  0.07524972203621455  accuracy =  0.90625\n",
      "now loss =  0.07834184860374672  accuracy =  0.890625\n",
      "now loss =  0.08425443858906179  accuracy =  0.85\n",
      "now loss =  0.07908508450202129  accuracy =  0.90625\n",
      "now loss =  0.06418746253827413  accuracy =  0.9375\n",
      "now loss =  0.08091034233017212  accuracy =  0.9375\n",
      "now loss =  0.11237173886118312  accuracy =  0.8125\n",
      "now loss =  0.10280023579288036  accuracy =  0.859375\n",
      "now loss =  0.100915698635973  accuracy =  0.84375\n",
      "now loss =  0.07917294114567239  accuracy =  0.875\n",
      "now loss =  0.09512026478448285  accuracy =  0.859375\n",
      "now loss =  0.08616559106015735  accuracy =  0.890625\n",
      "now loss =  0.07870771628636572  accuracy =  0.90625\n",
      "now loss =  0.0772836515005849  accuracy =  0.875\n",
      "now loss =  0.07974880756588325  accuracy =  0.890625\n",
      "now loss =  0.10517179442860614  accuracy =  0.84375\n",
      "now loss =  0.0780192900003076  accuracy =  0.90625\n",
      "now loss =  0.08759914683369555  accuracy =  0.859375\n",
      "now loss =  0.059491324810607635  accuracy =  0.95\n",
      "now loss =  0.1157111982198191  accuracy =  0.8125\n",
      "now loss =  0.0766378348525017  accuracy =  0.921875\n",
      "now loss =  0.08600162017768981  accuracy =  0.84375\n",
      "now loss =  0.07889918359768683  accuracy =  0.921875\n",
      "now loss =  0.08601060895954471  accuracy =  0.90625\n",
      "now loss =  0.11040864901263922  accuracy =  0.84375\n",
      "now loss =  0.07173537307843454  accuracy =  0.890625\n",
      "now loss =  0.06497931865740844  accuracy =  0.890625\n",
      "now loss =  0.12073350212161765  accuracy =  0.8125\n",
      "now loss =  0.08186745234551467  accuracy =  0.875\n",
      "now loss =  0.05586016352309273  accuracy =  0.921875\n",
      "now loss =  0.07071587001197535  accuracy =  0.921875\n",
      "now loss =  0.09603512099796974  accuracy =  0.859375\n",
      "now loss =  0.08593427651687613  accuracy =  0.90625\n",
      "now loss =  0.08616480831250378  accuracy =  0.90625\n",
      "now loss =  0.08493805283145424  accuracy =  0.9\n",
      "now loss =  0.08272679271353245  accuracy =  0.84375\n",
      "now loss =  0.09124299474863781  accuracy =  0.875\n",
      "now loss =  0.10915180819673545  accuracy =  0.875\n",
      "now loss =  0.08637391287922049  accuracy =  0.875\n",
      "now loss =  0.08396175165814634  accuracy =  0.875\n",
      "now loss =  0.10075985303772116  accuracy =  0.859375\n",
      "now loss =  0.049517847687987254  accuracy =  0.953125\n",
      "now loss =  0.08181742516691784  accuracy =  0.890625\n",
      "now loss =  0.1039395740869239  accuracy =  0.859375\n",
      "now loss =  0.08587763949058344  accuracy =  0.890625\n",
      "now loss =  0.08017540113186156  accuracy =  0.875\n",
      "now loss =  0.10709751844833326  accuracy =  0.828125\n",
      "now loss =  0.08024250391293916  accuracy =  0.90625\n",
      "now loss =  0.0905299143372798  accuracy =  0.890625\n",
      "now loss =  0.05367199615773756  accuracy =  0.953125\n",
      "now loss =  0.08952678146380984  accuracy =  0.875\n",
      "now loss =  0.06761681825643148  accuracy =  0.890625\n",
      "now loss =  0.10077756688344987  accuracy =  0.859375\n",
      "now loss =  0.08996339170009313  accuracy =  0.90625\n",
      "now loss =  0.11232546884144948  accuracy =  0.828125\n",
      "now loss =  0.08049043252284299  accuracy =  0.90625\n",
      "now loss =  0.09808299601605469  accuracy =  0.84375\n",
      "now loss =  0.09354730011269347  accuracy =  0.84375\n",
      "now loss =  0.08745308215676409  accuracy =  0.859375\n",
      "now loss =  0.09030678642019047  accuracy =  0.890625\n",
      "now loss =  0.09096339648635349  accuracy =  0.859375\n",
      "now loss =  0.06480766329130919  accuracy =  0.953125\n",
      "now loss =  0.07432614638681416  accuracy =  0.890625\n",
      "now loss =  0.06346547232208653  accuracy =  0.96875\n",
      "now loss =  0.0772015069658246  accuracy =  0.875\n",
      "now loss =  0.08470209362097796  accuracy =  0.890625\n",
      "now loss =  0.10856046222748114  accuracy =  0.9\n",
      "now loss =  0.07388914085878501  accuracy =  0.921875\n",
      "now loss =  0.06663171534217993  accuracy =  0.921875\n",
      "now loss =  0.0823057897098815  accuracy =  0.890625\n",
      "now loss =  0.11245623311706245  accuracy =  0.859375\n",
      "now loss =  0.09740670324328393  accuracy =  0.875\n",
      "now loss =  0.06495811793616318  accuracy =  0.953125\n",
      "now loss =  0.06863485338654884  accuracy =  0.9375\n",
      "now loss =  0.08761749331018824  accuracy =  0.875\n",
      "now loss =  0.05775212912865704  accuracy =  0.9375\n",
      "now loss =  0.08372442379748612  accuracy =  0.90625\n",
      "now loss =  0.1011835099056862  accuracy =  0.84375\n",
      "now loss =  0.08907216949376714  accuracy =  0.875\n",
      "now loss =  0.11362601353100815  accuracy =  0.828125\n",
      "now loss =  0.09371771949114846  accuracy =  0.84375\n",
      "now loss =  0.08255506451906588  accuracy =  0.90625\n",
      "now loss =  0.11197940884865547  accuracy =  0.75\n",
      "now loss =  0.1248563871915173  accuracy =  0.8125\n",
      "now loss =  0.09595465845831228  accuracy =  0.84375\n",
      "now loss =  0.051557938570124064  accuracy =  0.96875\n",
      "now loss =  0.08748577789174139  accuracy =  0.875\n",
      "now loss =  0.11324474183660113  accuracy =  0.84375\n",
      "now loss =  0.06610162492756522  accuracy =  0.921875\n",
      "now loss =  0.07477055158777815  accuracy =  0.921875\n",
      "now loss =  0.09318191114203268  accuracy =  0.828125\n",
      "now loss =  0.07151220703026595  accuracy =  0.921875\n",
      "now loss =  0.0687985923690444  accuracy =  0.9375\n",
      "now loss =  0.06854686562009144  accuracy =  0.921875\n",
      "now loss =  0.08971032412802338  accuracy =  0.859375\n",
      "now loss =  0.09949386856852019  accuracy =  0.875\n",
      "now loss =  0.08076473097783614  accuracy =  0.890625\n",
      "now loss =  0.10898459851535883  accuracy =  0.828125\n",
      "now loss =  0.08360354575257431  accuracy =  0.875\n",
      "now loss =  0.07386976546544782  accuracy =  0.890625\n",
      "now loss =  0.11593394684675018  accuracy =  0.828125\n",
      "now loss =  0.07658569699120685  accuracy =  0.90625\n",
      "now loss =  0.07733133248910883  accuracy =  0.921875\n",
      "now loss =  0.076153980985524  accuracy =  0.921875\n",
      "now loss =  0.08177317956882789  accuracy =  0.890625\n",
      "now loss =  0.09411531303889922  accuracy =  0.84375\n",
      "now loss =  0.09612758546295475  accuracy =  0.875\n",
      "now loss =  0.061615523956240315  accuracy =  0.953125\n",
      "now loss =  0.11148139725232897  accuracy =  0.84375\n",
      "now loss =  0.09853688600559739  accuracy =  0.8125\n",
      "now loss =  0.06889885950256688  accuracy =  0.921875\n",
      "now loss =  0.08114339883261815  accuracy =  0.875\n",
      "now loss =  0.10160271398239554  accuracy =  0.890625\n",
      "now loss =  0.09577123620005433  accuracy =  0.859375\n",
      "now loss =  0.06096233809215727  accuracy =  0.925\n",
      "now loss =  0.07766412659447958  accuracy =  0.890625\n",
      "now loss =  0.08050416064873926  accuracy =  0.890625\n",
      "now loss =  0.07571712014535717  accuracy =  0.90625\n",
      "now loss =  0.053262992283120744  accuracy =  0.96875\n",
      "now loss =  0.051470362666690465  accuracy =  0.96875\n",
      "now loss =  0.11254605945583049  accuracy =  0.8125\n",
      "now loss =  0.09241008980584747  accuracy =  0.890625\n",
      "now loss =  0.09092319230285115  accuracy =  0.890625\n",
      "now loss =  0.08886152745917314  accuracy =  0.875\n",
      "now loss =  0.08161045270460711  accuracy =  0.859375\n",
      "now loss =  0.1283204536394812  accuracy =  0.84375\n",
      "now loss =  0.06088633528839467  accuracy =  0.90625\n",
      "now loss =  0.10057501033456026  accuracy =  0.890625\n",
      "now loss =  0.07582140401577206  accuracy =  0.875\n",
      "now loss =  0.10518023705156003  accuracy =  0.84375\n",
      "now loss =  0.10381409832579007  accuracy =  0.875\n",
      "now loss =  0.11777428240634172  accuracy =  0.828125\n",
      "now loss =  0.13052933357424526  accuracy =  0.78125\n",
      "now loss =  0.09125477964217654  accuracy =  0.84375\n",
      "now loss =  0.055846619370625364  accuracy =  0.953125\n",
      "now loss =  0.08542155825867045  accuracy =  0.90625\n",
      "now loss =  0.09300062436496005  accuracy =  0.875\n",
      "now loss =  0.09511796518599107  accuracy =  0.828125\n",
      "now loss =  0.0691595899075803  accuracy =  0.9375\n",
      "now loss =  0.08838305744057531  accuracy =  0.875\n",
      "now loss =  0.08499722098854695  accuracy =  0.875\n",
      "now loss =  0.06558899981375951  accuracy =  0.953125\n",
      "now loss =  0.058389215517322415  accuracy =  0.921875\n",
      "now loss =  0.08319572785099907  accuracy =  0.890625\n",
      "now loss =  0.10055313810478361  accuracy =  0.859375\n",
      "now loss =  0.06983134725138213  accuracy =  0.9375\n",
      "now loss =  0.08294620948411772  accuracy =  0.925\n",
      "now loss =  0.07356468878500724  accuracy =  0.921875\n",
      "now loss =  0.09323316227558996  accuracy =  0.875\n",
      "now loss =  0.0887424085152769  accuracy =  0.875\n",
      "now loss =  0.06340690049406535  accuracy =  0.9375\n",
      "now loss =  0.09054070367971594  accuracy =  0.890625\n",
      "now loss =  0.07197677361032885  accuracy =  0.90625\n",
      "now loss =  0.09135351377879605  accuracy =  0.90625\n",
      "now loss =  0.0951378152705107  accuracy =  0.859375\n",
      "now loss =  0.12396357788178516  accuracy =  0.796875\n",
      "now loss =  0.08719379208039751  accuracy =  0.859375\n",
      "now loss =  0.07233532714304775  accuracy =  0.90625\n",
      "now loss =  0.06135536781786305  accuracy =  0.9375\n",
      "now loss =  0.10091071057820845  accuracy =  0.875\n",
      "now loss =  0.09273469226740466  accuracy =  0.859375\n",
      "now loss =  0.09216629355035155  accuracy =  0.875\n",
      "now loss =  0.06675055603658928  accuracy =  0.925\n",
      "now loss =  0.07336455346822807  accuracy =  0.90625\n",
      "now loss =  0.10746154389548769  accuracy =  0.84375\n",
      "now loss =  0.10085296665376373  accuracy =  0.828125\n",
      "now loss =  0.10106201566296819  accuracy =  0.84375\n",
      "now loss =  0.07569897771636627  accuracy =  0.921875\n",
      "now loss =  0.09629599650788706  accuracy =  0.890625\n",
      "now loss =  0.08283973859430467  accuracy =  0.859375\n",
      "now loss =  0.10120153374051565  accuracy =  0.875\n",
      "now loss =  0.08240499895846204  accuracy =  0.875\n",
      "now loss =  0.07085175726091525  accuracy =  0.890625\n",
      "now loss =  0.1016046555426267  accuracy =  0.84375\n",
      "now loss =  0.08732432191340385  accuracy =  0.890625\n",
      "now loss =  0.05687355354447621  accuracy =  0.921875\n",
      "now loss =  0.11083383336286015  accuracy =  0.84375\n",
      "now loss =  0.05946742589813824  accuracy =  0.953125\n",
      "now loss =  0.04676981141084084  accuracy =  0.975\n",
      "now loss =  0.10979847872288861  accuracy =  0.84375\n",
      "now loss =  0.08413175582628996  accuracy =  0.875\n",
      "now loss =  0.08611135460417138  accuracy =  0.890625\n",
      "now loss =  0.07256433927465697  accuracy =  0.890625\n",
      "now loss =  0.12017999760800016  accuracy =  0.828125\n",
      "now loss =  0.10434218386472724  accuracy =  0.890625\n",
      "now loss =  0.0639109523638612  accuracy =  0.9375\n",
      "now loss =  0.07516135422420385  accuracy =  0.921875\n",
      "now loss =  0.08182215428733845  accuracy =  0.875\n",
      "now loss =  0.10028384144814913  accuracy =  0.859375\n",
      "now loss =  0.07428612284346305  accuracy =  0.890625\n",
      "now loss =  0.06250405358404729  accuracy =  0.9375\n",
      "now loss =  0.08832770690952729  accuracy =  0.890625\n",
      "now loss =  0.0679948881487369  accuracy =  0.921875\n",
      "now loss =  0.09894680816957156  accuracy =  0.828125\n",
      "now loss =  0.10395507093440019  accuracy =  0.875\n",
      "now loss =  0.11087919925287819  accuracy =  0.828125\n",
      "now loss =  0.08012279720386048  accuracy =  0.875\n",
      "now loss =  0.09959783840379811  accuracy =  0.859375\n",
      "now loss =  0.0853429403389253  accuracy =  0.859375\n",
      "now loss =  0.09174289396509108  accuracy =  0.84375\n",
      "now loss =  0.07431536321881073  accuracy =  0.890625\n",
      "now loss =  0.08274218548957499  accuracy =  0.921875\n",
      "now loss =  0.05501935561169015  accuracy =  0.953125\n",
      "now loss =  0.10590124887945812  accuracy =  0.890625\n",
      "now loss =  0.08446633421625435  accuracy =  0.890625\n",
      "now loss =  0.07258184092114107  accuracy =  0.921875\n",
      "now loss =  0.0948010118691754  accuracy =  0.890625\n",
      "now loss =  0.08508817498035812  accuracy =  0.859375\n",
      "now loss =  0.08563711161252387  accuracy =  0.90625\n",
      "now loss =  0.0809399730847413  accuracy =  0.890625\n",
      "now loss =  0.08230463959672155  accuracy =  0.875\n",
      "now loss =  0.06662944526037534  accuracy =  0.953125\n",
      "now loss =  0.0904251349108817  accuracy =  0.859375\n",
      "now loss =  0.08315785355086969  accuracy =  0.921875\n",
      "now loss =  0.07143364485837392  accuracy =  0.890625\n",
      "now loss =  0.0739623646611582  accuracy =  0.890625\n",
      "now loss =  0.08240159066134849  accuracy =  0.890625\n",
      "now loss =  0.10973646606694742  accuracy =  0.859375\n",
      "now loss =  0.09947048920513402  accuracy =  0.859375\n",
      "now loss =  0.09915808746190788  accuracy =  0.859375\n",
      "now loss =  0.1113945202959231  accuracy =  0.796875\n",
      "now loss =  0.09929011229349861  accuracy =  0.796875\n",
      "now loss =  0.08610635578151866  accuracy =  0.890625\n",
      "now loss =  0.06458064167330066  accuracy =  0.9375\n",
      "now loss =  0.0719356845979173  accuracy =  0.921875\n",
      "now loss =  0.0860362533303833  accuracy =  0.875\n",
      "now loss =  0.0799020742845619  accuracy =  0.9\n",
      "now loss =  0.06250754258762262  accuracy =  0.921875\n",
      "now loss =  0.11238489997123849  accuracy =  0.8125\n",
      "now loss =  0.10025812613418313  accuracy =  0.859375\n",
      "now loss =  0.08777009178498715  accuracy =  0.921875\n",
      "now loss =  0.06393142247014175  accuracy =  0.9375\n",
      "now loss =  0.08355134621050368  accuracy =  0.890625\n",
      "now loss =  0.09013826702676309  accuracy =  0.875\n",
      "now loss =  0.0804745172426479  accuracy =  0.890625\n",
      "now loss =  0.0768600886793864  accuracy =  0.875\n",
      "now loss =  0.09236321790186292  accuracy =  0.875\n",
      "now loss =  0.08091945076549252  accuracy =  0.890625\n",
      "now loss =  0.08935158620778852  accuracy =  0.859375\n",
      "now loss =  0.09409781741154702  accuracy =  0.859375\n",
      "now loss =  0.07518289511616388  accuracy =  0.890625\n",
      "now loss =  0.08640426019825478  accuracy =  0.875\n",
      "now loss =  0.10261646423216444  accuracy =  0.85\n",
      "now loss =  0.12584852379497483  accuracy =  0.796875\n",
      "now loss =  0.08760758909716124  accuracy =  0.859375\n",
      "now loss =  0.07244411685900848  accuracy =  0.890625\n",
      "now loss =  0.10185336951645788  accuracy =  0.859375\n",
      "now loss =  0.07196262622943911  accuracy =  0.921875\n",
      "now loss =  0.059455752643746765  accuracy =  0.953125\n",
      "now loss =  0.08387874519258781  accuracy =  0.90625\n",
      "now loss =  0.07417883414877584  accuracy =  0.890625\n",
      "now loss =  0.07091819708548855  accuracy =  0.90625\n",
      "now loss =  0.09117251286729883  accuracy =  0.875\n",
      "now loss =  0.10783843153608119  accuracy =  0.875\n",
      "now loss =  0.1080564778067265  accuracy =  0.859375\n",
      "now loss =  0.07490211676461825  accuracy =  0.890625\n",
      "now loss =  0.06637230349083456  accuracy =  0.9375\n",
      "now loss =  0.09318967278599452  accuracy =  0.859375\n",
      "now loss =  0.0889771975859088  accuracy =  0.85\n",
      "now loss =  0.07508126570968124  accuracy =  0.90625\n",
      "now loss =  0.09925313630100334  accuracy =  0.8125\n",
      "now loss =  0.06519574661157759  accuracy =  0.953125\n",
      "now loss =  0.07818374913911176  accuracy =  0.859375\n",
      "now loss =  0.0671978919197607  accuracy =  0.90625\n",
      "now loss =  0.09677491433563282  accuracy =  0.859375\n",
      "now loss =  0.07931837036248843  accuracy =  0.875\n",
      "now loss =  0.0882580378896358  accuracy =  0.921875\n",
      "now loss =  0.07735500828281348  accuracy =  0.90625\n",
      "now loss =  0.08223489864535405  accuracy =  0.921875\n",
      "now loss =  0.07862695372593301  accuracy =  0.890625\n",
      "now loss =  0.08569796497228882  accuracy =  0.890625\n",
      "now loss =  0.08542049214023613  accuracy =  0.90625\n",
      "now loss =  0.1125381351959371  accuracy =  0.8125\n",
      "now loss =  0.08149878213586602  accuracy =  0.90625\n",
      "now loss =  0.13695357837583338  accuracy =  0.8\n",
      "now loss =  0.1394420947804122  accuracy =  0.734375\n",
      "now loss =  0.07971841818349269  accuracy =  0.921875\n",
      "now loss =  0.046385957919665446  accuracy =  0.96875\n",
      "now loss =  0.053602084603370265  accuracy =  0.96875\n",
      "now loss =  0.07188594899887807  accuracy =  0.921875\n",
      "now loss =  0.09258376517426173  accuracy =  0.875\n",
      "now loss =  0.08622675389233919  accuracy =  0.890625\n",
      "now loss =  0.0691502717099777  accuracy =  0.921875\n",
      "now loss =  0.07368160288899593  accuracy =  0.90625\n",
      "now loss =  0.1177035341029975  accuracy =  0.78125\n",
      "now loss =  0.07927796204007345  accuracy =  0.890625\n",
      "now loss =  0.10210804242702037  accuracy =  0.875\n",
      "now loss =  0.06845702496946815  accuracy =  0.890625\n",
      "now loss =  0.11433582131604894  accuracy =  0.859375\n",
      "now loss =  0.09276341624578863  accuracy =  0.859375\n",
      "now loss =  0.08664598902147906  accuracy =  0.9\n",
      "now loss =  0.07758942709357328  accuracy =  0.875\n",
      "now loss =  0.08489530422903149  accuracy =  0.90625\n",
      "now loss =  0.05715675269814699  accuracy =  0.921875\n",
      "now loss =  0.12035654366443573  accuracy =  0.859375\n",
      "now loss =  0.10632032140111103  accuracy =  0.796875\n",
      "now loss =  0.0951481377750869  accuracy =  0.875\n",
      "now loss =  0.1082520904350251  accuracy =  0.859375\n",
      "now loss =  0.0998241024822359  accuracy =  0.859375\n",
      "now loss =  0.0679499258429407  accuracy =  0.90625\n",
      "now loss =  0.09530300197808628  accuracy =  0.859375\n",
      "now loss =  0.08301081947432042  accuracy =  0.890625\n",
      "now loss =  0.06264492761363281  accuracy =  0.9375\n",
      "now loss =  0.0640485665882009  accuracy =  0.9375\n",
      "now loss =  0.08582479116645317  accuracy =  0.890625\n",
      "now loss =  0.09260954365881201  accuracy =  0.859375\n",
      "now loss =  0.0684582806376286  accuracy =  0.95\n",
      "now loss =  0.09839370825609328  accuracy =  0.859375\n",
      "now loss =  0.06649497320892654  accuracy =  0.953125\n",
      "now loss =  0.07633197609756576  accuracy =  0.90625\n",
      "now loss =  0.07788788937136724  accuracy =  0.90625\n",
      "now loss =  0.09708412726553878  accuracy =  0.828125\n",
      "now loss =  0.10972019115342939  accuracy =  0.828125\n",
      "now loss =  0.08195646026234008  accuracy =  0.875\n",
      "now loss =  0.09976347407731612  accuracy =  0.84375\n",
      "now loss =  0.10305109021975459  accuracy =  0.875\n",
      "now loss =  0.10186391347971724  accuracy =  0.84375\n",
      "now loss =  0.0999236647360067  accuracy =  0.859375\n",
      "now loss =  0.06393022808664375  accuracy =  0.921875\n",
      "now loss =  0.06919595810375315  accuracy =  0.90625\n",
      "now loss =  0.0740117167686301  accuracy =  0.90625\n",
      "now loss =  0.0717184644138587  accuracy =  0.90625\n",
      "now loss =  0.08745279285562152  accuracy =  0.85\n",
      "now loss =  0.08583183854974398  accuracy =  0.890625\n",
      "now loss =  0.10462546785973767  accuracy =  0.875\n",
      "now loss =  0.07363690406113584  accuracy =  0.9375\n",
      "now loss =  0.07431661031409455  accuracy =  0.921875\n",
      "now loss =  0.09278029218696887  accuracy =  0.859375\n",
      "now loss =  0.07541343864539032  accuracy =  0.859375\n",
      "now loss =  0.10881243809279115  accuracy =  0.859375\n",
      "now loss =  0.07042129445326634  accuracy =  0.90625\n",
      "now loss =  0.09361424014216031  accuracy =  0.859375\n",
      "now loss =  0.13790526733601605  accuracy =  0.78125\n",
      "now loss =  0.10642154993750812  accuracy =  0.84375\n",
      "now loss =  0.07677446714333136  accuracy =  0.90625\n",
      "now loss =  0.05900357794828249  accuracy =  0.9375\n",
      "now loss =  0.06157540904566758  accuracy =  0.921875\n",
      "now loss =  0.08131526261677292  accuracy =  0.890625\n",
      "now loss =  0.07250988268068528  accuracy =  0.925\n",
      "now loss =  0.07336536106588301  accuracy =  0.921875\n",
      "now loss =  0.10095964106613092  accuracy =  0.84375\n",
      "now loss =  0.06680148028344937  accuracy =  0.90625\n",
      "now loss =  0.09711780430535069  accuracy =  0.84375\n",
      "now loss =  0.08495705255182437  accuracy =  0.90625\n",
      "now loss =  0.08467733246622385  accuracy =  0.859375\n",
      "now loss =  0.07394062508008618  accuracy =  0.953125\n",
      "now loss =  0.08486204617136026  accuracy =  0.921875\n",
      "now loss =  0.08855055838463985  accuracy =  0.890625\n",
      "now loss =  0.0687575346292346  accuracy =  0.90625\n",
      "now loss =  0.07345034095668962  accuracy =  0.921875\n",
      "now loss =  0.09781565107923948  accuracy =  0.875\n",
      "now loss =  0.11020458086408995  accuracy =  0.796875\n",
      "now loss =  0.07604850243325005  accuracy =  0.921875\n",
      "now loss =  0.11427820950376699  accuracy =  0.8125\n",
      "now loss =  0.07317011636952611  accuracy =  0.875\n",
      "now loss =  0.09127498361688757  accuracy =  0.859375\n",
      "now loss =  0.0892252882915729  accuracy =  0.859375\n",
      "now loss =  0.09075301385012612  accuracy =  0.875\n",
      "now loss =  0.10246158893607012  accuracy =  0.84375\n",
      "now loss =  0.07519069739168743  accuracy =  0.90625\n",
      "now loss =  0.09397703108222485  accuracy =  0.921875\n",
      "now loss =  0.08812667048971073  accuracy =  0.875\n",
      "now loss =  0.09369478337061143  accuracy =  0.84375\n",
      "now loss =  0.08526386631462299  accuracy =  0.890625\n",
      "now loss =  0.09463083404923833  accuracy =  0.84375\n",
      "now loss =  0.06606263018892111  accuracy =  0.921875\n",
      "now loss =  0.12287838099158098  accuracy =  0.828125\n",
      "now loss =  0.07388537430056126  accuracy =  0.9375\n",
      "now loss =  0.06286165856942749  accuracy =  0.9375\n",
      "now loss =  0.04976316749746499  accuracy =  0.9375\n",
      "now loss =  0.10560005843620372  accuracy =  0.8\n",
      "now loss =  0.09069612701853025  accuracy =  0.859375\n",
      "now loss =  0.04487699140306202  accuracy =  0.96875\n",
      "now loss =  0.09034403006808418  accuracy =  0.875\n",
      "now loss =  0.07587477045737187  accuracy =  0.921875\n",
      "now loss =  0.07908312773917464  accuracy =  0.90625\n",
      "now loss =  0.10249117999869678  accuracy =  0.84375\n",
      "now loss =  0.08967677039447033  accuracy =  0.859375\n",
      "now loss =  0.11005961901358452  accuracy =  0.828125\n",
      "now loss =  0.07241048112177764  accuracy =  0.890625\n",
      "now loss =  0.11629214986207748  accuracy =  0.8125\n",
      "now loss =  0.09742283268090099  accuracy =  0.84375\n",
      "now loss =  0.06467416094451824  accuracy =  0.921875\n",
      "now loss =  0.08543385602152917  accuracy =  0.890625\n",
      "now loss =  0.06322253171423452  accuracy =  0.96875\n",
      "now loss =  0.11049342747709931  accuracy =  0.84375\n",
      "now loss =  0.0758594679183455  accuracy =  0.9\n",
      "now loss =  0.08296008193232751  accuracy =  0.90625\n",
      "now loss =  0.09608733172708261  accuracy =  0.875\n",
      "now loss =  0.10210063264370227  accuracy =  0.84375\n",
      "now loss =  0.07189235336185475  accuracy =  0.921875\n",
      "now loss =  0.07056307187447453  accuracy =  0.921875\n",
      "now loss =  0.0928283829674776  accuracy =  0.875\n",
      "now loss =  0.07075084695461496  accuracy =  0.9375\n",
      "now loss =  0.06750863482545894  accuracy =  0.9375\n",
      "now loss =  0.07927080412362669  accuracy =  0.90625\n",
      "now loss =  0.09993288692323225  accuracy =  0.84375\n",
      "now loss =  0.11156968483801538  accuracy =  0.8125\n",
      "now loss =  0.08390185470691988  accuracy =  0.875\n",
      "now loss =  0.08541115906572921  accuracy =  0.921875\n",
      "now loss =  0.09604816765429873  accuracy =  0.875\n",
      "now loss =  0.08033134581260432  accuracy =  0.890625\n",
      "now loss =  0.08356414866779696  accuracy =  0.85\n",
      "now loss =  0.11577794754141768  accuracy =  0.8125\n",
      "now loss =  0.07118498262568733  accuracy =  0.9375\n",
      "now loss =  0.06833131648034171  accuracy =  0.921875\n",
      "now loss =  0.10259678819243762  accuracy =  0.84375\n",
      "now loss =  0.07451225122095687  accuracy =  0.90625\n",
      "now loss =  0.09012498866232804  accuracy =  0.859375\n",
      "now loss =  0.08869495102740804  accuracy =  0.859375\n",
      "now loss =  0.0559290209214199  accuracy =  0.984375\n",
      "now loss =  0.07874171328867977  accuracy =  0.90625\n",
      "now loss =  0.0838076075505953  accuracy =  0.921875\n",
      "now loss =  0.10556120959707574  accuracy =  0.8125\n",
      "now loss =  0.07802408362793314  accuracy =  0.90625\n",
      "now loss =  0.09814410630007199  accuracy =  0.859375\n",
      "now loss =  0.09563426101562056  accuracy =  0.859375\n",
      "now loss =  0.06760823297575103  accuracy =  0.9375\n",
      "now loss =  0.09978013731072378  accuracy =  0.825\n",
      "now loss =  0.050610672060701335  accuracy =  0.96875\n",
      "now loss =  0.07915654121624234  accuracy =  0.890625\n",
      "now loss =  0.10906878397122338  accuracy =  0.828125\n",
      "now loss =  0.09779366410376739  accuracy =  0.859375\n",
      "now loss =  0.07449577281408822  accuracy =  0.921875\n",
      "now loss =  0.06929321464808408  accuracy =  0.90625\n",
      "now loss =  0.07642342508667935  accuracy =  0.875\n",
      "now loss =  0.0908447091069598  accuracy =  0.890625\n",
      "now loss =  0.0925762959520461  accuracy =  0.890625\n",
      "now loss =  0.08485103426037062  accuracy =  0.890625\n",
      "now loss =  0.09044200758721918  accuracy =  0.875\n",
      "now loss =  0.089013296685957  accuracy =  0.890625\n",
      "now loss =  0.07684934773536563  accuracy =  0.890625\n",
      "now loss =  0.07898636440416142  accuracy =  0.890625\n",
      "now loss =  0.1282928397021983  accuracy =  0.765625\n",
      "now loss =  0.0840629433091373  accuracy =  0.875\n",
      "now loss =  0.08185905005444485  accuracy =  0.90625\n",
      "now loss =  0.07715890620942817  accuracy =  0.890625\n",
      "now loss =  0.0848976375566694  accuracy =  0.90625\n",
      "now loss =  0.10554501010519696  accuracy =  0.859375\n",
      "now loss =  0.07504624657246793  accuracy =  0.921875\n",
      "now loss =  0.10373134192881578  accuracy =  0.859375\n",
      "now loss =  0.08088578196476358  accuracy =  0.90625\n",
      "now loss =  0.05064004876466713  accuracy =  0.953125\n",
      "now loss =  0.14661602922696437  accuracy =  0.71875\n",
      "now loss =  0.06744170219609383  accuracy =  0.890625\n",
      "now loss =  0.09336815989158669  accuracy =  0.890625\n",
      "now loss =  0.08395516109144  accuracy =  0.890625\n",
      "now loss =  0.08587761450071643  accuracy =  0.90625\n",
      "now loss =  0.04985730552295638  accuracy =  0.953125\n",
      "now loss =  0.08289184279650803  accuracy =  0.921875\n",
      "now loss =  0.11872976258704337  accuracy =  0.825\n",
      "now loss =  0.08130658506439531  accuracy =  0.921875\n",
      "now loss =  0.11105992362003518  accuracy =  0.8125\n",
      "now loss =  0.0739981780727711  accuracy =  0.921875\n",
      "now loss =  0.09340982163543782  accuracy =  0.84375\n",
      "now loss =  0.08815870998453457  accuracy =  0.90625\n",
      "now loss =  0.06408744032789115  accuracy =  0.921875\n",
      "now loss =  0.06806319322317467  accuracy =  0.921875\n",
      "now loss =  0.09767045352587245  accuracy =  0.859375\n",
      "now loss =  0.07312311091706984  accuracy =  0.890625\n",
      "now loss =  0.09196500882656171  accuracy =  0.859375\n",
      "now loss =  0.08753178267505193  accuracy =  0.890625\n",
      "now loss =  0.0887579387358357  accuracy =  0.890625\n",
      "now loss =  0.09744546201691581  accuracy =  0.84375\n",
      "now loss =  0.09497423654225404  accuracy =  0.890625\n",
      "now loss =  0.08594052632990629  accuracy =  0.90625\n",
      "now loss =  0.07408796189015804  accuracy =  0.875\n",
      "now loss =  0.10360721429251843  accuracy =  0.828125\n",
      "now loss =  0.08883656785008877  accuracy =  0.921875\n",
      "now loss =  0.0843829747736739  accuracy =  0.875\n",
      "now loss =  0.0792348048287472  accuracy =  0.90625\n",
      "now loss =  0.09371377904217898  accuracy =  0.859375\n",
      "now loss =  0.07947474614941605  accuracy =  0.9375\n",
      "now loss =  0.06409777410161566  accuracy =  0.9375\n",
      "now loss =  0.08004992619475218  accuracy =  0.90625\n",
      "now loss =  0.07343416723591845  accuracy =  0.921875\n",
      "now loss =  0.10303176195565569  accuracy =  0.859375\n",
      "now loss =  0.06755489269040049  accuracy =  0.921875\n",
      "now loss =  0.08320756591666699  accuracy =  0.890625\n",
      "now loss =  0.1078733977629786  accuracy =  0.84375\n",
      "now loss =  0.0940961989909179  accuracy =  0.828125\n",
      "now loss =  0.08141008368074627  accuracy =  0.859375\n",
      "now loss =  0.09666248668622016  accuracy =  0.775\n",
      "now loss =  0.06982825387054283  accuracy =  0.9375\n",
      "now loss =  0.09728084875128068  accuracy =  0.890625\n",
      "now loss =  0.0911131116012821  accuracy =  0.84375\n",
      "now loss =  0.07146452160872606  accuracy =  0.921875\n",
      "now loss =  0.05450578118205905  accuracy =  0.9375\n",
      "now loss =  0.09229361283444056  accuracy =  0.875\n",
      "now loss =  0.071328838239055  accuracy =  0.90625\n",
      "now loss =  0.09412889614233325  accuracy =  0.859375\n",
      "now loss =  0.10155956334255632  accuracy =  0.828125\n",
      "now loss =  0.08016701151128414  accuracy =  0.890625\n",
      "now loss =  0.0859670242600116  accuracy =  0.90625\n",
      "now loss =  0.08242791326096677  accuracy =  0.859375\n",
      "now loss =  0.1087489233466848  accuracy =  0.859375\n",
      "now loss =  0.0972871963053456  accuracy =  0.875\n",
      "now loss =  0.08135610442130377  accuracy =  0.921875\n",
      "now loss =  0.0969725837597672  accuracy =  0.85\n",
      "now loss =  0.08075706974576309  accuracy =  0.890625\n",
      "now loss =  0.0734914589257302  accuracy =  0.90625\n",
      "now loss =  0.08060039602168556  accuracy =  0.90625\n",
      "now loss =  0.09194140793413896  accuracy =  0.859375\n",
      "now loss =  0.08656397060207272  accuracy =  0.890625\n",
      "now loss =  0.05924451533069357  accuracy =  0.9375\n",
      "now loss =  0.06703070870664062  accuracy =  0.921875\n",
      "now loss =  0.10821036649390678  accuracy =  0.8125\n",
      "now loss =  0.07446072883996369  accuracy =  0.921875\n",
      "now loss =  0.06901960292518368  accuracy =  0.921875\n",
      "now loss =  0.1045050330678033  accuracy =  0.84375\n",
      "now loss =  0.08123308772063809  accuracy =  0.875\n",
      "now loss =  0.11743220389726741  accuracy =  0.84375\n",
      "now loss =  0.07193481208550641  accuracy =  0.921875\n",
      "now loss =  0.13270737085625015  accuracy =  0.765625\n",
      "now loss =  0.07124663914175593  accuracy =  0.9\n",
      "now loss =  0.1071371314162981  accuracy =  0.859375\n",
      "now loss =  0.10732827375080457  accuracy =  0.8125\n",
      "now loss =  0.08026101468079494  accuracy =  0.859375\n",
      "now loss =  0.08596845938879798  accuracy =  0.875\n",
      "now loss =  0.08656817373479365  accuracy =  0.875\n",
      "now loss =  0.06733319512191785  accuracy =  0.90625\n",
      "now loss =  0.08553264466072068  accuracy =  0.90625\n",
      "now loss =  0.07911416669087094  accuracy =  0.90625\n",
      "now loss =  0.075788472631492  accuracy =  0.921875\n",
      "now loss =  0.08043734216164955  accuracy =  0.90625\n",
      "now loss =  0.08365064517826432  accuracy =  0.890625\n",
      "now loss =  0.07128397212500456  accuracy =  0.921875\n",
      "now loss =  0.10650514180970796  accuracy =  0.8125\n",
      "now loss =  0.07879927508712488  accuracy =  0.890625\n",
      "now loss =  0.08653105138329639  accuracy =  0.859375\n",
      "now loss =  0.0947222409381369  accuracy =  0.875\n",
      "now loss =  0.08928427610296277  accuracy =  0.84375\n",
      "now loss =  0.08520716946722706  accuracy =  0.890625\n",
      "now loss =  0.09149018370018744  accuracy =  0.9375\n",
      "now loss =  0.07202597023708118  accuracy =  0.9375\n",
      "now loss =  0.07263415394657884  accuracy =  0.90625\n",
      "now loss =  0.12512460632481742  accuracy =  0.828125\n",
      "now loss =  0.07045997555908924  accuracy =  0.90625\n",
      "now loss =  0.0885683991023939  accuracy =  0.890625\n",
      "now loss =  0.08365748316327543  accuracy =  0.859375\n",
      "now loss =  0.09901259037284091  accuracy =  0.875\n",
      "now loss =  0.10111138894675888  accuracy =  0.84375\n",
      "now loss =  0.06396871905021949  accuracy =  0.921875\n",
      "now loss =  0.10708006139544488  accuracy =  0.859375\n",
      "now loss =  0.0776707803230548  accuracy =  0.875\n",
      "now loss =  0.07131347440323764  accuracy =  0.90625\n",
      "now loss =  0.06810773351973841  accuracy =  0.95\n",
      "now loss =  0.08917020134445627  accuracy =  0.90625\n",
      "now loss =  0.08404095574521872  accuracy =  0.859375\n",
      "now loss =  0.06220631925323966  accuracy =  0.9375\n",
      "now loss =  0.1210337625131999  accuracy =  0.8125\n",
      "now loss =  0.06937343732274326  accuracy =  0.921875\n",
      "now loss =  0.06893506247371844  accuracy =  0.921875\n",
      "now loss =  0.12398810484089157  accuracy =  0.796875\n",
      "now loss =  0.07821004855279308  accuracy =  0.90625\n",
      "now loss =  0.1064988692797347  accuracy =  0.84375\n",
      "now loss =  0.07082690201997091  accuracy =  0.90625\n",
      "now loss =  0.09526975089968578  accuracy =  0.828125\n",
      "now loss =  0.0750395556149394  accuracy =  0.890625\n",
      "now loss =  0.10368366658441644  accuracy =  0.828125\n",
      "now loss =  0.0718758462675119  accuracy =  0.921875\n",
      "now loss =  0.07692547716849746  accuracy =  0.921875\n",
      "now loss =  0.06654192193653376  accuracy =  0.925\n",
      "now loss =  0.07848517152072493  accuracy =  0.90625\n",
      "now loss =  0.10250833231997314  accuracy =  0.859375\n",
      "now loss =  0.08268198627153261  accuracy =  0.890625\n",
      "now loss =  0.08174525393225486  accuracy =  0.890625\n",
      "now loss =  0.07770891043648079  accuracy =  0.859375\n",
      "now loss =  0.0849761782746503  accuracy =  0.90625\n",
      "now loss =  0.08825934946542877  accuracy =  0.875\n",
      "now loss =  0.10744740700011882  accuracy =  0.8125\n",
      "now loss =  0.07110685917522998  accuracy =  0.921875\n",
      "now loss =  0.0862971010208305  accuracy =  0.890625\n",
      "now loss =  0.10996969110077023  accuracy =  0.828125\n",
      "now loss =  0.051505965915913554  accuracy =  0.96875\n",
      "now loss =  0.09379511586534102  accuracy =  0.875\n",
      "now loss =  0.10230241228043116  accuracy =  0.84375\n",
      "now loss =  0.06282189077680994  accuracy =  0.953125\n",
      "now loss =  0.09785661138878156  accuracy =  0.8\n",
      "now loss =  0.0819561613427269  accuracy =  0.875\n",
      "now loss =  0.07525369925392683  accuracy =  0.890625\n",
      "now loss =  0.09032728743039475  accuracy =  0.890625\n",
      "now loss =  0.09472796140771887  accuracy =  0.875\n",
      "now loss =  0.06801059678418295  accuracy =  0.890625\n",
      "now loss =  0.11155993247218984  accuracy =  0.828125\n",
      "now loss =  0.09099731120323078  accuracy =  0.859375\n",
      "now loss =  0.07203023349222931  accuracy =  0.90625\n",
      "now loss =  0.08194175203840853  accuracy =  0.90625\n",
      "now loss =  0.11196974627740774  accuracy =  0.875\n",
      "now loss =  0.08596229963334573  accuracy =  0.890625\n",
      "now loss =  0.0799058197319462  accuracy =  0.890625\n",
      "now loss =  0.09087996078884993  accuracy =  0.859375\n",
      "now loss =  0.07613778253274855  accuracy =  0.90625\n",
      "now loss =  0.09446704517350415  accuracy =  0.890625\n",
      "now loss =  0.07760007967742374  accuracy =  0.9\n",
      "now loss =  0.058380495849494396  accuracy =  0.921875\n",
      "now loss =  0.07117284920387972  accuracy =  0.921875\n",
      "now loss =  0.07887019159963518  accuracy =  0.890625\n",
      "now loss =  0.10047202209577916  accuracy =  0.84375\n",
      "now loss =  0.10922474391233264  accuracy =  0.84375\n",
      "now loss =  0.1277760441365309  accuracy =  0.859375\n",
      "now loss =  0.08348883212852506  accuracy =  0.875\n",
      "now loss =  0.0457061183672607  accuracy =  0.96875\n",
      "now loss =  0.1003686033562792  accuracy =  0.84375\n",
      "now loss =  0.08970410659502247  accuracy =  0.890625\n",
      "now loss =  0.0745992919874594  accuracy =  0.890625\n",
      "now loss =  0.09033758754719819  accuracy =  0.875\n",
      "now loss =  0.09234655182130858  accuracy =  0.890625\n",
      "now loss =  0.095228533769016  accuracy =  0.859375\n",
      "now loss =  0.08418879768906155  accuracy =  0.90625\n",
      "now loss =  0.08111530940850027  accuracy =  0.875\n",
      "now loss =  0.07663556760060586  accuracy =  0.890625\n",
      "now loss =  0.10668682459146907  accuracy =  0.8125\n",
      "now loss =  0.10653455891516901  accuracy =  0.84375\n",
      "now loss =  0.09388953773327643  accuracy =  0.875\n",
      "now loss =  0.07396348832648025  accuracy =  0.890625\n",
      "now loss =  0.10886212570386694  accuracy =  0.828125\n",
      "now loss =  0.06618145889971336  accuracy =  0.953125\n",
      "now loss =  0.07841845494465924  accuracy =  0.921875\n",
      "now loss =  0.07111619727643972  accuracy =  0.921875\n",
      "now loss =  0.13661893644360174  accuracy =  0.765625\n",
      "now loss =  0.07149869154006087  accuracy =  0.921875\n",
      "now loss =  0.07496194218221985  accuracy =  0.921875\n",
      "now loss =  0.08799399725184802  accuracy =  0.875\n",
      "now loss =  0.08867210648205147  accuracy =  0.890625\n",
      "now loss =  0.06580007289239828  accuracy =  0.921875\n",
      "now loss =  0.05285482176631723  accuracy =  0.95\n",
      "now loss =  0.09590796007208338  accuracy =  0.875\n",
      "now loss =  0.0748465696586  accuracy =  0.90625\n",
      "now loss =  0.10188037227938539  accuracy =  0.875\n",
      "now loss =  0.09579170742149279  accuracy =  0.859375\n",
      "now loss =  0.07977611327616606  accuracy =  0.875\n",
      "now loss =  0.09841479718862184  accuracy =  0.828125\n",
      "now loss =  0.07155615399438704  accuracy =  0.921875\n",
      "now loss =  0.08884007203981353  accuracy =  0.890625\n",
      "now loss =  0.09727917316438846  accuracy =  0.859375\n",
      "now loss =  0.07199928239878378  accuracy =  0.90625\n",
      "now loss =  0.07709239310283882  accuracy =  0.90625\n",
      "now loss =  0.07762440840332686  accuracy =  0.890625\n",
      "now loss =  0.08489680316683706  accuracy =  0.875\n",
      "now loss =  0.10021565617499509  accuracy =  0.84375\n",
      "now loss =  0.07562141460871796  accuracy =  0.90625\n",
      "now loss =  0.0773120070096188  accuracy =  0.9\n",
      "now loss =  0.07826383198150397  accuracy =  0.9375\n",
      "now loss =  0.07741079567460392  accuracy =  0.921875\n",
      "now loss =  0.10022313612232232  accuracy =  0.859375\n",
      "now loss =  0.07493615816210739  accuracy =  0.875\n",
      "now loss =  0.07892904062351835  accuracy =  0.875\n",
      "now loss =  0.09739121524514632  accuracy =  0.828125\n",
      "now loss =  0.08573568398458228  accuracy =  0.90625\n",
      "now loss =  0.07894693251452176  accuracy =  0.921875\n",
      "now loss =  0.10136652180340572  accuracy =  0.859375\n",
      "now loss =  0.07340181002911242  accuracy =  0.890625\n",
      "now loss =  0.07892189411970646  accuracy =  0.859375\n",
      "now loss =  0.07281310362325547  accuracy =  0.9375\n",
      "now loss =  0.09204111982747068  accuracy =  0.875\n",
      "now loss =  0.12095704710480987  accuracy =  0.8125\n",
      "now loss =  0.09285018619513807  accuracy =  0.84375\n",
      "now loss =  0.06302971532029422  accuracy =  0.925\n",
      "now loss =  0.056836041055269404  accuracy =  0.953125\n",
      "now loss =  0.07572980973534553  accuracy =  0.875\n",
      "now loss =  0.06762188388065395  accuracy =  0.921875\n",
      "now loss =  0.08376028580539965  accuracy =  0.875\n",
      "now loss =  0.112235381492645  accuracy =  0.828125\n",
      "now loss =  0.09969518254488807  accuracy =  0.859375\n",
      "now loss =  0.1090516964326245  accuracy =  0.859375\n",
      "now loss =  0.0882719842439203  accuracy =  0.90625\n",
      "now loss =  0.10111147514600517  accuracy =  0.859375\n",
      "now loss =  0.08477167706123406  accuracy =  0.890625\n",
      "now loss =  0.07249002353447025  accuracy =  0.921875\n",
      "now loss =  0.09284941152127664  accuracy =  0.859375\n",
      "now loss =  0.08040196627845672  accuracy =  0.90625\n",
      "now loss =  0.1095933575360224  accuracy =  0.828125\n",
      "now loss =  0.08355239224312153  accuracy =  0.890625\n",
      "now loss =  0.04541543728790387  accuracy =  0.95\n",
      "now loss =  0.07112000371442212  accuracy =  0.921875\n",
      "now loss =  0.06632689892984289  accuracy =  0.921875\n",
      "now loss =  0.08682774315356798  accuracy =  0.90625\n",
      "now loss =  0.054980782568960024  accuracy =  0.953125\n",
      "now loss =  0.10893932696332931  accuracy =  0.8125\n",
      "now loss =  0.09475565909494577  accuracy =  0.875\n",
      "now loss =  0.10626464493552254  accuracy =  0.828125\n",
      "now loss =  0.058222806047998434  accuracy =  0.9375\n",
      "now loss =  0.11802816962285739  accuracy =  0.78125\n",
      "now loss =  0.08251489157254374  accuracy =  0.890625\n",
      "now loss =  0.10392607719429582  accuracy =  0.8125\n",
      "now loss =  0.05270055089289606  accuracy =  0.953125\n",
      "now loss =  0.10658123134675163  accuracy =  0.90625\n",
      "now loss =  0.09056172758612135  accuracy =  0.859375\n",
      "now loss =  0.1053556653477927  accuracy =  0.859375\n",
      "now loss =  0.056025512744181195  accuracy =  0.95\n",
      "now loss =  0.08776145596401785  accuracy =  0.859375\n",
      "now loss =  0.07769111919457691  accuracy =  0.890625\n",
      "now loss =  0.13820978203630802  accuracy =  0.796875\n",
      "now loss =  0.10746389534896642  accuracy =  0.84375\n",
      "now loss =  0.08041542068199273  accuracy =  0.90625\n",
      "now loss =  0.07767513696513097  accuracy =  0.90625\n",
      "now loss =  0.09666646529847894  accuracy =  0.90625\n",
      "now loss =  0.10087643513563008  accuracy =  0.859375\n",
      "now loss =  0.10912119278206316  accuracy =  0.8125\n",
      "now loss =  0.057349893622948483  accuracy =  0.921875\n",
      "now loss =  0.0948031353070519  accuracy =  0.84375\n",
      "now loss =  0.05100818694793245  accuracy =  0.953125\n",
      "now loss =  0.07946551500573096  accuracy =  0.890625\n",
      "now loss =  0.08936573999152636  accuracy =  0.859375\n",
      "now loss =  0.05047808705153621  accuracy =  0.953125\n",
      "now loss =  0.08164899207096217  accuracy =  0.9\n",
      "now loss =  0.08892265124631656  accuracy =  0.890625\n",
      "now loss =  0.12414415440570602  accuracy =  0.78125\n",
      "now loss =  0.09200735317124717  accuracy =  0.875\n",
      "now loss =  0.07622425132270572  accuracy =  0.875\n",
      "now loss =  0.08795919417015514  accuracy =  0.890625\n",
      "now loss =  0.08513925958957191  accuracy =  0.9375\n",
      "now loss =  0.08518990318189609  accuracy =  0.859375\n",
      "now loss =  0.10080314618393371  accuracy =  0.859375\n",
      "now loss =  0.08537500209058653  accuracy =  0.890625\n",
      "now loss =  0.07254112993542408  accuracy =  0.9375\n",
      "now loss =  0.07808569446865202  accuracy =  0.875\n",
      "now loss =  0.0742878041165284  accuracy =  0.921875\n",
      "now loss =  0.08119618236612325  accuracy =  0.90625\n",
      "now loss =  0.09484940737974695  accuracy =  0.828125\n",
      "now loss =  0.07545999820170228  accuracy =  0.921875\n",
      "now loss =  0.0731975237337954  accuracy =  0.925\n",
      "now loss =  0.10576167884478649  accuracy =  0.859375\n",
      "now loss =  0.07550739793013778  accuracy =  0.921875\n",
      "now loss =  0.09605006243120756  accuracy =  0.890625\n",
      "now loss =  0.10163546332415362  accuracy =  0.84375\n",
      "now loss =  0.07849180002504336  accuracy =  0.859375\n",
      "now loss =  0.07284562565974906  accuracy =  0.875\n",
      "now loss =  0.08971392746426435  accuracy =  0.890625\n",
      "now loss =  0.09911079896621458  accuracy =  0.84375\n",
      "now loss =  0.05312131966945157  accuracy =  0.96875\n",
      "now loss =  0.12197230140120009  accuracy =  0.78125\n",
      "now loss =  0.08178156510162464  accuracy =  0.875\n",
      "now loss =  0.06605920443592515  accuracy =  0.921875\n",
      "now loss =  0.09416967418747073  accuracy =  0.875\n",
      "now loss =  0.057055652499155805  accuracy =  0.96875\n",
      "now loss =  0.0781918228076302  accuracy =  0.90625\n",
      "now loss =  0.10869893869665795  accuracy =  0.85\n",
      "now loss =  0.08738590206187069  accuracy =  0.875\n",
      "now loss =  0.09821019213571329  accuracy =  0.84375\n",
      "now loss =  0.05990515010004838  accuracy =  0.96875\n",
      "now loss =  0.08425391949119146  accuracy =  0.890625\n",
      "now loss =  0.09355225212311982  accuracy =  0.875\n",
      "now loss =  0.06518333930138707  accuracy =  0.9375\n",
      "now loss =  0.09824197014423111  accuracy =  0.828125\n",
      "now loss =  0.07507529420930337  accuracy =  0.90625\n",
      "now loss =  0.07434375867459674  accuracy =  0.921875\n",
      "now loss =  0.10803531127603389  accuracy =  0.828125\n",
      "now loss =  0.08727680736169208  accuracy =  0.875\n",
      "now loss =  0.07241727379867105  accuracy =  0.890625\n",
      "now loss =  0.09727532629091273  accuracy =  0.84375\n",
      "now loss =  0.0850747737264205  accuracy =  0.875\n",
      "now loss =  0.1019948321966955  accuracy =  0.875\n",
      "now loss =  0.08664539049862371  accuracy =  0.875\n",
      "now loss =  0.08201337885398138  accuracy =  0.84375\n",
      "now loss =  0.07198446442143175  accuracy =  0.890625\n",
      "now loss =  0.10966529611087286  accuracy =  0.828125\n",
      "now loss =  0.10054318616891736  accuracy =  0.875\n",
      "now loss =  0.11488558051500213  accuracy =  0.828125\n",
      "now loss =  0.07996599145578219  accuracy =  0.90625\n",
      "now loss =  0.08282095400951357  accuracy =  0.890625\n",
      "now loss =  0.09737345108769553  accuracy =  0.859375\n",
      "now loss =  0.10573719392049544  accuracy =  0.84375\n",
      "now loss =  0.0732324510307982  accuracy =  0.9375\n",
      "now loss =  0.07005834875151007  accuracy =  0.9375\n",
      "now loss =  0.08048153266089036  accuracy =  0.890625\n",
      "now loss =  0.08598239374616068  accuracy =  0.90625\n",
      "now loss =  0.07154484013405338  accuracy =  0.921875\n",
      "now loss =  0.08445885226357619  accuracy =  0.875\n",
      "now loss =  0.06028126454359314  accuracy =  0.925\n",
      "now loss =  0.0642445597861675  accuracy =  0.921875\n",
      "now loss =  0.07685440573752907  accuracy =  0.890625\n",
      "now loss =  0.08291088037735297  accuracy =  0.890625\n",
      "now loss =  0.10337082511042248  accuracy =  0.828125\n",
      "now loss =  0.0983653569060256  accuracy =  0.875\n",
      "now loss =  0.0742386293744385  accuracy =  0.90625\n",
      "now loss =  0.10833129419339568  accuracy =  0.84375\n",
      "now loss =  0.053785208306657575  accuracy =  0.921875\n",
      "now loss =  0.053690476982652974  accuracy =  0.953125\n",
      "now loss =  0.10140021020065683  accuracy =  0.859375\n",
      "now loss =  0.0845113910893773  accuracy =  0.90625\n",
      "now loss =  0.08607010060499985  accuracy =  0.84375\n",
      "now loss =  0.09783871110412677  accuracy =  0.90625\n",
      "now loss =  0.09342475151225686  accuracy =  0.875\n",
      "now loss =  0.10686311660980338  accuracy =  0.8125\n",
      "now loss =  0.08990231862659952  accuracy =  0.875\n",
      "now loss =  0.10730289058915306  accuracy =  0.828125\n",
      "now loss =  0.10451795625140722  accuracy =  0.84375\n",
      "now loss =  0.10555574173280041  accuracy =  0.8125\n",
      "now loss =  0.07896138431678035  accuracy =  0.890625\n",
      "now loss =  0.09424159045628612  accuracy =  0.875\n",
      "now loss =  0.051514032823016295  accuracy =  0.953125\n",
      "now loss =  0.06578819434457936  accuracy =  0.921875\n",
      "now loss =  0.0694320079220723  accuracy =  0.90625\n",
      "now loss =  0.07400595388864203  accuracy =  0.921875\n",
      "now loss =  0.09744699445602921  accuracy =  0.84375\n",
      "now loss =  0.06983835185432716  accuracy =  0.9375\n",
      "now loss =  0.09441031196553888  accuracy =  0.84375\n",
      "now loss =  0.10919960081278979  accuracy =  0.859375\n",
      "now loss =  0.09963578207769433  accuracy =  0.8125\n",
      "now loss =  0.06797298906209573  accuracy =  0.9375\n",
      "now loss =  0.09034118963212064  accuracy =  0.875\n",
      "now loss =  0.09178473161294112  accuracy =  0.875\n",
      "now loss =  0.09330050768430935  accuracy =  0.859375\n",
      "now loss =  0.08964522251211539  accuracy =  0.875\n",
      "now loss =  0.10373486394335624  accuracy =  0.828125\n",
      "now loss =  0.08361057145279202  accuracy =  0.84375\n",
      "now loss =  0.07076092186874965  accuracy =  0.9375\n",
      "now loss =  0.09816498877552086  accuracy =  0.84375\n",
      "now loss =  0.07127732022721729  accuracy =  0.890625\n",
      "now loss =  0.059175551436584865  accuracy =  0.953125\n",
      "now loss =  0.10029130361542496  accuracy =  0.875\n",
      "now loss =  0.11724707285828138  accuracy =  0.84375\n",
      "now loss =  0.07034432551378073  accuracy =  0.9375\n",
      "now loss =  0.096442823907578  accuracy =  0.84375\n",
      "now loss =  0.08369191751973987  accuracy =  0.90625\n",
      "now loss =  0.06756419273806295  accuracy =  0.953125\n",
      "now loss =  0.08739600213068469  accuracy =  0.875\n",
      "now loss =  0.11690926727651721  accuracy =  0.8125\n",
      "now loss =  0.07029053995408518  accuracy =  0.9375\n",
      "now loss =  0.09689681300341865  accuracy =  0.84375\n",
      "now loss =  0.08935294414318085  accuracy =  0.859375\n",
      "now loss =  0.07510382249229483  accuracy =  0.90625\n",
      "now loss =  0.07993884227772242  accuracy =  0.921875\n",
      "now loss =  0.0758842311602288  accuracy =  0.875\n",
      "now loss =  0.08038796426044068  accuracy =  0.921875\n",
      "now loss =  0.07504540746069598  accuracy =  0.875\n",
      "now loss =  0.07264797137891604  accuracy =  0.953125\n",
      "now loss =  0.10223542658863172  accuracy =  0.875\n",
      "now loss =  0.08632164277705283  accuracy =  0.890625\n",
      "now loss =  0.0937864848523671  accuracy =  0.890625\n",
      "now loss =  0.10310809878139382  accuracy =  0.828125\n",
      "now loss =  0.08803208027935074  accuracy =  0.890625\n",
      "now loss =  0.08288146482559923  accuracy =  0.925\n",
      "now loss =  0.07705965741621322  accuracy =  0.890625\n",
      "now loss =  0.06917632753121206  accuracy =  0.921875\n",
      "now loss =  0.09817478290703144  accuracy =  0.84375\n",
      "now loss =  0.06333144046070105  accuracy =  0.9375\n",
      "now loss =  0.10300678725731188  accuracy =  0.859375\n",
      "now loss =  0.08268839345441964  accuracy =  0.859375\n",
      "now loss =  0.10411433784054512  accuracy =  0.84375\n",
      "now loss =  0.07188447976486798  accuracy =  0.890625\n",
      "now loss =  0.08573335056560108  accuracy =  0.90625\n",
      "now loss =  0.07520915277412402  accuracy =  0.921875\n",
      "now loss =  0.08860756487088997  accuracy =  0.875\n",
      "now loss =  0.09410392647972948  accuracy =  0.859375\n",
      "now loss =  0.09835810495536804  accuracy =  0.875\n",
      "now loss =  0.10184095212684047  accuracy =  0.875\n",
      "now loss =  0.09164332848958212  accuracy =  0.875\n",
      "now loss =  0.08266617264220853  accuracy =  0.9\n",
      "now loss =  0.10344105116006298  accuracy =  0.859375\n",
      "now loss =  0.06656369992388832  accuracy =  0.9375\n",
      "now loss =  0.11116755377880311  accuracy =  0.828125\n",
      "now loss =  0.08453733898258711  accuracy =  0.875\n",
      "now loss =  0.07226809766688835  accuracy =  0.90625\n",
      "now loss =  0.09215600932403317  accuracy =  0.84375\n",
      "now loss =  0.10160473961474488  accuracy =  0.84375\n",
      "now loss =  0.07117446756330009  accuracy =  0.890625\n",
      "now loss =  0.08323786825678399  accuracy =  0.90625\n",
      "now loss =  0.07135426448789915  accuracy =  0.921875\n",
      "now loss =  0.08859242952417418  accuracy =  0.875\n",
      "now loss =  0.08340284143223198  accuracy =  0.890625\n",
      "now loss =  0.09739219214955788  accuracy =  0.84375\n",
      "now loss =  0.08604121595267955  accuracy =  0.890625\n",
      "now loss =  0.08308591313917388  accuracy =  0.9375\n",
      "now loss =  0.09156081135184807  accuracy =  0.85\n",
      "now loss =  0.08404078186624535  accuracy =  0.90625\n",
      "now loss =  0.09065064705994699  accuracy =  0.890625\n",
      "now loss =  0.11697541149943172  accuracy =  0.8125\n",
      "now loss =  0.11053599475228658  accuracy =  0.859375\n",
      "now loss =  0.06371585812019871  accuracy =  0.921875\n",
      "now loss =  0.10283128634298608  accuracy =  0.859375\n",
      "now loss =  0.06305043116600152  accuracy =  0.921875\n",
      "now loss =  0.04894920285501518  accuracy =  0.953125\n",
      "now loss =  0.10646742307553649  accuracy =  0.8125\n",
      "now loss =  0.09445969235846022  accuracy =  0.84375\n",
      "now loss =  0.08066764142059887  accuracy =  0.890625\n",
      "now loss =  0.09645480547594656  accuracy =  0.859375\n",
      "now loss =  0.058747622328149035  accuracy =  0.953125\n",
      "now loss =  0.08713651926094397  accuracy =  0.890625\n",
      "now loss =  0.08320591773388213  accuracy =  0.890625\n",
      "now loss =  0.08393865558077067  accuracy =  0.925\n",
      "now loss =  0.0864646330691282  accuracy =  0.875\n",
      "now loss =  0.1163287543684326  accuracy =  0.8125\n",
      "now loss =  0.07286184123671263  accuracy =  0.90625\n",
      "now loss =  0.08155456321039936  accuracy =  0.90625\n",
      "now loss =  0.09708804838036167  accuracy =  0.859375\n",
      "now loss =  0.07907347922543527  accuracy =  0.921875\n",
      "now loss =  0.12867074601134834  accuracy =  0.78125\n",
      "now loss =  0.10081258408992358  accuracy =  0.890625\n",
      "now loss =  0.06776983273508368  accuracy =  0.921875\n",
      "now loss =  0.08879862172104067  accuracy =  0.890625\n",
      "now loss =  0.08190324592674134  accuracy =  0.875\n",
      "now loss =  0.06688043067886909  accuracy =  0.890625\n",
      "now loss =  0.06778664961293868  accuracy =  0.9375\n",
      "now loss =  0.07567229335174216  accuracy =  0.90625\n",
      "now loss =  0.04544950826441917  accuracy =  0.96875\n",
      "now loss =  0.1196668598870422  accuracy =  0.8\n",
      "now loss =  0.07482232349317952  accuracy =  0.890625\n",
      "now loss =  0.07095738195713927  accuracy =  0.90625\n",
      "now loss =  0.07234708916896192  accuracy =  0.921875\n",
      "now loss =  0.10520712218851822  accuracy =  0.859375\n",
      "now loss =  0.08548629181482545  accuracy =  0.921875\n",
      "now loss =  0.10317164875337037  accuracy =  0.84375\n",
      "now loss =  0.09032011627066597  accuracy =  0.890625\n",
      "now loss =  0.07145355562010153  accuracy =  0.90625\n",
      "now loss =  0.0652095542800059  accuracy =  0.921875\n",
      "now loss =  0.07014274531224772  accuracy =  0.921875\n",
      "now loss =  0.13710093819942282  accuracy =  0.765625\n",
      "now loss =  0.09323405252327857  accuracy =  0.875\n",
      "now loss =  0.05448108232412524  accuracy =  0.953125\n",
      "now loss =  0.11100949175667331  accuracy =  0.828125\n",
      "now loss =  0.08570458417586538  accuracy =  0.84375\n",
      "now loss =  0.08022614923592562  accuracy =  0.95\n",
      "now loss =  0.07029518392069006  accuracy =  0.921875\n",
      "now loss =  0.08664640580321144  accuracy =  0.890625\n",
      "now loss =  0.09419655209643601  accuracy =  0.84375\n",
      "now loss =  0.07785139896412677  accuracy =  0.90625\n",
      "now loss =  0.07944186593960946  accuracy =  0.921875\n",
      "now loss =  0.1080002225698469  accuracy =  0.84375\n",
      "now loss =  0.05259649836437208  accuracy =  0.953125\n",
      "now loss =  0.09617598837220342  accuracy =  0.859375\n",
      "now loss =  0.08896227280189553  accuracy =  0.84375\n",
      "now loss =  0.09913091803196937  accuracy =  0.859375\n",
      "now loss =  0.09710512110671378  accuracy =  0.828125\n",
      "now loss =  0.07289866246649496  accuracy =  0.90625\n",
      "now loss =  0.11512089709521038  accuracy =  0.828125\n",
      "now loss =  0.07851540005956212  accuracy =  0.890625\n",
      "now loss =  0.08164311057770995  accuracy =  0.90625\n",
      "now loss =  0.09451236639545232  accuracy =  0.85\n",
      "now loss =  0.07058760355041975  accuracy =  0.890625\n",
      "now loss =  0.09917179801059414  accuracy =  0.890625\n",
      "now loss =  0.0888605980436803  accuracy =  0.859375\n",
      "now loss =  0.0839611782112559  accuracy =  0.859375\n",
      "now loss =  0.041086110741074336  accuracy =  0.96875\n",
      "now loss =  0.0913415977884187  accuracy =  0.828125\n",
      "now loss =  0.08653598699332143  accuracy =  0.875\n",
      "now loss =  0.09894790322199785  accuracy =  0.890625\n",
      "now loss =  0.08453044825622663  accuracy =  0.890625\n",
      "now loss =  0.09537578478450068  accuracy =  0.875\n",
      "now loss =  0.1106735503308427  accuracy =  0.84375\n",
      "now loss =  0.07464388591900961  accuracy =  0.921875\n",
      "now loss =  0.12195826677186923  accuracy =  0.828125\n",
      "now loss =  0.06945574951218933  accuracy =  0.921875\n",
      "now loss =  0.08696517874311811  accuracy =  0.890625\n",
      "now loss =  0.06621982913841783  accuracy =  0.925\n",
      "now loss =  0.06786337574158977  accuracy =  0.921875\n",
      "now loss =  0.08208417890650346  accuracy =  0.875\n",
      "now loss =  0.07945999570226081  accuracy =  0.9375\n",
      "now loss =  0.10921551983163426  accuracy =  0.828125\n",
      "now loss =  0.08017299178329676  accuracy =  0.90625\n",
      "now loss =  0.06418338678787167  accuracy =  0.921875\n",
      "now loss =  0.09440370362547976  accuracy =  0.859375\n",
      "now loss =  0.08987497098377245  accuracy =  0.828125\n",
      "now loss =  0.09437138858431665  accuracy =  0.890625\n",
      "now loss =  0.09701321138783946  accuracy =  0.90625\n",
      "now loss =  0.06076156796187879  accuracy =  0.921875\n",
      "now loss =  0.08670936086728868  accuracy =  0.84375\n",
      "now loss =  0.0987138188919268  accuracy =  0.859375\n",
      "now loss =  0.10579265528148545  accuracy =  0.875\n",
      "now loss =  0.0832254601865108  accuracy =  0.84375\n",
      "now loss =  0.07959755470264672  accuracy =  0.925\n",
      "now loss =  0.061773586442599865  accuracy =  0.921875\n",
      "now loss =  0.09796009388265911  accuracy =  0.84375\n",
      "now loss =  0.08873868246460093  accuracy =  0.84375\n",
      "now loss =  0.08311860157686006  accuracy =  0.890625\n",
      "now loss =  0.08110792441335142  accuracy =  0.921875\n",
      "now loss =  0.05643181581511708  accuracy =  0.9375\n",
      "now loss =  0.08970497554716642  accuracy =  0.859375\n",
      "now loss =  0.06164738085283836  accuracy =  0.9375\n",
      "now loss =  0.09334528387469765  accuracy =  0.890625\n",
      "now loss =  0.12447001890940274  accuracy =  0.78125\n",
      "now loss =  0.08739882745081992  accuracy =  0.90625\n",
      "now loss =  0.06557436185402266  accuracy =  0.921875\n",
      "now loss =  0.11363930030899874  accuracy =  0.84375\n",
      "now loss =  0.08899387437109854  accuracy =  0.921875\n",
      "now loss =  0.10329080417808112  accuracy =  0.84375\n",
      "now loss =  0.07039069218381186  accuracy =  0.9\n",
      "now loss =  0.13623449803463944  accuracy =  0.765625\n",
      "now loss =  0.09999655467964694  accuracy =  0.8125\n",
      "now loss =  0.07373925776755574  accuracy =  0.90625\n",
      "now loss =  0.06769818283611818  accuracy =  0.875\n",
      "now loss =  0.1126710907917503  accuracy =  0.90625\n",
      "now loss =  0.05784723740212902  accuracy =  0.96875\n",
      "now loss =  0.09200824682741567  accuracy =  0.890625\n",
      "now loss =  0.06073073332887895  accuracy =  0.9375\n",
      "now loss =  0.08261362439624681  accuracy =  0.890625\n",
      "now loss =  0.0727056284621303  accuracy =  0.921875\n",
      "now loss =  0.07021290005969252  accuracy =  0.921875\n",
      "now loss =  0.08675301031242723  accuracy =  0.875\n",
      "now loss =  0.0762789498660271  accuracy =  0.890625\n",
      "now loss =  0.09761912167166756  accuracy =  0.84375\n",
      "now loss =  0.12063520023029378  accuracy =  0.828125\n",
      "now loss =  0.05630935621637423  accuracy =  0.95\n",
      "now loss =  0.06471878868560853  accuracy =  0.9375\n",
      "now loss =  0.09578256996081763  accuracy =  0.875\n",
      "now loss =  0.08795712238110001  accuracy =  0.890625\n",
      "now loss =  0.0946437224164475  accuracy =  0.890625\n",
      "now loss =  0.06571894143060988  accuracy =  0.9375\n",
      "now loss =  0.09894112665558319  accuracy =  0.875\n",
      "now loss =  0.08660311858794523  accuracy =  0.875\n",
      "now loss =  0.07387030431676533  accuracy =  0.90625\n",
      "now loss =  0.11164216380989678  accuracy =  0.8125\n",
      "now loss =  0.0747796925893021  accuracy =  0.921875\n",
      "now loss =  0.09111787726931275  accuracy =  0.84375\n",
      "now loss =  0.0726247227304612  accuracy =  0.90625\n",
      "now loss =  0.1124160154769713  accuracy =  0.828125\n",
      "now loss =  0.11466943011714956  accuracy =  0.78125\n",
      "now loss =  0.05384280627402335  accuracy =  0.96875\n",
      "now loss =  0.07229558935071291  accuracy =  0.9\n",
      "now loss =  0.1044793384895486  accuracy =  0.8125\n",
      "now loss =  0.1089701450659185  accuracy =  0.859375\n",
      "now loss =  0.08601842971066065  accuracy =  0.90625\n",
      "now loss =  0.1042514633209045  accuracy =  0.828125\n",
      "now loss =  0.09970692834022016  accuracy =  0.828125\n",
      "now loss =  0.07127277610279804  accuracy =  0.90625\n",
      "now loss =  0.09233141498343275  accuracy =  0.859375\n",
      "now loss =  0.09511364556560666  accuracy =  0.84375\n",
      "now loss =  0.07474137005701631  accuracy =  0.90625\n",
      "now loss =  0.07794215052249978  accuracy =  0.890625\n",
      "now loss =  0.07015227747615096  accuracy =  0.90625\n",
      "now loss =  0.07371175568139296  accuracy =  0.890625\n",
      "now loss =  0.0913613211227926  accuracy =  0.90625\n",
      "now loss =  0.07279322105400857  accuracy =  0.921875\n",
      "now loss =  0.06561657517088108  accuracy =  0.9375\n",
      "now loss =  0.08581970099362776  accuracy =  0.9\n",
      "now loss =  0.07559566297123427  accuracy =  0.9375\n",
      "now loss =  0.0943743916341103  accuracy =  0.859375\n",
      "now loss =  0.07368102509148777  accuracy =  0.890625\n",
      "now loss =  0.13368342440294764  accuracy =  0.8125\n",
      "now loss =  0.07826433209617248  accuracy =  0.875\n",
      "now loss =  0.07175850891527946  accuracy =  0.921875\n",
      "now loss =  0.08687940099965463  accuracy =  0.84375\n",
      "now loss =  0.09703294547402525  accuracy =  0.828125\n",
      "now loss =  0.10037882289171092  accuracy =  0.859375\n",
      "now loss =  0.07600437233352314  accuracy =  0.921875\n",
      "now loss =  0.09231691624098212  accuracy =  0.859375\n",
      "now loss =  0.07882349043048115  accuracy =  0.890625\n",
      "now loss =  0.07988909743607703  accuracy =  0.9375\n",
      "now loss =  0.10241944810984878  accuracy =  0.890625\n",
      "now loss =  0.05767558216790317  accuracy =  0.921875\n",
      "now loss =  0.06895768273935184  accuracy =  0.925\n",
      "now loss =  0.09157310050217382  accuracy =  0.875\n",
      "now loss =  0.0575096040840634  accuracy =  0.921875\n",
      "now loss =  0.06673605737791327  accuracy =  0.9375\n",
      "now loss =  0.10589073181402447  accuracy =  0.859375\n",
      "now loss =  0.10181494453566606  accuracy =  0.859375\n",
      "now loss =  0.06282990184574533  accuracy =  0.921875\n",
      "now loss =  0.07723114319261025  accuracy =  0.90625\n",
      "now loss =  0.08787673068010783  accuracy =  0.890625\n",
      "now loss =  0.08073684023886102  accuracy =  0.90625\n",
      "now loss =  0.07186871922560806  accuracy =  0.90625\n",
      "now loss =  0.07925767578738968  accuracy =  0.890625\n",
      "now loss =  0.07262755528928949  accuracy =  0.90625\n",
      "now loss =  0.14029439867229151  accuracy =  0.75\n",
      "now loss =  0.09817614348129722  accuracy =  0.890625\n",
      "now loss =  0.09122429953376762  accuracy =  0.875\n",
      "now loss =  0.09810903671203464  accuracy =  0.825\n",
      "now loss =  0.1059755913680384  accuracy =  0.84375\n",
      "now loss =  0.08483299396859043  accuracy =  0.890625\n",
      "now loss =  0.06541197681671736  accuracy =  0.921875\n",
      "now loss =  0.08968279671668375  accuracy =  0.875\n",
      "now loss =  0.07160805415698386  accuracy =  0.921875\n",
      "now loss =  0.09131086430720212  accuracy =  0.84375\n",
      "now loss =  0.06706131694680248  accuracy =  0.90625\n",
      "now loss =  0.06865592290434226  accuracy =  0.921875\n",
      "now loss =  0.07968446848255897  accuracy =  0.90625\n",
      "now loss =  0.08579108843383051  accuracy =  0.875\n",
      "now loss =  0.08301292063966009  accuracy =  0.90625\n",
      "now loss =  0.11578658128178912  accuracy =  0.8125\n",
      "now loss =  0.0952653569160138  accuracy =  0.84375\n",
      "now loss =  0.08113185672233214  accuracy =  0.875\n",
      "now loss =  0.11406246576827835  accuracy =  0.828125\n",
      "now loss =  0.06340194255273372  accuracy =  0.925\n",
      "now loss =  0.0689515501645322  accuracy =  0.90625\n",
      "now loss =  0.10720054415614763  accuracy =  0.84375\n",
      "now loss =  0.09631161262882655  accuracy =  0.875\n",
      "now loss =  0.08979991943825254  accuracy =  0.890625\n",
      "now loss =  0.1258449418027647  accuracy =  0.765625\n",
      "now loss =  0.06766900709583525  accuracy =  0.90625\n",
      "now loss =  0.07648237708913616  accuracy =  0.921875\n",
      "now loss =  0.0707924306308451  accuracy =  0.9375\n",
      "now loss =  0.1127069309521268  accuracy =  0.828125\n",
      "now loss =  0.08258622195309862  accuracy =  0.90625\n",
      "now loss =  0.09279421584040627  accuracy =  0.890625\n",
      "now loss =  0.09700589708466142  accuracy =  0.859375\n",
      "now loss =  0.06973454504583756  accuracy =  0.90625\n",
      "now loss =  0.07494762277334778  accuracy =  0.921875\n",
      "now loss =  0.07418245378171698  accuracy =  0.921875\n",
      "now loss =  0.054540224191654316  accuracy =  0.95\n",
      "now loss =  0.08474936514279452  accuracy =  0.890625\n",
      "now loss =  0.07350049976982738  accuracy =  0.90625\n",
      "now loss =  0.07850111684847039  accuracy =  0.890625\n",
      "now loss =  0.08252378404610983  accuracy =  0.859375\n",
      "now loss =  0.10465010621242855  accuracy =  0.875\n",
      "now loss =  0.07864337886459616  accuracy =  0.890625\n",
      "now loss =  0.08230121662633066  accuracy =  0.90625\n",
      "now loss =  0.06553306382180848  accuracy =  0.921875\n",
      "now loss =  0.06547555703981772  accuracy =  0.953125\n",
      "now loss =  0.10819606973760364  accuracy =  0.84375\n",
      "now loss =  0.08359662194956688  accuracy =  0.859375\n",
      "now loss =  0.08743814019486892  accuracy =  0.890625\n",
      "now loss =  0.08869715963006301  accuracy =  0.921875\n",
      "now loss =  0.10442573312835565  accuracy =  0.8125\n",
      "now loss =  0.10498555601408585  accuracy =  0.8125\n",
      "now loss =  0.0867762810735524  accuracy =  0.875\n",
      "now loss =  0.0925376061117458  accuracy =  0.875\n",
      "now loss =  0.08410239299067827  accuracy =  0.875\n",
      "now loss =  0.11583401086674147  accuracy =  0.8125\n",
      "now loss =  0.08778306021224039  accuracy =  0.875\n",
      "now loss =  0.05604663600272612  accuracy =  0.921875\n",
      "now loss =  0.0673490059727985  accuracy =  0.875\n",
      "now loss =  0.09155706033443033  accuracy =  0.90625\n",
      "now loss =  0.11315331238465293  accuracy =  0.828125\n",
      "now loss =  0.071784400546782  accuracy =  0.921875\n",
      "now loss =  0.07037120291718765  accuracy =  0.9375\n",
      "now loss =  0.07544482764613049  accuracy =  0.90625\n",
      "now loss =  0.08603271631974335  accuracy =  0.890625\n",
      "now loss =  0.09915748844216896  accuracy =  0.859375\n",
      "now loss =  0.08686829826607351  accuracy =  0.890625\n",
      "now loss =  0.109793760687977  accuracy =  0.859375\n",
      "now loss =  0.06930024711196096  accuracy =  0.95\n",
      "now loss =  0.08465852398719811  accuracy =  0.875\n",
      "now loss =  0.10572309336341586  accuracy =  0.84375\n",
      "now loss =  0.09579734359408743  accuracy =  0.859375\n",
      "now loss =  0.05306470330927487  accuracy =  0.9375\n",
      "now loss =  0.08607318611216411  accuracy =  0.875\n",
      "now loss =  0.08220368905735764  accuracy =  0.90625\n",
      "now loss =  0.08535424446958684  accuracy =  0.890625\n",
      "now loss =  0.10147492597843599  accuracy =  0.828125\n",
      "now loss =  0.06463057277847613  accuracy =  0.953125\n",
      "now loss =  0.08110451099617913  accuracy =  0.90625\n",
      "now loss =  0.08066570725966964  accuracy =  0.921875\n",
      "now loss =  0.0692771390687853  accuracy =  0.9375\n",
      "now loss =  0.10839016287309683  accuracy =  0.828125\n",
      "now loss =  0.10097064427007472  accuracy =  0.859375\n",
      "now loss =  0.08321063090771671  accuracy =  0.875\n",
      "now loss =  0.10051886188863449  accuracy =  0.875\n",
      "now loss =  0.07365046569308119  accuracy =  0.890625\n",
      "now loss =  0.09997591826391308  accuracy =  0.84375\n",
      "now loss =  0.0691941202199681  accuracy =  0.90625\n",
      "now loss =  0.055895644881349904  accuracy =  0.921875\n",
      "now loss =  0.10188969607975676  accuracy =  0.859375\n",
      "now loss =  0.08646621435984173  accuracy =  0.890625\n",
      "now loss =  0.08169783436041582  accuracy =  0.90625\n",
      "now loss =  0.07757888547809705  accuracy =  0.890625\n",
      "now loss =  0.09334854260237894  accuracy =  0.875\n",
      "now loss =  0.09245193667559401  accuracy =  0.890625\n",
      "now loss =  0.10882745570548355  accuracy =  0.8125\n",
      "now loss =  0.10520756471671491  accuracy =  0.828125\n",
      "now loss =  0.08719477811650157  accuracy =  0.890625\n",
      "now loss =  0.07050263245721819  accuracy =  0.90625\n",
      "now loss =  0.09599414185548366  accuracy =  0.875\n",
      "now loss =  0.0700905906052836  accuracy =  0.925\n",
      "now loss =  0.08258213379225884  accuracy =  0.890625\n",
      "now loss =  0.0686211703674549  accuracy =  0.90625\n",
      "now loss =  0.07650017394406795  accuracy =  0.90625\n",
      "now loss =  0.09734419258448535  accuracy =  0.84375\n",
      "now loss =  0.08207447015164653  accuracy =  0.921875\n",
      "now loss =  0.0629874149791868  accuracy =  0.953125\n",
      "now loss =  0.07695565654405587  accuracy =  0.921875\n",
      "now loss =  0.08985584610188471  accuracy =  0.84375\n",
      "now loss =  0.09954884601660843  accuracy =  0.84375\n",
      "now loss =  0.0813224773319498  accuracy =  0.890625\n",
      "now loss =  0.09045461089132668  accuracy =  0.84375\n",
      "now loss =  0.09699489856286816  accuracy =  0.875\n",
      "now loss =  0.0894417477831953  accuracy =  0.859375\n",
      "now loss =  0.0813205633538791  accuracy =  0.90625\n",
      "now loss =  0.11348712053509058  accuracy =  0.828125\n",
      "now loss =  0.09429970404032337  accuracy =  0.85\n",
      "now loss =  0.10111066591124696  accuracy =  0.859375\n",
      "now loss =  0.1394724402635162  accuracy =  0.78125\n",
      "now loss =  0.09218126306036617  accuracy =  0.890625\n",
      "now loss =  0.05220398790534772  accuracy =  0.984375\n",
      "now loss =  0.06660064108158097  accuracy =  0.921875\n",
      "now loss =  0.08847732150670973  accuracy =  0.90625\n",
      "now loss =  0.05739854764051361  accuracy =  0.9375\n",
      "now loss =  0.10573966969021659  accuracy =  0.796875\n",
      "now loss =  0.06700931224871995  accuracy =  0.890625\n",
      "now loss =  0.08249918989906432  accuracy =  0.921875\n",
      "now loss =  0.10024790779815407  accuracy =  0.84375\n",
      "now loss =  0.09566306755084146  accuracy =  0.859375\n",
      "now loss =  0.08019761009250498  accuracy =  0.875\n",
      "now loss =  0.09081303830300791  accuracy =  0.921875\n",
      "now loss =  0.07085557245919753  accuracy =  0.890625\n",
      "now loss =  0.07811432112119679  accuracy =  0.9\n",
      "now loss =  0.0698252852376994  accuracy =  0.9375\n",
      "now loss =  0.09534546226587817  accuracy =  0.84375\n",
      "now loss =  0.07503519534386673  accuracy =  0.921875\n",
      "now loss =  0.056524895129936324  accuracy =  0.9375\n",
      "now loss =  0.09347681333323545  accuracy =  0.859375\n",
      "now loss =  0.08631283971428663  accuracy =  0.875\n",
      "now loss =  0.11691578384558227  accuracy =  0.84375\n",
      "now loss =  0.0721861164249823  accuracy =  0.921875\n",
      "now loss =  0.0848651812278032  accuracy =  0.90625\n",
      "now loss =  0.0762245421019064  accuracy =  0.890625\n",
      "now loss =  0.1160806806136078  accuracy =  0.8125\n",
      "now loss =  0.060077006396264634  accuracy =  0.921875\n",
      "now loss =  0.10783710101375404  accuracy =  0.828125\n",
      "now loss =  0.09097001816415395  accuracy =  0.890625\n",
      "now loss =  0.06977527754790418  accuracy =  0.921875\n",
      "now loss =  0.10975179465222254  accuracy =  0.85\n",
      "now loss =  0.08656195410091985  accuracy =  0.890625\n",
      "now loss =  0.09632250181013065  accuracy =  0.859375\n",
      "now loss =  0.05847299171108343  accuracy =  0.96875\n",
      "now loss =  0.08159832339446814  accuracy =  0.90625\n",
      "now loss =  0.09709709961786694  accuracy =  0.828125\n",
      "now loss =  0.08633132497407293  accuracy =  0.890625\n",
      "now loss =  0.06308017953694108  accuracy =  0.921875\n",
      "now loss =  0.09678292201582059  accuracy =  0.84375\n",
      "now loss =  0.09488925592892432  accuracy =  0.890625\n",
      "now loss =  0.09142129772886504  accuracy =  0.84375\n",
      "now loss =  0.08181536452818616  accuracy =  0.875\n",
      "now loss =  0.09585355271113462  accuracy =  0.859375\n",
      "now loss =  0.08535039854785871  accuracy =  0.890625\n",
      "now loss =  0.0603917078919401  accuracy =  0.9375\n",
      "now loss =  0.11005800108501382  accuracy =  0.84375\n",
      "now loss =  0.08953555276805909  accuracy =  0.85\n",
      "now loss =  0.06881618954346515  accuracy =  0.90625\n",
      "now loss =  0.08772355048920469  accuracy =  0.875\n",
      "now loss =  0.10821031289503338  accuracy =  0.84375\n",
      "now loss =  0.08854384135653966  accuracy =  0.875\n",
      "now loss =  0.07315148378851685  accuracy =  0.921875\n",
      "now loss =  0.10105356770811313  accuracy =  0.84375\n",
      "now loss =  0.08638160217244571  accuracy =  0.875\n",
      "now loss =  0.09052325474971612  accuracy =  0.890625\n",
      "now loss =  0.07534227933439985  accuracy =  0.90625\n",
      "now loss =  0.055782639112373134  accuracy =  0.953125\n",
      "now loss =  0.09393148672670631  accuracy =  0.890625\n",
      "now loss =  0.0808095847874734  accuracy =  0.890625\n",
      "now loss =  0.10104302359057718  accuracy =  0.84375\n",
      "now loss =  0.10103427010343209  accuracy =  0.859375\n",
      "now loss =  0.08891624250282851  accuracy =  0.859375\n",
      "now loss =  0.06299284543627441  accuracy =  0.95\n",
      "now loss =  0.11411054520923541  accuracy =  0.828125\n",
      "now loss =  0.09075684142294907  accuracy =  0.890625\n",
      "now loss =  0.08379657685315259  accuracy =  0.859375\n",
      "now loss =  0.08510847707206583  accuracy =  0.890625\n",
      "now loss =  0.08308449656839964  accuracy =  0.875\n",
      "now loss =  0.06029749385623566  accuracy =  0.921875\n",
      "now loss =  0.10215825507650349  accuracy =  0.890625\n",
      "now loss =  0.06690938090639761  accuracy =  0.921875\n",
      "now loss =  0.07710605018434845  accuracy =  0.921875\n",
      "now loss =  0.10596093115854024  accuracy =  0.859375\n",
      "now loss =  0.08674187716391855  accuracy =  0.890625\n",
      "now loss =  0.0815743048183166  accuracy =  0.890625\n",
      "now loss =  0.08892719263932375  accuracy =  0.859375\n",
      "now loss =  0.0966977121830356  accuracy =  0.859375\n",
      "now loss =  0.056513671608771236  accuracy =  0.953125\n",
      "now loss =  0.09434870568631705  accuracy =  0.825\n",
      "now loss =  0.07450505294774462  accuracy =  0.875\n",
      "now loss =  0.07848736413704016  accuracy =  0.890625\n",
      "now loss =  0.07334278116984268  accuracy =  0.953125\n",
      "now loss =  0.09826374249980112  accuracy =  0.859375\n",
      "now loss =  0.07899016381075838  accuracy =  0.921875\n",
      "now loss =  0.08455100940397105  accuracy =  0.875\n",
      "now loss =  0.08690856888903356  accuracy =  0.90625\n",
      "now loss =  0.10619910359258294  accuracy =  0.8125\n",
      "now loss =  0.08300853003827527  accuracy =  0.890625\n",
      "now loss =  0.0717038356264253  accuracy =  0.890625\n",
      "now loss =  0.11271652207233662  accuracy =  0.875\n",
      "now loss =  0.07553273474664515  accuracy =  0.921875\n",
      "now loss =  0.07997574843275336  accuracy =  0.890625\n",
      "now loss =  0.10366089422869298  accuracy =  0.828125\n",
      "now loss =  0.0818482187398754  accuracy =  0.9375\n",
      "now loss =  0.08847818964249576  accuracy =  0.9\n",
      "now loss =  0.07693760421284646  accuracy =  0.890625\n",
      "now loss =  0.061883013932850776  accuracy =  0.9375\n",
      "now loss =  0.07230290726468343  accuracy =  0.921875\n",
      "now loss =  0.0656988761050749  accuracy =  0.9375\n",
      "now loss =  0.07083965333660437  accuracy =  0.890625\n",
      "now loss =  0.1292680503248898  accuracy =  0.8125\n",
      "now loss =  0.061134787852133235  accuracy =  0.9375\n",
      "now loss =  0.08431125178243905  accuracy =  0.875\n",
      "now loss =  0.09170038147623036  accuracy =  0.875\n",
      "now loss =  0.07923470483460215  accuracy =  0.890625\n",
      "now loss =  0.10993901385352134  accuracy =  0.828125\n",
      "now loss =  0.09224838564496926  accuracy =  0.875\n",
      "now loss =  0.060818396202130434  accuracy =  0.9375\n",
      "now loss =  0.13084570585954924  accuracy =  0.828125\n",
      "now loss =  0.08134863171713494  accuracy =  0.890625\n",
      "now loss =  0.12244915464933817  accuracy =  0.8\n",
      "now loss =  0.07292969250881927  accuracy =  0.9375\n",
      "now loss =  0.06736052966704562  accuracy =  0.953125\n",
      "now loss =  0.07911440635599593  accuracy =  0.90625\n",
      "now loss =  0.10855788878111246  accuracy =  0.828125\n",
      "now loss =  0.08758667882078708  accuracy =  0.859375\n",
      "now loss =  0.08633739014759811  accuracy =  0.890625\n",
      "now loss =  0.08153159501524869  accuracy =  0.859375\n",
      "now loss =  0.0735546829743518  accuracy =  0.921875\n",
      "now loss =  0.08232861126348602  accuracy =  0.859375\n",
      "now loss =  0.12871900751465076  accuracy =  0.8125\n",
      "now loss =  0.09724276834922188  accuracy =  0.859375\n",
      "now loss =  0.09271425729262359  accuracy =  0.90625\n",
      "now loss =  0.08007891386213498  accuracy =  0.875\n",
      "now loss =  0.08682051885459476  accuracy =  0.875\n",
      "now loss =  0.07678613526551642  accuracy =  0.890625\n",
      "now loss =  0.06508953287333684  accuracy =  0.95\n",
      "now loss =  0.10867729051985833  accuracy =  0.8125\n",
      "now loss =  0.0817628240172077  accuracy =  0.875\n",
      "now loss =  0.07985483703283419  accuracy =  0.90625\n",
      "now loss =  0.08226288846078987  accuracy =  0.90625\n",
      "now loss =  0.09708287346345759  accuracy =  0.84375\n",
      "now loss =  0.09074770645428906  accuracy =  0.90625\n",
      "now loss =  0.08928634889384543  accuracy =  0.859375\n",
      "now loss =  0.0826965224600926  accuracy =  0.890625\n",
      "now loss =  0.08397936041067777  accuracy =  0.890625\n",
      "now loss =  0.08328004157037344  accuracy =  0.875\n",
      "now loss =  0.1088133193693773  accuracy =  0.828125\n",
      "now loss =  0.07577429496296387  accuracy =  0.90625\n",
      "now loss =  0.07732958137148174  accuracy =  0.90625\n",
      "now loss =  0.07773901946837797  accuracy =  0.921875\n",
      "now loss =  0.07334922317465992  accuracy =  0.921875\n",
      "now loss =  0.0769686369342373  accuracy =  0.9\n",
      "now loss =  0.07245906471910997  accuracy =  0.90625\n",
      "now loss =  0.07804178576907997  accuracy =  0.90625\n",
      "now loss =  0.06270721103812729  accuracy =  0.90625\n",
      "now loss =  0.11596081258534455  accuracy =  0.859375\n",
      "now loss =  0.11369003862833302  accuracy =  0.828125\n",
      "now loss =  0.10424065273940747  accuracy =  0.859375\n",
      "now loss =  0.0649942407913203  accuracy =  0.9375\n",
      "now loss =  0.1012007715536417  accuracy =  0.921875\n",
      "now loss =  0.08323505621602098  accuracy =  0.859375\n",
      "now loss =  0.07364898738159881  accuracy =  0.875\n",
      "now loss =  0.07589467117068073  accuracy =  0.9375\n",
      "now loss =  0.08112922245544649  accuracy =  0.875\n",
      "now loss =  0.10446455054715748  accuracy =  0.828125\n",
      "now loss =  0.07104100499761704  accuracy =  0.90625\n",
      "now loss =  0.08644249327595524  accuracy =  0.90625\n",
      "now loss =  0.07119079652736256  accuracy =  0.9\n",
      "now loss =  0.08284602619212252  accuracy =  0.90625\n",
      "now loss =  0.10938134528304802  accuracy =  0.84375\n",
      "now loss =  0.07978873727928165  accuracy =  0.921875\n",
      "now loss =  0.0800376169474981  accuracy =  0.875\n",
      "now loss =  0.10392350453437615  accuracy =  0.859375\n",
      "now loss =  0.1149124171644898  accuracy =  0.8125\n",
      "now loss =  0.05725977006521982  accuracy =  0.953125\n",
      "now loss =  0.07423869943143716  accuracy =  0.890625\n",
      "now loss =  0.06927037135164969  accuracy =  0.921875\n",
      "now loss =  0.10187110290944909  accuracy =  0.875\n",
      "now loss =  0.06819356997911137  accuracy =  0.921875\n",
      "now loss =  0.08812894898097401  accuracy =  0.890625\n",
      "now loss =  0.09904782031647996  accuracy =  0.859375\n",
      "now loss =  0.07290406991328657  accuracy =  0.90625\n",
      "now loss =  0.09687013667321794  accuracy =  0.84375\n",
      "now loss =  0.06555095378677885  accuracy =  0.95\n",
      "now loss =  0.09693288386354237  accuracy =  0.84375\n",
      "now loss =  0.09063863538237116  accuracy =  0.875\n",
      "now loss =  0.09128973110747915  accuracy =  0.921875\n",
      "now loss =  0.07149709632612143  accuracy =  0.890625\n",
      "now loss =  0.07436616712534537  accuracy =  0.90625\n",
      "now loss =  0.07179288827958502  accuracy =  0.90625\n",
      "now loss =  0.06615029009100315  accuracy =  0.921875\n",
      "now loss =  0.08635873045386522  accuracy =  0.859375\n",
      "now loss =  0.0669581164948963  accuracy =  0.953125\n",
      "now loss =  0.1066932628932475  accuracy =  0.859375\n",
      "now loss =  0.11172907231487539  accuracy =  0.828125\n",
      "now loss =  0.10210661349159564  accuracy =  0.828125\n",
      "now loss =  0.09549531152265597  accuracy =  0.875\n",
      "now loss =  0.0848050614983572  accuracy =  0.890625\n",
      "now loss =  0.07390914486703312  accuracy =  0.890625\n",
      "now loss =  0.07974296551992216  accuracy =  0.925\n",
      "now loss =  0.05031527850238755  accuracy =  0.96875\n",
      "now loss =  0.06218457847987384  accuracy =  0.953125\n",
      "now loss =  0.09902095447516834  accuracy =  0.859375\n",
      "now loss =  0.06445707028546313  accuracy =  0.9375\n",
      "now loss =  0.07757593000410476  accuracy =  0.90625\n",
      "now loss =  0.09663348804580026  accuracy =  0.921875\n",
      "now loss =  0.08382995487319311  accuracy =  0.859375\n",
      "now loss =  0.1283221259087956  accuracy =  0.75\n",
      "now loss =  0.10631825345372556  accuracy =  0.828125\n",
      "now loss =  0.08611705028185634  accuracy =  0.875\n",
      "now loss =  0.07792166711787014  accuracy =  0.90625\n",
      "now loss =  0.08873360650595535  accuracy =  0.859375\n",
      "now loss =  0.06660452076563891  accuracy =  0.953125\n",
      "now loss =  0.11298631085987826  accuracy =  0.84375\n",
      "now loss =  0.06384856834077214  accuracy =  0.921875\n",
      "now loss =  0.11566463648728757  accuracy =  0.8\n",
      "now loss =  0.10164364100980602  accuracy =  0.796875\n",
      "now loss =  0.11687248665968336  accuracy =  0.8125\n",
      "now loss =  0.07775354505149881  accuracy =  0.90625\n",
      "now loss =  0.1311154583801185  accuracy =  0.8125\n",
      "now loss =  0.06102346190234011  accuracy =  0.921875\n",
      "now loss =  0.08017898252202102  accuracy =  0.890625\n",
      "now loss =  0.10127381980499342  accuracy =  0.8125\n",
      "now loss =  0.06334374827012762  accuracy =  0.921875\n",
      "now loss =  0.07475819339416018  accuracy =  0.90625\n",
      "now loss =  0.1066995345363635  accuracy =  0.875\n",
      "now loss =  0.0723798600556866  accuracy =  0.921875\n",
      "now loss =  0.06607977638573459  accuracy =  0.953125\n",
      "now loss =  0.09992290520814259  accuracy =  0.859375\n",
      "now loss =  0.07292211493781464  accuracy =  0.890625\n",
      "now loss =  0.07492230998699952  accuracy =  0.90625\n",
      "now loss =  0.07089844821952193  accuracy =  0.9\n",
      "now loss =  0.09348928344556598  accuracy =  0.875\n",
      "now loss =  0.05904042117173383  accuracy =  0.9375\n",
      "now loss =  0.07889917512553027  accuracy =  0.890625\n",
      "now loss =  0.06366841370684417  accuracy =  0.921875\n",
      "now loss =  0.08001506579753737  accuracy =  0.875\n",
      "now loss =  0.09393316041265004  accuracy =  0.875\n",
      "now loss =  0.072161529131737  accuracy =  0.90625\n",
      "now loss =  0.09541859301523223  accuracy =  0.875\n",
      "now loss =  0.10006812815668936  accuracy =  0.84375\n",
      "now loss =  0.09135214666745572  accuracy =  0.890625\n",
      "now loss =  0.09979734058102636  accuracy =  0.84375\n",
      "now loss =  0.08993976861827141  accuracy =  0.921875\n",
      "now loss =  0.07465187975990903  accuracy =  0.890625\n",
      "now loss =  0.09939936428808636  accuracy =  0.875\n",
      "now loss =  0.11725483571809345  accuracy =  0.8125\n",
      "now loss =  0.08021011947146026  accuracy =  0.875\n",
      "now loss =  0.10427303778628201  accuracy =  0.84375\n",
      "now loss =  0.09237465335825155  accuracy =  0.90625\n",
      "now loss =  0.10834167134767922  accuracy =  0.859375\n",
      "now loss =  0.07965021318639605  accuracy =  0.890625\n",
      "now loss =  0.06565230924147565  accuracy =  0.9375\n",
      "now loss =  0.0773579799637226  accuracy =  0.859375\n",
      "now loss =  0.059864593142202056  accuracy =  0.9375\n",
      "now loss =  0.0753082885905936  accuracy =  0.90625\n",
      "now loss =  0.03852818271961034  accuracy =  0.96875\n",
      "now loss =  0.08188566921838979  accuracy =  0.90625\n",
      "now loss =  0.1224296732062821  accuracy =  0.765625\n",
      "now loss =  0.10014515823133988  accuracy =  0.84375\n",
      "now loss =  0.1012039258189174  accuracy =  0.84375\n",
      "now loss =  0.10326489624010239  accuracy =  0.859375\n",
      "now loss =  0.08656855454083508  accuracy =  0.890625\n",
      "now loss =  0.07852253937438566  accuracy =  0.95\n",
      "now loss =  0.1278366078775567  accuracy =  0.796875\n",
      "now loss =  0.07987425287783176  accuracy =  0.90625\n",
      "now loss =  0.054466069786176394  accuracy =  0.96875\n",
      "now loss =  0.08379627807601012  accuracy =  0.875\n",
      "now loss =  0.06932887740556923  accuracy =  0.921875\n",
      "now loss =  0.05829716197399446  accuracy =  0.9375\n",
      "now loss =  0.10017747047465397  accuracy =  0.859375\n",
      "now loss =  0.10752337277470281  accuracy =  0.84375\n",
      "now loss =  0.08700575284468696  accuracy =  0.875\n",
      "now loss =  0.06960281218757638  accuracy =  0.921875\n",
      "now loss =  0.0743427583533276  accuracy =  0.890625\n",
      "now loss =  0.10340128869550798  accuracy =  0.84375\n",
      "now loss =  0.09501951287879751  accuracy =  0.890625\n",
      "now loss =  0.09140491957368022  accuracy =  0.84375\n",
      "now loss =  0.09101306517641802  accuracy =  0.875\n",
      "now loss =  0.07889837637943513  accuracy =  0.9\n",
      "now loss =  0.08953518371090467  accuracy =  0.875\n",
      "now loss =  0.08272892993628678  accuracy =  0.859375\n",
      "now loss =  0.10687689362677374  accuracy =  0.859375\n",
      "now loss =  0.07933499586161524  accuracy =  0.875\n",
      "now loss =  0.0985696581091387  accuracy =  0.84375\n",
      "now loss =  0.07873024529777325  accuracy =  0.921875\n",
      "now loss =  0.08730252061202926  accuracy =  0.890625\n",
      "now loss =  0.07911719000596323  accuracy =  0.921875\n",
      "now loss =  0.0931007847331293  accuracy =  0.859375\n",
      "now loss =  0.08363136024690213  accuracy =  0.890625\n",
      "now loss =  0.08850800248446258  accuracy =  0.890625\n",
      "now loss =  0.07526103792524842  accuracy =  0.921875\n",
      "now loss =  0.08761838847467643  accuracy =  0.875\n",
      "now loss =  0.09184886535775091  accuracy =  0.859375\n",
      "now loss =  0.07261259911364437  accuracy =  0.875\n",
      "now loss =  0.06945168360118435  accuracy =  0.95\n",
      "now loss =  0.07567024751577806  accuracy =  0.921875\n",
      "now loss =  0.10060077253838884  accuracy =  0.84375\n",
      "now loss =  0.1019182313618564  accuracy =  0.828125\n",
      "now loss =  0.07717947563735267  accuracy =  0.90625\n",
      "now loss =  0.06959180410750634  accuracy =  0.921875\n",
      "now loss =  0.08855894044513829  accuracy =  0.84375\n",
      "now loss =  0.07024596957035355  accuracy =  0.9375\n",
      "now loss =  0.11155716098998342  accuracy =  0.8125\n",
      "now loss =  0.09598410763134  accuracy =  0.890625\n",
      "now loss =  0.09808109619963432  accuracy =  0.859375\n",
      "now loss =  0.08368351892975096  accuracy =  0.875\n",
      "now loss =  0.10907057833762723  accuracy =  0.84375\n",
      "now loss =  0.08043913290835669  accuracy =  0.890625\n",
      "now loss =  0.05224675936973369  accuracy =  0.953125\n",
      "now loss =  0.09030486612816885  accuracy =  0.859375\n",
      "now loss =  0.08119246183396497  accuracy =  0.9\n",
      "now loss =  0.07218634959203932  accuracy =  0.921875\n",
      "now loss =  0.0792608611203014  accuracy =  0.875\n",
      "now loss =  0.09470994815351261  accuracy =  0.890625\n",
      "now loss =  0.08191932472141525  accuracy =  0.890625\n",
      "now loss =  0.0768161655150143  accuracy =  0.9375\n",
      "now loss =  0.07798259996889466  accuracy =  0.890625\n",
      "now loss =  0.09808819442234348  accuracy =  0.875\n",
      "now loss =  0.0766636170925704  accuracy =  0.859375\n",
      "now loss =  0.09947649544073592  accuracy =  0.8125\n",
      "now loss =  0.08770236508957402  accuracy =  0.859375\n",
      "now loss =  0.10005434580518277  accuracy =  0.875\n",
      "now loss =  0.12572486082868847  accuracy =  0.796875\n",
      "now loss =  0.06878356246185963  accuracy =  0.921875\n",
      "now loss =  0.06293239679081825  accuracy =  0.9375\n",
      "now loss =  0.07966271105984817  accuracy =  0.921875\n",
      "now loss =  0.09008906791579366  accuracy =  0.875\n",
      "now loss =  0.10234645674264325  accuracy =  0.84375\n",
      "now loss =  0.07428224573331654  accuracy =  0.921875\n",
      "now loss =  0.07418920803611151  accuracy =  0.921875\n",
      "now loss =  0.06987287100007702  accuracy =  0.921875\n",
      "now loss =  0.10067538057787254  accuracy =  0.84375\n",
      "now loss =  0.1039755312734468  accuracy =  0.828125\n",
      "now loss =  0.06559085994688657  accuracy =  0.9375\n",
      "now loss =  0.10233661590042101  accuracy =  0.859375\n",
      "now loss =  0.07802357780686882  accuracy =  0.890625\n",
      "now loss =  0.0666665206073916  accuracy =  0.90625\n",
      "now loss =  0.08914916742533097  accuracy =  0.875\n",
      "now loss =  0.09493126384501796  accuracy =  0.828125\n",
      "now loss =  0.10188802858649255  accuracy =  0.890625\n",
      "now loss =  0.07680152385052505  accuracy =  0.875\n",
      "now loss =  0.08755919286681688  accuracy =  0.875\n",
      "now loss =  0.07267133455051891  accuracy =  0.925\n",
      "now loss =  0.08825928397254376  accuracy =  0.859375\n",
      "now loss =  0.094518800842744  accuracy =  0.859375\n",
      "now loss =  0.06419059398696442  accuracy =  0.921875\n",
      "now loss =  0.10481717084184433  accuracy =  0.828125\n",
      "now loss =  0.06452881309958117  accuracy =  0.921875\n",
      "now loss =  0.10793303468977922  accuracy =  0.84375\n",
      "now loss =  0.09132960033920523  accuracy =  0.890625\n",
      "now loss =  0.09245463695407662  accuracy =  0.90625\n",
      "now loss =  0.08662065303769144  accuracy =  0.890625\n",
      "now loss =  0.060780377839506315  accuracy =  0.9375\n",
      "now loss =  0.082941620311235  accuracy =  0.890625\n",
      "now loss =  0.09243329391737892  accuracy =  0.890625\n",
      "now loss =  0.09254249898582463  accuracy =  0.84375\n",
      "now loss =  0.0891247081450585  accuracy =  0.890625\n",
      "now loss =  0.0984898474305425  accuracy =  0.875\n",
      "now loss =  0.05934784417990544  accuracy =  0.875\n",
      "now loss =  0.10218558091406023  accuracy =  0.828125\n",
      "now loss =  0.10890983483749149  accuracy =  0.84375\n",
      "now loss =  0.08698729134317668  accuracy =  0.921875\n",
      "now loss =  0.08165492340056565  accuracy =  0.890625\n",
      "now loss =  0.09073274651954984  accuracy =  0.90625\n",
      "now loss =  0.08340072254399988  accuracy =  0.859375\n",
      "now loss =  0.06682961020597125  accuracy =  0.921875\n",
      "now loss =  0.07014054001724912  accuracy =  0.953125\n",
      "now loss =  0.06325027888507445  accuracy =  0.9375\n",
      "now loss =  0.11805383488238137  accuracy =  0.828125\n",
      "now loss =  0.07527462396620516  accuracy =  0.90625\n",
      "now loss =  0.09275854123874872  accuracy =  0.8125\n",
      "now loss =  0.0663053483125607  accuracy =  0.921875\n",
      "now loss =  0.10541820995749294  accuracy =  0.84375\n",
      "now loss =  0.08091889587222388  accuracy =  0.921875\n",
      "now loss =  0.08027735522375128  accuracy =  0.875\n",
      "now loss =  0.07844783269198373  accuracy =  0.90625\n",
      "now loss =  0.0903468789031108  accuracy =  0.875\n",
      "now loss =  0.10613474590772248  accuracy =  0.828125\n",
      "now loss =  0.08607435172746761  accuracy =  0.828125\n",
      "now loss =  0.08342141501306863  accuracy =  0.890625\n",
      "now loss =  0.1289927185086319  accuracy =  0.8125\n",
      "now loss =  0.08657402953962495  accuracy =  0.875\n",
      "now loss =  0.08156017786802103  accuracy =  0.921875\n",
      "now loss =  0.09448106914242946  accuracy =  0.90625\n",
      "now loss =  0.04415468249813592  accuracy =  0.96875\n",
      "now loss =  0.08565656993178898  accuracy =  0.859375\n",
      "now loss =  0.08018327445659504  accuracy =  0.90625\n",
      "now loss =  0.08152984455519388  accuracy =  0.875\n",
      "now loss =  0.08485695347994254  accuracy =  0.890625\n",
      "now loss =  0.08936525541591954  accuracy =  0.90625\n",
      "now loss =  0.06208112432041194  accuracy =  0.925\n",
      "now loss =  0.06500739979045989  accuracy =  0.9375\n",
      "now loss =  0.08116343874838884  accuracy =  0.90625\n",
      "now loss =  0.10152984066401781  accuracy =  0.8125\n",
      "now loss =  0.10397104613693733  accuracy =  0.84375\n",
      "now loss =  0.07425559021205741  accuracy =  0.921875\n",
      "now loss =  0.11787550944454656  accuracy =  0.859375\n",
      "now loss =  0.07227138821137657  accuracy =  0.90625\n",
      "now loss =  0.0724373140893666  accuracy =  0.921875\n",
      "now loss =  0.09121220523968566  accuracy =  0.875\n",
      "now loss =  0.08284220073266535  accuracy =  0.875\n",
      "now loss =  0.09005728458420288  accuracy =  0.90625\n",
      "now loss =  0.10772381223374333  accuracy =  0.84375\n",
      "now loss =  0.05416139085794604  accuracy =  0.921875\n",
      "now loss =  0.08449996116948127  accuracy =  0.890625\n",
      "now loss =  0.06809754907523075  accuracy =  0.921875\n",
      "now loss =  0.13388749140272288  accuracy =  0.75\n",
      "now loss =  0.04952654895537156  accuracy =  0.953125\n",
      "now loss =  0.10452595349502933  accuracy =  0.828125\n",
      "now loss =  0.10448078352767087  accuracy =  0.84375\n",
      "now loss =  0.13131590553720646  accuracy =  0.8125\n",
      "now loss =  0.07649758557556749  accuracy =  0.890625\n",
      "now loss =  0.07519279927583812  accuracy =  0.921875\n",
      "now loss =  0.07847669842822505  accuracy =  0.9375\n",
      "now loss =  0.07197547935616537  accuracy =  0.921875\n",
      "now loss =  0.09886724479206634  accuracy =  0.890625\n",
      "now loss =  0.07783252537484901  accuracy =  0.921875\n",
      "now loss =  0.05315236842638041  accuracy =  0.953125\n",
      "now loss =  0.07306217517379482  accuracy =  0.890625\n",
      "now loss =  0.08885748552771672  accuracy =  0.859375\n",
      "now loss =  0.08845416263894416  accuracy =  0.828125\n",
      "now loss =  0.11461543732244484  accuracy =  0.8125\n",
      "now loss =  0.09147659476241067  accuracy =  0.85\n",
      "now loss =  0.08244790951504397  accuracy =  0.890625\n",
      "now loss =  0.06307308963024838  accuracy =  0.9375\n",
      "now loss =  0.08180211663717732  accuracy =  0.90625\n",
      "now loss =  0.1082802033959133  accuracy =  0.828125\n",
      "now loss =  0.09089205899083524  accuracy =  0.875\n",
      "now loss =  0.0960887013051323  accuracy =  0.859375\n",
      "now loss =  0.061561115493955085  accuracy =  0.96875\n",
      "now loss =  0.09647986823859629  accuracy =  0.875\n",
      "now loss =  0.06784727421706727  accuracy =  0.90625\n",
      "now loss =  0.10187199608998107  accuracy =  0.828125\n",
      "now loss =  0.08515595409604307  accuracy =  0.84375\n",
      "now loss =  0.08559285039157075  accuracy =  0.890625\n",
      "now loss =  0.12342348199669856  accuracy =  0.828125\n",
      "now loss =  0.0564377759925785  accuracy =  0.9375\n",
      "now loss =  0.08619951711899534  accuracy =  0.890625\n",
      "now loss =  0.08249229515956721  accuracy =  0.925\n",
      "now loss =  0.08190405276859505  accuracy =  0.890625\n",
      "now loss =  0.06444541361391562  accuracy =  0.9375\n",
      "now loss =  0.06697723632459285  accuracy =  0.953125\n",
      "now loss =  0.11136867626201431  accuracy =  0.8125\n",
      "now loss =  0.11166331257882464  accuracy =  0.828125\n",
      "now loss =  0.100544794140394  accuracy =  0.84375\n",
      "now loss =  0.07752265295742428  accuracy =  0.921875\n",
      "now loss =  0.07347087364856833  accuracy =  0.921875\n",
      "now loss =  0.08785084382170828  accuracy =  0.859375\n",
      "now loss =  0.09100380060993263  accuracy =  0.90625\n",
      "now loss =  0.07454114670341645  accuracy =  0.90625\n",
      "now loss =  0.09025856621624052  accuracy =  0.875\n",
      "now loss =  0.09162153330839888  accuracy =  0.859375\n",
      "now loss =  0.09147421944837236  accuracy =  0.859375\n",
      "now loss =  0.08771112644405572  accuracy =  0.875\n",
      "now loss =  0.07825545222547942  accuracy =  0.925\n",
      "now loss =  0.08350343791960602  accuracy =  0.890625\n",
      "now loss =  0.09323626095899873  accuracy =  0.859375\n",
      "now loss =  0.08367505592591588  accuracy =  0.890625\n",
      "now loss =  0.09768667588691002  accuracy =  0.859375\n",
      "now loss =  0.09925443975455425  accuracy =  0.84375\n",
      "now loss =  0.09856992008463511  accuracy =  0.875\n",
      "now loss =  0.08539162531047789  accuracy =  0.890625\n",
      "now loss =  0.07908319847077136  accuracy =  0.90625\n",
      "now loss =  0.08180547850084408  accuracy =  0.890625\n",
      "now loss =  0.10222426189098024  accuracy =  0.859375\n",
      "now loss =  0.08025117740297584  accuracy =  0.890625\n",
      "now loss =  0.052110588710685704  accuracy =  0.953125\n",
      "now loss =  0.08622582793237399  accuracy =  0.859375\n",
      "now loss =  0.08661437872415481  accuracy =  0.890625\n",
      "now loss =  0.0904441741124723  accuracy =  0.890625\n",
      "now loss =  0.061436888565621614  accuracy =  0.9\n",
      "now loss =  0.09627497778439528  accuracy =  0.90625\n",
      "now loss =  0.11511948167995444  accuracy =  0.84375\n",
      "now loss =  0.09799616892983555  accuracy =  0.828125\n",
      "now loss =  0.10711163956754671  accuracy =  0.828125\n",
      "now loss =  0.06850875628444894  accuracy =  0.921875\n",
      "now loss =  0.08751646546191004  accuracy =  0.890625\n",
      "now loss =  0.06474760985229311  accuracy =  0.921875\n",
      "now loss =  0.08814872154788138  accuracy =  0.828125\n",
      "now loss =  0.06575443604528013  accuracy =  0.921875\n",
      "now loss =  0.09196422860911632  accuracy =  0.875\n",
      "now loss =  0.08169773330993625  accuracy =  0.921875\n",
      "now loss =  0.09232360848780866  accuracy =  0.875\n",
      "now loss =  0.08708420173627823  accuracy =  0.84375\n",
      "now loss =  0.08597059452872942  accuracy =  0.90625\n",
      "now loss =  0.063118404753735  accuracy =  0.921875\n",
      "now loss =  0.08459123276588829  accuracy =  0.925\n",
      "now loss =  0.09009013864428242  accuracy =  0.859375\n",
      "now loss =  0.08273615701968043  accuracy =  0.921875\n",
      "now loss =  0.08409515937129358  accuracy =  0.859375\n",
      "now loss =  0.08387409948004382  accuracy =  0.84375\n",
      "now loss =  0.08000501973949647  accuracy =  0.890625\n",
      "now loss =  0.09392292977382827  accuracy =  0.859375\n",
      "now loss =  0.08900268316991375  accuracy =  0.84375\n",
      "now loss =  0.08562419252025334  accuracy =  0.890625\n",
      "now loss =  0.05884926815044178  accuracy =  0.9375\n",
      "now loss =  0.1214627196039889  accuracy =  0.796875\n",
      "now loss =  0.06065226911410323  accuracy =  0.953125\n",
      "now loss =  0.06767184626123593  accuracy =  0.921875\n",
      "now loss =  0.10427400970906622  accuracy =  0.890625\n",
      "now loss =  0.09370375173148061  accuracy =  0.859375\n",
      "now loss =  0.08483322364937093  accuracy =  0.921875\n",
      "now loss =  0.10515438347971066  accuracy =  0.875\n",
      "now loss =  0.07371637803055207  accuracy =  0.921875\n",
      "now loss =  0.07211736418199702  accuracy =  0.90625\n",
      "now loss =  0.07068723556160944  accuracy =  0.921875\n",
      "now loss =  0.127952478191119  accuracy =  0.828125\n",
      "now loss =  0.06473486935477012  accuracy =  0.921875\n",
      "now loss =  0.08130114051923606  accuracy =  0.875\n",
      "now loss =  0.06911960670156678  accuracy =  0.921875\n",
      "now loss =  0.10629951995680992  accuracy =  0.84375\n",
      "now loss =  0.08570693889569614  accuracy =  0.859375\n",
      "now loss =  0.10869529901730397  accuracy =  0.84375\n",
      "now loss =  0.05577667052433976  accuracy =  0.96875\n",
      "now loss =  0.09406733084384289  accuracy =  0.859375\n",
      "now loss =  0.07595697610384144  accuracy =  0.921875\n",
      "now loss =  0.09538029042497859  accuracy =  0.859375\n",
      "now loss =  0.124207158346002  accuracy =  0.796875\n",
      "now loss =  0.06158845462097752  accuracy =  0.95\n",
      "now loss =  0.08364748744914594  accuracy =  0.90625\n",
      "now loss =  0.08623846232737578  accuracy =  0.859375\n",
      "now loss =  0.07767210256409107  accuracy =  0.890625\n",
      "now loss =  0.10522663596794524  accuracy =  0.859375\n",
      "now loss =  0.08288601491964119  accuracy =  0.9375\n",
      "now loss =  0.06310785424550214  accuracy =  0.921875\n",
      "now loss =  0.06734242551575674  accuracy =  0.921875\n",
      "now loss =  0.10627350826499081  accuracy =  0.84375\n",
      "now loss =  0.09592382233234503  accuracy =  0.875\n",
      "now loss =  0.05300609252319217  accuracy =  0.953125\n",
      "now loss =  0.11964327366884017  accuracy =  0.78125\n",
      "now loss =  0.05671087329853335  accuracy =  0.9375\n",
      "now loss =  0.08645229055692058  accuracy =  0.875\n",
      "now loss =  0.10820430157468988  accuracy =  0.84375\n",
      "now loss =  0.0962900150049081  accuracy =  0.828125\n",
      "now loss =  0.08334313399188553  accuracy =  0.85\n",
      "now loss =  0.07656366604570941  accuracy =  0.90625\n",
      "now loss =  0.0968676385807942  accuracy =  0.859375\n",
      "now loss =  0.11813124294053033  accuracy =  0.78125\n",
      "now loss =  0.07573947769305149  accuracy =  0.921875\n",
      "now loss =  0.07000378400433024  accuracy =  0.9375\n",
      "now loss =  0.09114290351650513  accuracy =  0.875\n",
      "now loss =  0.0752136838123398  accuracy =  0.890625\n",
      "now loss =  0.1110861171643647  accuracy =  0.8125\n",
      "now loss =  0.07092280518325299  accuracy =  0.921875\n",
      "now loss =  0.11051142312183182  accuracy =  0.828125\n",
      "now loss =  0.08788501328377563  accuracy =  0.859375\n",
      "now loss =  0.07334572733821719  accuracy =  0.921875\n",
      "now loss =  0.06849868372213219  accuracy =  0.921875\n",
      "now loss =  0.08454617036112812  accuracy =  0.90625\n",
      "now loss =  0.06957305817025237  accuracy =  0.90625\n",
      "now loss =  0.09385170649948708  accuracy =  0.875\n",
      "now loss =  0.07129731836443506  accuracy =  0.90625\n",
      "now loss =  0.091449262925129  accuracy =  0.84375\n",
      "now loss =  0.09162176108414605  accuracy =  0.859375\n",
      "now loss =  0.07670406379171761  accuracy =  0.90625\n",
      "now loss =  0.11001450885406544  accuracy =  0.84375\n",
      "now loss =  0.06714553789850844  accuracy =  0.921875\n",
      "now loss =  0.07037356820377225  accuracy =  0.90625\n",
      "now loss =  0.07883907164423853  accuracy =  0.90625\n",
      "now loss =  0.09612011543726863  accuracy =  0.859375\n",
      "now loss =  0.11790181082931334  accuracy =  0.765625\n",
      "now loss =  0.06502848996543481  accuracy =  0.9375\n",
      "now loss =  0.09995003876274886  accuracy =  0.875\n",
      "now loss =  0.07917741117156368  accuracy =  0.90625\n",
      "now loss =  0.07587936814309258  accuracy =  0.921875\n",
      "now loss =  0.10341454046642967  accuracy =  0.84375\n",
      "now loss =  0.08284694788440672  accuracy =  0.925\n",
      "now loss =  0.07460874448012349  accuracy =  0.90625\n",
      "now loss =  0.08843867014550945  accuracy =  0.859375\n",
      "now loss =  0.109547326654799  accuracy =  0.84375\n",
      "now loss =  0.07914633518562866  accuracy =  0.921875\n",
      "now loss =  0.08263656259975663  accuracy =  0.90625\n",
      "now loss =  0.0853010506437671  accuracy =  0.875\n",
      "now loss =  0.09230801026425464  accuracy =  0.890625\n",
      "now loss =  0.06866499030369427  accuracy =  0.90625\n",
      "now loss =  0.08763513930522879  accuracy =  0.859375\n",
      "now loss =  0.08052163909510905  accuracy =  0.921875\n",
      "now loss =  0.09001156677564337  accuracy =  0.828125\n",
      "now loss =  0.08542566792224954  accuracy =  0.90625\n",
      "now loss =  0.08482105151220647  accuracy =  0.875\n",
      "now loss =  0.09702807496765094  accuracy =  0.875\n",
      "now loss =  0.09102917511099548  accuracy =  0.859375\n",
      "now loss =  0.07614868352720008  accuracy =  0.925\n",
      "now loss =  0.10673696638144614  accuracy =  0.859375\n",
      "now loss =  0.08669310964403408  accuracy =  0.890625\n",
      "now loss =  0.07590507614548259  accuracy =  0.921875\n",
      "now loss =  0.07661159249736253  accuracy =  0.90625\n",
      "now loss =  0.0960870035199066  accuracy =  0.828125\n",
      "now loss =  0.1012824708060986  accuracy =  0.859375\n",
      "now loss =  0.08490947431321436  accuracy =  0.875\n",
      "now loss =  0.07874267876891278  accuracy =  0.875\n",
      "now loss =  0.08249857268968852  accuracy =  0.890625\n",
      "now loss =  0.10457081815096145  accuracy =  0.859375\n",
      "now loss =  0.0883129043784691  accuracy =  0.890625\n",
      "now loss =  0.09930522357140772  accuracy =  0.8125\n",
      "now loss =  0.05310557583627024  accuracy =  0.96875\n",
      "now loss =  0.06969044344849104  accuracy =  0.890625\n",
      "now loss =  0.08361946567551796  accuracy =  0.859375\n",
      "now loss =  0.07344308472660768  accuracy =  0.95\n",
      "now loss =  0.12420996342716845  accuracy =  0.8125\n",
      "now loss =  0.07135204475225854  accuracy =  0.921875\n",
      "now loss =  0.07225600849183755  accuracy =  0.9375\n",
      "now loss =  0.0844306390913829  accuracy =  0.859375\n",
      "now loss =  0.1111822609930687  accuracy =  0.828125\n",
      "now loss =  0.06127625930403384  accuracy =  0.921875\n",
      "now loss =  0.08890718400964796  accuracy =  0.875\n",
      "now loss =  0.087409310393806  accuracy =  0.890625\n",
      "now loss =  0.10695846744676393  accuracy =  0.8125\n",
      "now loss =  0.09108757369149646  accuracy =  0.859375\n",
      "now loss =  0.08373109353156755  accuracy =  0.890625\n",
      "now loss =  0.08806299631639058  accuracy =  0.890625\n",
      "now loss =  0.08959645479052417  accuracy =  0.875\n",
      "now loss =  0.06795546125843686  accuracy =  0.90625\n",
      "now loss =  0.08137795457977964  accuracy =  0.9375\n",
      "now loss =  0.050034154651763044  accuracy =  0.925\n",
      "now loss =  0.06909843204991857  accuracy =  0.9375\n",
      "now loss =  0.08768719725670117  accuracy =  0.875\n",
      "now loss =  0.09745710950362128  accuracy =  0.84375\n",
      "now loss =  0.10024602963537742  accuracy =  0.84375\n",
      "now loss =  0.09951934420711551  accuracy =  0.828125\n",
      "now loss =  0.11004045493081084  accuracy =  0.828125\n",
      "now loss =  0.07466700292323201  accuracy =  0.859375\n",
      "now loss =  0.07348813091528238  accuracy =  0.9375\n",
      "now loss =  0.09982091163356197  accuracy =  0.875\n",
      "now loss =  0.09711263907646676  accuracy =  0.84375\n",
      "now loss =  0.07901102060195424  accuracy =  0.90625\n",
      "now loss =  0.06928926402411896  accuracy =  0.921875\n",
      "now loss =  0.08293098344923949  accuracy =  0.921875\n",
      "now loss =  0.11045493512803357  accuracy =  0.828125\n",
      "now loss =  0.05595475537844179  accuracy =  0.9375\n",
      "now loss =  0.042165677505058875  accuracy =  0.975\n",
      "now loss =  0.10144613412830247  accuracy =  0.84375\n",
      "now loss =  0.07095623210968532  accuracy =  0.921875\n",
      "now loss =  0.06689903925298113  accuracy =  0.921875\n",
      "now loss =  0.10530960189279229  accuracy =  0.859375\n",
      "now loss =  0.07481322372073418  accuracy =  0.890625\n",
      "now loss =  0.07716349163517615  accuracy =  0.90625\n",
      "now loss =  0.1325033364013557  accuracy =  0.78125\n",
      "now loss =  0.10166374444417323  accuracy =  0.859375\n",
      "now loss =  0.06089609602994654  accuracy =  0.90625\n",
      "now loss =  0.09230246052466601  accuracy =  0.875\n",
      "now loss =  0.0892172965722329  accuracy =  0.90625\n",
      "now loss =  0.06328285750974372  accuracy =  0.953125\n",
      "now loss =  0.08607057498139298  accuracy =  0.890625\n",
      "now loss =  0.0945533996403187  accuracy =  0.84375\n",
      "now loss =  0.06960626443168531  accuracy =  0.90625\n",
      "now loss =  0.09593764372111302  accuracy =  0.875\n",
      "now loss =  0.08533924077021826  accuracy =  0.890625\n",
      "now loss =  0.1052682368137968  accuracy =  0.828125\n",
      "now loss =  0.08259961923368733  accuracy =  0.890625\n",
      "now loss =  0.09592493915304759  accuracy =  0.84375\n",
      "now loss =  0.06502969414297524  accuracy =  0.90625\n",
      "now loss =  0.06959179955185477  accuracy =  0.890625\n",
      "now loss =  0.08647840268015418  accuracy =  0.90625\n",
      "now loss =  0.07576085390067147  accuracy =  0.921875\n",
      "now loss =  0.10243553727808317  accuracy =  0.875\n",
      "now loss =  0.0862641502478929  accuracy =  0.875\n",
      "now loss =  0.08722680439512248  accuracy =  0.890625\n",
      "now loss =  0.1042261720299093  accuracy =  0.828125\n",
      "now loss =  0.06378648045096832  accuracy =  0.9375\n",
      "now loss =  0.08490377471213495  accuracy =  0.890625\n",
      "now loss =  0.09541599811932241  accuracy =  0.890625\n",
      "now loss =  0.07313313360508121  accuracy =  0.925\n",
      "now loss =  0.09231984938933048  accuracy =  0.90625\n",
      "now loss =  0.07012120667380109  accuracy =  0.921875\n",
      "now loss =  0.07816975136937246  accuracy =  0.890625\n",
      "now loss =  0.07330290919498245  accuracy =  0.90625\n",
      "now loss =  0.07593958097399064  accuracy =  0.90625\n",
      "now loss =  0.0810484799855571  accuracy =  0.90625\n",
      "now loss =  0.0841250192728695  accuracy =  0.875\n",
      "now loss =  0.10519337707122386  accuracy =  0.890625\n",
      "now loss =  0.09510575949516283  accuracy =  0.84375\n",
      "now loss =  0.06787508894610052  accuracy =  0.90625\n",
      "now loss =  0.06194337632719672  accuracy =  0.90625\n",
      "now loss =  0.09002545639114568  accuracy =  0.890625\n",
      "now loss =  0.09557595530677444  accuracy =  0.890625\n",
      "now loss =  0.08498518039532549  accuracy =  0.859375\n",
      "now loss =  0.13305965045875412  accuracy =  0.78125\n",
      "now loss =  0.09207699643858891  accuracy =  0.875\n",
      "now loss =  0.06177820378740309  accuracy =  0.9375\n",
      "now loss =  0.09275226491785063  accuracy =  0.859375\n",
      "now loss =  0.08130059575282175  accuracy =  0.875\n",
      "now loss =  0.08535691830633836  accuracy =  0.875\n",
      "now loss =  0.09752205711742386  accuracy =  0.828125\n",
      "now loss =  0.08516420136900239  accuracy =  0.875\n",
      "now loss =  0.09269230077965368  accuracy =  0.890625\n",
      "now loss =  0.06867765869578982  accuracy =  0.921875\n",
      "now loss =  0.09637278400385724  accuracy =  0.859375\n",
      "now loss =  0.10488433083654783  accuracy =  0.828125\n",
      "now loss =  0.0829896486231767  accuracy =  0.890625\n",
      "now loss =  0.057904008610124555  accuracy =  0.9375\n",
      "now loss =  0.10527024877736074  accuracy =  0.859375\n",
      "now loss =  0.08771337371101948  accuracy =  0.90625\n",
      "now loss =  0.10075535545666436  accuracy =  0.890625\n",
      "now loss =  0.05929613728026706  accuracy =  0.95\n",
      "now loss =  0.12214368392742758  accuracy =  0.828125\n",
      "now loss =  0.08931945724336351  accuracy =  0.890625\n",
      "now loss =  0.07629985750554569  accuracy =  0.890625\n",
      "now loss =  0.07655481316571466  accuracy =  0.921875\n",
      "now loss =  0.09276436889621006  accuracy =  0.859375\n",
      "now loss =  0.10253181616100968  accuracy =  0.84375\n",
      "now loss =  0.06153752098860612  accuracy =  0.9375\n",
      "now loss =  0.10432162167302862  accuracy =  0.875\n",
      "now loss =  0.09719604991497882  accuracy =  0.859375\n",
      "now loss =  0.09956114360412299  accuracy =  0.84375\n",
      "now loss =  0.09669861393508364  accuracy =  0.875\n",
      "now loss =  0.05824400466840282  accuracy =  0.953125\n",
      "now loss =  0.08918689086198081  accuracy =  0.859375\n",
      "now loss =  0.08263170486937  accuracy =  0.921875\n",
      "now loss =  0.040507723150100594  accuracy =  0.953125\n",
      "now loss =  0.0923909121695464  accuracy =  0.9\n",
      "now loss =  0.07308208487720505  accuracy =  0.921875\n",
      "now loss =  0.09020396395546448  accuracy =  0.875\n",
      "now loss =  0.10604308651350768  accuracy =  0.859375\n",
      "now loss =  0.08172286216549907  accuracy =  0.90625\n",
      "now loss =  0.08745818148146166  accuracy =  0.890625\n",
      "now loss =  0.08822723422320047  accuracy =  0.875\n",
      "now loss =  0.09004033534740355  accuracy =  0.859375\n",
      "now loss =  0.09125617275977332  accuracy =  0.84375\n",
      "now loss =  0.05448870056742587  accuracy =  0.9375\n",
      "now loss =  0.08662862642349176  accuracy =  0.859375\n",
      "now loss =  0.12546936741084763  accuracy =  0.8125\n",
      "now loss =  0.08596181077450918  accuracy =  0.890625\n",
      "now loss =  0.06071618485115879  accuracy =  0.953125\n",
      "now loss =  0.08494515344736447  accuracy =  0.875\n",
      "now loss =  0.07868648934232933  accuracy =  0.9375\n",
      "now loss =  0.0954756366440799  accuracy =  0.85\n",
      "now loss =  0.12497851252429462  accuracy =  0.765625\n",
      "now loss =  0.0942903303973198  accuracy =  0.859375\n",
      "now loss =  0.07363837862007501  accuracy =  0.890625\n",
      "now loss =  0.11689756888665563  accuracy =  0.828125\n",
      "now loss =  0.08247876827322885  accuracy =  0.859375\n",
      "now loss =  0.08174496334511047  accuracy =  0.890625\n",
      "now loss =  0.07546399641660292  accuracy =  0.921875\n",
      "now loss =  0.04529855258108847  accuracy =  0.984375\n",
      "now loss =  0.10390690148402844  accuracy =  0.828125\n",
      "now loss =  0.08952687207893491  accuracy =  0.875\n",
      "now loss =  0.07774739896577196  accuracy =  0.890625\n",
      "now loss =  0.07770706936837901  accuracy =  0.90625\n",
      "now loss =  0.07961065000823474  accuracy =  0.953125\n",
      "now loss =  0.059998388783130865  accuracy =  0.953125\n",
      "now loss =  0.11346701975376275  accuracy =  0.8125\n",
      "now loss =  0.07702665717890705  accuracy =  0.9\n",
      "now loss =  0.07709066791926372  accuracy =  0.9375\n",
      "now loss =  0.0715999993259118  accuracy =  0.875\n",
      "now loss =  0.0819743750572513  accuracy =  0.875\n",
      "now loss =  0.07078623804927137  accuracy =  0.890625\n",
      "now loss =  0.08281816290231112  accuracy =  0.890625\n",
      "now loss =  0.08745337343387566  accuracy =  0.875\n",
      "now loss =  0.059972116083725  accuracy =  0.921875\n",
      "now loss =  0.10588167808223188  accuracy =  0.84375\n",
      "now loss =  0.07844358566940235  accuracy =  0.921875\n",
      "now loss =  0.10294553217901972  accuracy =  0.84375\n",
      "now loss =  0.09979706660156179  accuracy =  0.84375\n",
      "now loss =  0.09903033381652404  accuracy =  0.84375\n",
      "now loss =  0.0838216348919684  accuracy =  0.890625\n",
      "now loss =  0.09458968491791939  accuracy =  0.84375\n",
      "now loss =  0.07607822248936125  accuracy =  0.9375\n",
      "now loss =  0.10840496811534446  accuracy =  0.9\n",
      "now loss =  0.08958177195856859  accuracy =  0.890625\n",
      "now loss =  0.09278161364374202  accuracy =  0.890625\n",
      "now loss =  0.09204831655357792  accuracy =  0.875\n",
      "now loss =  0.07228285885138178  accuracy =  0.890625\n",
      "now loss =  0.06725058898128286  accuracy =  0.921875\n",
      "now loss =  0.07807447993349154  accuracy =  0.875\n",
      "now loss =  0.09537907859785133  accuracy =  0.875\n",
      "now loss =  0.09118171198558127  accuracy =  0.859375\n",
      "now loss =  0.0875880067771741  accuracy =  0.890625\n",
      "now loss =  0.09607975427998507  accuracy =  0.84375\n",
      "now loss =  0.08997631008642461  accuracy =  0.859375\n",
      "now loss =  0.0962889842610734  accuracy =  0.875\n",
      "now loss =  0.07124047471096162  accuracy =  0.9375\n",
      "now loss =  0.09533124977376078  accuracy =  0.84375\n",
      "now loss =  0.07593227996952877  accuracy =  0.921875\n",
      "now loss =  0.08721024953480552  accuracy =  0.875\n",
      "now loss =  0.08819414483225993  accuracy =  0.875\n",
      "now loss =  0.07742284555078098  accuracy =  0.890625\n",
      "now loss =  0.08184865725345306  accuracy =  0.890625\n",
      "now loss =  0.08894316729326035  accuracy =  0.859375\n",
      "now loss =  0.06525723183233301  accuracy =  0.9375\n",
      "now loss =  0.09237744003298914  accuracy =  0.859375\n",
      "now loss =  0.09270297821109852  accuracy =  0.875\n",
      "now loss =  0.07864908363976732  accuracy =  0.9375\n",
      "now loss =  0.07835247285399213  accuracy =  0.90625\n",
      "now loss =  0.10722171182783896  accuracy =  0.828125\n",
      "now loss =  0.09667242975009063  accuracy =  0.890625\n",
      "now loss =  0.09470030568347143  accuracy =  0.859375\n",
      "now loss =  0.07062954720275576  accuracy =  0.921875\n",
      "now loss =  0.061301028303306096  accuracy =  0.921875\n",
      "now loss =  0.1042221297733665  accuracy =  0.875\n",
      "now loss =  0.10860849455850992  accuracy =  0.85\n",
      "now loss =  0.10188271669352675  accuracy =  0.875\n",
      "now loss =  0.07797314279575876  accuracy =  0.875\n",
      "now loss =  0.09998832384805975  accuracy =  0.875\n",
      "now loss =  0.08608138454901405  accuracy =  0.90625\n",
      "now loss =  0.06359872980791478  accuracy =  0.921875\n",
      "now loss =  0.0859667718319608  accuracy =  0.875\n",
      "now loss =  0.11637522389268788  accuracy =  0.828125\n",
      "now loss =  0.10247308514794956  accuracy =  0.828125\n",
      "now loss =  0.08523527984478924  accuracy =  0.890625\n",
      "now loss =  0.10843866334290828  accuracy =  0.859375\n",
      "now loss =  0.09400184727019831  accuracy =  0.875\n",
      "now loss =  0.10438268955786828  accuracy =  0.828125\n",
      "now loss =  0.07530202535929995  accuracy =  0.921875\n",
      "now loss =  0.06343710572216411  accuracy =  0.953125\n",
      "now loss =  0.051588735025002205  accuracy =  0.96875\n",
      "now loss =  0.049159545546372634  accuracy =  1.0\n",
      "now loss =  0.08979194518115907  accuracy =  0.90625\n",
      "now loss =  0.10168704768699777  accuracy =  0.8125\n",
      "now loss =  0.06067116851413758  accuracy =  0.953125\n",
      "now loss =  0.07156134416646309  accuracy =  0.921875\n",
      "now loss =  0.08356033234072897  accuracy =  0.890625\n",
      "now loss =  0.12226263423250316  accuracy =  0.828125\n",
      "now loss =  0.08595423525080838  accuracy =  0.890625\n",
      "now loss =  0.07918293141023945  accuracy =  0.875\n",
      "now loss =  0.09574368143509628  accuracy =  0.859375\n",
      "now loss =  0.06407992911313737  accuracy =  0.921875\n",
      "now loss =  0.09237455635523685  accuracy =  0.859375\n",
      "now loss =  0.054995001554083184  accuracy =  0.921875\n",
      "now loss =  0.07996647661249769  accuracy =  0.90625\n",
      "now loss =  0.09000662692411493  accuracy =  0.875\n",
      "now loss =  0.07921077806818103  accuracy =  0.90625\n",
      "now loss =  0.13882353389675947  accuracy =  0.75\n",
      "now loss =  0.08923428271028662  accuracy =  0.890625\n",
      "now loss =  0.07902906171828528  accuracy =  0.890625\n",
      "now loss =  0.10929841954047664  accuracy =  0.828125\n",
      "now loss =  0.06424060302217757  accuracy =  0.90625\n",
      "now loss =  0.07077040449048576  accuracy =  0.90625\n",
      "now loss =  0.08936020746832049  accuracy =  0.859375\n",
      "now loss =  0.07693902693624557  accuracy =  0.9375\n",
      "now loss =  0.09646775395613721  accuracy =  0.859375\n",
      "now loss =  0.08478101836688945  accuracy =  0.90625\n",
      "now loss =  0.07351944023494192  accuracy =  0.90625\n",
      "now loss =  0.10796340192477902  accuracy =  0.875\n",
      "now loss =  0.0919532270874239  accuracy =  0.875\n",
      "now loss =  0.0855196707189724  accuracy =  0.875\n",
      "now loss =  0.077229503734297  accuracy =  0.90625\n",
      "now loss =  0.10555907318443977  accuracy =  0.828125\n",
      "now loss =  0.07305444124490965  accuracy =  0.875\n",
      "now loss =  0.07504029973423706  accuracy =  0.90625\n",
      "now loss =  0.08393473796248942  accuracy =  0.84375\n",
      "now loss =  0.08223242559205356  accuracy =  0.890625\n",
      "now loss =  0.07045140554302722  accuracy =  0.890625\n",
      "now loss =  0.0987917012048609  accuracy =  0.890625\n",
      "now loss =  0.0719616318416445  accuracy =  0.921875\n",
      "now loss =  0.07439710866406968  accuracy =  0.90625\n",
      "now loss =  0.07770821241114012  accuracy =  0.921875\n",
      "now loss =  0.09584670502269722  accuracy =  0.84375\n",
      "now loss =  0.07816350050813314  accuracy =  0.90625\n",
      "now loss =  0.09968749992853734  accuracy =  0.875\n",
      "now loss =  0.11394552329746348  accuracy =  0.84375\n",
      "now loss =  0.08234352307122908  accuracy =  0.875\n",
      "now loss =  0.0925114404849453  accuracy =  0.875\n",
      "now loss =  0.0652088813509223  accuracy =  0.9375\n",
      "now loss =  0.12379248612239739  accuracy =  0.875\n",
      "now loss =  0.08834966966297768  accuracy =  0.875\n",
      "now loss =  0.10857258989169334  accuracy =  0.859375\n",
      "now loss =  0.0954352023655429  accuracy =  0.859375\n",
      "now loss =  0.05275869196588753  accuracy =  0.953125\n",
      "now loss =  0.0619880992154661  accuracy =  0.921875\n",
      "now loss =  0.10191960361068586  accuracy =  0.859375\n",
      "now loss =  0.0966905296477671  accuracy =  0.828125\n",
      "now loss =  0.08199843841480266  accuracy =  0.921875\n",
      "now loss =  0.09789364099418452  accuracy =  0.890625\n",
      "now loss =  0.09948795944203377  accuracy =  0.8125\n",
      "now loss =  0.07375288520869432  accuracy =  0.921875\n",
      "now loss =  0.08338124836145848  accuracy =  0.90625\n",
      "now loss =  0.07232141038338911  accuracy =  0.890625\n",
      "now loss =  0.10310691932565635  accuracy =  0.84375\n",
      "now loss =  0.04478464205685259  accuracy =  0.984375\n",
      "now loss =  0.12281435140557506  accuracy =  0.8\n",
      "now loss =  0.10583747880173765  accuracy =  0.859375\n",
      "now loss =  0.08451619659248419  accuracy =  0.890625\n",
      "now loss =  0.06251654440210792  accuracy =  0.90625\n",
      "now loss =  0.09182535518917823  accuracy =  0.875\n",
      "now loss =  0.10028435815532133  accuracy =  0.828125\n",
      "now loss =  0.09417275839288142  accuracy =  0.828125\n",
      "now loss =  0.06850001212780193  accuracy =  0.890625\n",
      "now loss =  0.07220780743654581  accuracy =  0.9375\n",
      "now loss =  0.08117898942135912  accuracy =  0.875\n",
      "now loss =  0.0756177804329367  accuracy =  0.921875\n",
      "now loss =  0.07625590372323943  accuracy =  0.921875\n",
      "now loss =  0.07965141717663246  accuracy =  0.890625\n",
      "now loss =  0.09837821787469404  accuracy =  0.875\n",
      "now loss =  0.10125754417049582  accuracy =  0.859375\n",
      "now loss =  0.09727404630473147  accuracy =  0.875\n",
      "now loss =  0.08926670746149722  accuracy =  0.925\n",
      "now loss =  0.0636462980517957  accuracy =  0.9375\n",
      "now loss =  0.10021779087168298  accuracy =  0.828125\n",
      "now loss =  0.09215497715663773  accuracy =  0.859375\n",
      "now loss =  0.06411460444330914  accuracy =  0.9375\n",
      "now loss =  0.06305535957284122  accuracy =  0.921875\n",
      "now loss =  0.06620141169205068  accuracy =  0.9375\n",
      "now loss =  0.12951362793290377  accuracy =  0.78125\n",
      "now loss =  0.08735615196608286  accuracy =  0.90625\n",
      "now loss =  0.07524929839976315  accuracy =  0.890625\n",
      "now loss =  0.08544517772146806  accuracy =  0.890625\n",
      "now loss =  0.09109605818775998  accuracy =  0.875\n",
      "now loss =  0.08890970840404207  accuracy =  0.859375\n",
      "now loss =  0.07502640106442246  accuracy =  0.9375\n",
      "now loss =  0.08766669035457342  accuracy =  0.875\n",
      "now loss =  0.10062404870777203  accuracy =  0.84375\n",
      "now loss =  0.10833347448768275  accuracy =  0.875\n",
      "now loss =  0.076357848884825  accuracy =  0.890625\n",
      "now loss =  0.1060674317875428  accuracy =  0.84375\n",
      "now loss =  0.10052208663875253  accuracy =  0.890625\n",
      "now loss =  0.08656047220307811  accuracy =  0.90625\n",
      "now loss =  0.0719165038970325  accuracy =  0.9375\n",
      "now loss =  0.08392597814769767  accuracy =  0.9375\n",
      "now loss =  0.09052929966859724  accuracy =  0.859375\n",
      "now loss =  0.07470379568289998  accuracy =  0.9375\n",
      "now loss =  0.09402186287279563  accuracy =  0.828125\n",
      "now loss =  0.07090863338362603  accuracy =  0.890625\n",
      "now loss =  0.0892214419297809  accuracy =  0.875\n",
      "now loss =  0.07873900852433588  accuracy =  0.890625\n",
      "now loss =  0.09473677478222833  accuracy =  0.859375\n",
      "now loss =  0.07626015022953014  accuracy =  0.875\n",
      "now loss =  0.09431077381644669  accuracy =  0.828125\n",
      "now loss =  0.08982498930956995  accuracy =  0.85\n",
      "now loss =  0.11295855392300533  accuracy =  0.828125\n",
      "now loss =  0.1122589807725193  accuracy =  0.84375\n",
      "now loss =  0.11506252476446949  accuracy =  0.859375\n",
      "now loss =  0.08040727288171676  accuracy =  0.890625\n",
      "now loss =  0.06904889347958543  accuracy =  0.90625\n",
      "now loss =  0.10485560540319036  accuracy =  0.84375\n",
      "now loss =  0.07290446523576194  accuracy =  0.90625\n",
      "now loss =  0.0910035223598562  accuracy =  0.859375\n",
      "now loss =  0.07727405572505323  accuracy =  0.90625\n",
      "now loss =  0.0936022870130783  accuracy =  0.890625\n",
      "now loss =  0.06989949727335946  accuracy =  0.921875\n",
      "now loss =  0.07860722372396305  accuracy =  0.875\n",
      "now loss =  0.07550855749632451  accuracy =  0.875\n",
      "now loss =  0.07608506668226032  accuracy =  0.90625\n",
      "now loss =  0.07398206992562086  accuracy =  0.921875\n",
      "now loss =  0.06960481959507311  accuracy =  0.9\n",
      "now loss =  0.0896320860863089  accuracy =  0.890625\n",
      "now loss =  0.09808974408402085  accuracy =  0.84375\n",
      "now loss =  0.1029715944564864  accuracy =  0.890625\n",
      "now loss =  0.07427760014248623  accuracy =  0.875\n",
      "now loss =  0.07849767707373792  accuracy =  0.890625\n",
      "now loss =  0.07790376139355772  accuracy =  0.90625\n",
      "now loss =  0.0665982853664636  accuracy =  0.90625\n",
      "now loss =  0.08610507035661397  accuracy =  0.890625\n",
      "now loss =  0.1012121704285425  accuracy =  0.828125\n",
      "now loss =  0.08739906944900534  accuracy =  0.828125\n",
      "now loss =  0.08756531676270564  accuracy =  0.890625\n",
      "now loss =  0.0984898918493342  accuracy =  0.875\n",
      "now loss =  0.09354004384907408  accuracy =  0.875\n",
      "now loss =  0.06745732961005135  accuracy =  0.9375\n",
      "now loss =  0.0760872274547379  accuracy =  0.90625\n",
      "now loss =  0.0857530968021719  accuracy =  0.875\n",
      "now loss =  0.07818161358402329  accuracy =  0.875\n",
      "now loss =  0.0920089501770156  accuracy =  0.890625\n",
      "now loss =  0.09446223751811968  accuracy =  0.875\n",
      "now loss =  0.09334136941961155  accuracy =  0.890625\n",
      "now loss =  0.09780484181440394  accuracy =  0.875\n",
      "now loss =  0.05690073239427156  accuracy =  0.9375\n",
      "now loss =  0.06754800944845488  accuracy =  0.9375\n",
      "now loss =  0.06539401384732886  accuracy =  0.90625\n",
      "now loss =  0.09808401421326467  accuracy =  0.859375\n",
      "now loss =  0.10472551762846269  accuracy =  0.859375\n",
      "now loss =  0.11225449625559619  accuracy =  0.828125\n",
      "now loss =  0.08446854691276762  accuracy =  0.859375\n",
      "now loss =  0.09025650630383855  accuracy =  0.890625\n",
      "now loss =  0.0843974314910696  accuracy =  0.875\n",
      "now loss =  0.059109095002684305  accuracy =  0.921875\n",
      "now loss =  0.09517894313311843  accuracy =  0.85\n",
      "now loss =  0.07725201115465988  accuracy =  0.90625\n",
      "now loss =  0.09932604266201982  accuracy =  0.875\n",
      "now loss =  0.08583146876722322  accuracy =  0.890625\n",
      "now loss =  0.0661050851563433  accuracy =  0.953125\n",
      "now loss =  0.06384797856456861  accuracy =  0.921875\n",
      "now loss =  0.09805603005306468  accuracy =  0.84375\n",
      "now loss =  0.09218216460141106  accuracy =  0.875\n",
      "now loss =  0.08323321487492652  accuracy =  0.859375\n",
      "now loss =  0.07276457335296353  accuracy =  0.890625\n",
      "now loss =  0.11318268840643611  accuracy =  0.78125\n",
      "now loss =  0.108292829159399  accuracy =  0.859375\n",
      "now loss =  0.07982924031043226  accuracy =  0.875\n",
      "now loss =  0.05967685239755656  accuracy =  0.953125\n",
      "now loss =  0.08523359259700164  accuracy =  0.875\n",
      "now loss =  0.07255527180102958  accuracy =  0.921875\n",
      "now loss =  0.12067860313353251  accuracy =  0.85\n",
      "now loss =  0.08398868434498305  accuracy =  0.90625\n",
      "now loss =  0.06399184142680739  accuracy =  0.921875\n",
      "now loss =  0.0818903455069778  accuracy =  0.890625\n",
      "now loss =  0.08606365930012534  accuracy =  0.859375\n",
      "now loss =  0.09555698358062947  accuracy =  0.859375\n",
      "now loss =  0.09670015295224797  accuracy =  0.84375\n",
      "now loss =  0.08484467036189919  accuracy =  0.875\n",
      "now loss =  0.11024392928346584  accuracy =  0.796875\n",
      "now loss =  0.06548883271712494  accuracy =  0.953125\n",
      "now loss =  0.09353485231936898  accuracy =  0.890625\n",
      "now loss =  0.06814908835955459  accuracy =  0.890625\n",
      "now loss =  0.0869077407148294  accuracy =  0.921875\n",
      "now loss =  0.1131044934299538  accuracy =  0.8125\n",
      "now loss =  0.08158737883875432  accuracy =  0.921875\n",
      "now loss =  0.08069332647860532  accuracy =  0.90625\n",
      "now loss =  0.07536353735442326  accuracy =  0.925\n",
      "now loss =  0.09949480187181649  accuracy =  0.828125\n",
      "now loss =  0.07589239478617993  accuracy =  0.890625\n",
      "now loss =  0.07878719041807407  accuracy =  0.90625\n",
      "now loss =  0.08549390418443371  accuracy =  0.875\n",
      "now loss =  0.08318598001189959  accuracy =  0.890625\n",
      "now loss =  0.10577832461060337  accuracy =  0.875\n",
      "now loss =  0.09601118930150047  accuracy =  0.84375\n",
      "now loss =  0.05562192872022348  accuracy =  0.953125\n",
      "now loss =  0.10601935821318563  accuracy =  0.84375\n",
      "now loss =  0.09049380345491817  accuracy =  0.890625\n",
      "now loss =  0.10421633671046282  accuracy =  0.84375\n",
      "now loss =  0.10056019088013182  accuracy =  0.859375\n",
      "now loss =  0.07649533656696289  accuracy =  0.875\n",
      "now loss =  0.062249607314229384  accuracy =  0.953125\n",
      "now loss =  0.08090725141558144  accuracy =  0.890625\n",
      "now loss =  0.0721444141699237  accuracy =  0.9\n",
      "now loss =  0.10092209213722916  accuracy =  0.84375\n",
      "now loss =  0.09504062843970519  accuracy =  0.890625\n",
      "now loss =  0.08192149781151745  accuracy =  0.84375\n",
      "now loss =  0.08668261790546213  accuracy =  0.875\n",
      "now loss =  0.08571449425674084  accuracy =  0.859375\n",
      "now loss =  0.07967794931675633  accuracy =  0.921875\n",
      "now loss =  0.11734624830324467  accuracy =  0.84375\n",
      "now loss =  0.09324054717544147  accuracy =  0.875\n",
      "now loss =  0.06909496091257926  accuracy =  0.9375\n",
      "now loss =  0.10826105198165582  accuracy =  0.8125\n",
      "now loss =  0.09079998752121782  accuracy =  0.890625\n",
      "now loss =  0.09471427256587486  accuracy =  0.890625\n",
      "now loss =  0.072334638491327  accuracy =  0.875\n",
      "now loss =  0.08451070184048734  accuracy =  0.890625\n",
      "now loss =  0.052286396079419664  accuracy =  0.96875\n",
      "now loss =  0.06865516507038102  accuracy =  0.9\n",
      "now loss =  0.10066826645793531  accuracy =  0.875\n",
      "now loss =  0.09122249973738483  accuracy =  0.875\n",
      "now loss =  0.08323295901049772  accuracy =  0.859375\n",
      "now loss =  0.07448511323516172  accuracy =  0.921875\n",
      "now loss =  0.09713883431611223  accuracy =  0.8125\n",
      "now loss =  0.09140623758711308  accuracy =  0.890625\n",
      "now loss =  0.0908083755835938  accuracy =  0.875\n",
      "now loss =  0.08248121844245793  accuracy =  0.890625\n",
      "now loss =  0.10468467881807592  accuracy =  0.828125\n",
      "now loss =  0.0636245478986306  accuracy =  0.96875\n",
      "now loss =  0.09106450215088788  accuracy =  0.859375\n",
      "now loss =  0.07589443720481023  accuracy =  0.875\n",
      "now loss =  0.07407208641116439  accuracy =  0.90625\n",
      "now loss =  0.0824719809149409  accuracy =  0.890625\n",
      "now loss =  0.09858538965863575  accuracy =  0.875\n",
      "now loss =  0.0677937159273522  accuracy =  0.9\n",
      "now loss =  0.07730495621214972  accuracy =  0.890625\n",
      "now loss =  0.09811836532435467  accuracy =  0.875\n",
      "now loss =  0.06842958336092769  accuracy =  0.921875\n",
      "now loss =  0.09597016865356132  accuracy =  0.859375\n",
      "now loss =  0.06277362891279203  accuracy =  0.921875\n",
      "now loss =  0.10126369695622878  accuracy =  0.828125\n",
      "now loss =  0.08578940004437186  accuracy =  0.875\n",
      "now loss =  0.06644297813833142  accuracy =  0.90625\n",
      "now loss =  0.09290834653004756  accuracy =  0.875\n",
      "now loss =  0.06452240438145647  accuracy =  0.90625\n",
      "now loss =  0.1075803312601073  accuracy =  0.859375\n",
      "now loss =  0.09549689231101532  accuracy =  0.90625\n",
      "now loss =  0.07815223022421841  accuracy =  0.890625\n",
      "now loss =  0.08625917422453078  accuracy =  0.90625\n",
      "now loss =  0.10141912209931506  accuracy =  0.84375\n",
      "now loss =  0.09461098723271048  accuracy =  0.875\n",
      "now loss =  0.08979497672131262  accuracy =  0.859375\n",
      "now loss =  0.0810437962972553  accuracy =  0.90625\n",
      "now loss =  0.10251896732537726  accuracy =  0.859375\n",
      "now loss =  0.07042400038865299  accuracy =  0.96875\n",
      "now loss =  0.09135222522004931  accuracy =  0.875\n",
      "now loss =  0.09823642490277865  accuracy =  0.859375\n",
      "now loss =  0.08574931865665855  accuracy =  0.890625\n",
      "now loss =  0.05931663937655959  accuracy =  0.9375\n",
      "now loss =  0.11790877767236704  accuracy =  0.84375\n",
      "now loss =  0.07467557327032712  accuracy =  0.921875\n",
      "now loss =  0.08651033966145963  accuracy =  0.859375\n",
      "now loss =  0.08888961978919699  accuracy =  0.875\n",
      "now loss =  0.07495133198202283  accuracy =  0.921875\n",
      "now loss =  0.08803169043658357  accuracy =  0.875\n",
      "now loss =  0.08652286449881946  accuracy =  0.859375\n",
      "now loss =  0.07514942702509544  accuracy =  0.9\n",
      "now loss =  0.08804010647023114  accuracy =  0.890625\n",
      "now loss =  0.07809477182488483  accuracy =  0.875\n",
      "now loss =  0.1256356283431092  accuracy =  0.8125\n",
      "now loss =  0.10512171358108688  accuracy =  0.8125\n",
      "now loss =  0.059393024454292086  accuracy =  0.96875\n",
      "now loss =  0.07224917253707532  accuracy =  0.9375\n",
      "now loss =  0.08569277536855394  accuracy =  0.875\n",
      "now loss =  0.07712951034069486  accuracy =  0.90625\n",
      "now loss =  0.07187467582464632  accuracy =  0.921875\n",
      "now loss =  0.08437815615004701  accuracy =  0.859375\n",
      "now loss =  0.06845363652957645  accuracy =  0.9375\n",
      "now loss =  0.059886241625481645  accuracy =  0.9375\n",
      "now loss =  0.10386807653563038  accuracy =  0.828125\n",
      "now loss =  0.09581886982826707  accuracy =  0.859375\n",
      "now loss =  0.1100846284214121  accuracy =  0.859375\n",
      "now loss =  0.0930398245524583  accuracy =  0.875\n",
      "now loss =  0.07453547106127548  accuracy =  0.90625\n",
      "now loss =  0.09310847394209512  accuracy =  0.875\n",
      "now loss =  0.08959171431818908  accuracy =  0.90625\n",
      "now loss =  0.08440299771770218  accuracy =  0.890625\n",
      "now loss =  0.10411138241880664  accuracy =  0.84375\n",
      "now loss =  0.06903118060186372  accuracy =  0.9375\n",
      "now loss =  0.09681527730862494  accuracy =  0.875\n",
      "now loss =  0.0819147170379069  accuracy =  0.875\n",
      "now loss =  0.07779991842439916  accuracy =  0.890625\n",
      "now loss =  0.08834659571934048  accuracy =  0.859375\n",
      "now loss =  0.10527440843635552  accuracy =  0.828125\n",
      "now loss =  0.07402806327238746  accuracy =  0.875\n",
      "now loss =  0.08888786242297524  accuracy =  0.90625\n",
      "now loss =  0.07159923128417506  accuracy =  0.90625\n",
      "now loss =  0.10208756645877208  accuracy =  0.859375\n",
      "now loss =  0.07025545621813596  accuracy =  0.875\n",
      "now loss =  0.08448833899586633  accuracy =  0.921875\n",
      "now loss =  0.09683046236091253  accuracy =  0.875\n",
      "now loss =  0.07793265310791445  accuracy =  0.921875\n",
      "now loss =  0.06442793509301689  accuracy =  0.9375\n",
      "now loss =  0.05334359554999059  accuracy =  0.96875\n",
      "now loss =  0.07415683891376368  accuracy =  0.921875\n",
      "now loss =  0.09258807594451635  accuracy =  0.875\n",
      "now loss =  0.08646334910670664  accuracy =  0.859375\n",
      "now loss =  0.0525124966004516  accuracy =  0.953125\n",
      "now loss =  0.08365315586919746  accuracy =  0.875\n",
      "now loss =  0.0991668511286967  accuracy =  0.84375\n",
      "now loss =  0.10199182348081201  accuracy =  0.84375\n",
      "now loss =  0.09519192071825375  accuracy =  0.828125\n",
      "now loss =  0.12117565127181011  accuracy =  0.796875\n",
      "now loss =  0.09429041418881454  accuracy =  0.875\n",
      "now loss =  0.091360292972149  accuracy =  0.85\n",
      "now loss =  0.08984322738892672  accuracy =  0.859375\n",
      "now loss =  0.11120326106567627  accuracy =  0.8125\n",
      "now loss =  0.08565462642500403  accuracy =  0.875\n",
      "now loss =  0.07558806785424715  accuracy =  0.90625\n",
      "now loss =  0.08199119842711863  accuracy =  0.890625\n",
      "now loss =  0.06601027670930457  accuracy =  0.921875\n",
      "now loss =  0.06324849922440082  accuracy =  0.90625\n",
      "now loss =  0.07657904898027654  accuracy =  0.90625\n",
      "now loss =  0.07788372879768704  accuracy =  0.90625\n",
      "now loss =  0.09238845270772675  accuracy =  0.90625\n",
      "now loss =  0.11848819471784022  accuracy =  0.8125\n",
      "now loss =  0.14730235654015794  accuracy =  0.78125\n",
      "now loss =  0.07924871170471254  accuracy =  0.90625\n",
      "now loss =  0.05411514819151278  accuracy =  0.953125\n",
      "now loss =  0.07848594224850361  accuracy =  0.890625\n",
      "now loss =  0.07406375795360103  accuracy =  0.925\n",
      "now loss =  0.06718001829598474  accuracy =  0.9375\n",
      "now loss =  0.09043947239962305  accuracy =  0.9375\n",
      "now loss =  0.07227089884403712  accuracy =  0.875\n",
      "now loss =  0.10495068397994352  accuracy =  0.84375\n",
      "now loss =  0.06792991072641888  accuracy =  0.921875\n",
      "now loss =  0.11959571043644138  accuracy =  0.8125\n",
      "now loss =  0.09235295477500932  accuracy =  0.84375\n",
      "now loss =  0.08351153685845969  accuracy =  0.875\n",
      "now loss =  0.0828663982742526  accuracy =  0.921875\n",
      "now loss =  0.06520599182313477  accuracy =  0.921875\n",
      "now loss =  0.09571567266762232  accuracy =  0.890625\n",
      "now loss =  0.043944600248470835  accuracy =  0.96875\n",
      "now loss =  0.10127558731726521  accuracy =  0.859375\n",
      "now loss =  0.08923022411151503  accuracy =  0.84375\n",
      "now loss =  0.10080620423729666  accuracy =  0.875\n",
      "now loss =  0.09917696415929345  accuracy =  0.85\n",
      "now loss =  0.08789783301894726  accuracy =  0.890625\n",
      "now loss =  0.09639165363079086  accuracy =  0.875\n",
      "now loss =  0.07135473161335987  accuracy =  0.921875\n",
      "now loss =  0.07761593943541074  accuracy =  0.890625\n",
      "now loss =  0.062494967426057584  accuracy =  0.9375\n",
      "now loss =  0.07693392382449568  accuracy =  0.90625\n",
      "now loss =  0.08928920728382224  accuracy =  0.875\n",
      "now loss =  0.08028626421720814  accuracy =  0.921875\n",
      "now loss =  0.09147365106165536  accuracy =  0.875\n",
      "now loss =  0.07743088565526246  accuracy =  0.890625\n",
      "now loss =  0.07868316124494837  accuracy =  0.90625\n",
      "now loss =  0.07719219559667216  accuracy =  0.890625\n",
      "now loss =  0.08850753060119584  accuracy =  0.890625\n",
      "now loss =  0.12528946834901272  accuracy =  0.796875\n",
      "now loss =  0.0948295384184197  accuracy =  0.859375\n",
      "now loss =  0.11043475862583944  accuracy =  0.8\n",
      "now loss =  0.07609871190315785  accuracy =  0.921875\n",
      "now loss =  0.08756296842208464  accuracy =  0.875\n",
      "now loss =  0.05643563335940528  accuracy =  0.921875\n",
      "now loss =  0.08430051387734502  accuracy =  0.875\n",
      "now loss =  0.09818097066430398  accuracy =  0.859375\n",
      "now loss =  0.09822443519127166  accuracy =  0.859375\n",
      "now loss =  0.10980095242225141  accuracy =  0.84375\n",
      "now loss =  0.05787739618128493  accuracy =  0.921875\n",
      "now loss =  0.08455449758338249  accuracy =  0.890625\n",
      "now loss =  0.0938651843539378  accuracy =  0.890625\n",
      "now loss =  0.10767476153404118  accuracy =  0.875\n",
      "now loss =  0.0557643906256731  accuracy =  0.953125\n",
      "now loss =  0.11062066030762054  accuracy =  0.828125\n",
      "now loss =  0.12601702028898426  accuracy =  0.796875\n",
      "now loss =  0.06192262842965833  accuracy =  0.953125\n",
      "now loss =  0.06466488945112622  accuracy =  0.925\n",
      "now loss =  0.08852297234261058  accuracy =  0.875\n",
      "now loss =  0.08601516542106233  accuracy =  0.875\n",
      "now loss =  0.06501383318289752  accuracy =  0.90625\n",
      "now loss =  0.07027097099331352  accuracy =  0.875\n",
      "now loss =  0.08209065379056782  accuracy =  0.875\n",
      "now loss =  0.07925681267573104  accuracy =  0.890625\n",
      "now loss =  0.1074543940632877  accuracy =  0.84375\n",
      "now loss =  0.09746373963501356  accuracy =  0.859375\n",
      "now loss =  0.08610007113486284  accuracy =  0.859375\n",
      "now loss =  0.08108260361973892  accuracy =  0.921875\n",
      "now loss =  0.0888594442710532  accuracy =  0.90625\n",
      "now loss =  0.11394769395285081  accuracy =  0.84375\n",
      "now loss =  0.10707369738327258  accuracy =  0.859375\n",
      "now loss =  0.07041592783929307  accuracy =  0.9375\n",
      "now loss =  0.07888644944630466  accuracy =  0.90625\n",
      "now loss =  0.06367557961338792  accuracy =  0.95\n",
      "now loss =  0.08063412728821046  accuracy =  0.890625\n",
      "now loss =  0.07331223287276167  accuracy =  0.90625\n",
      "now loss =  0.0904673765204018  accuracy =  0.890625\n",
      "now loss =  0.07100475663235055  accuracy =  0.921875\n",
      "now loss =  0.08789856248128167  accuracy =  0.84375\n",
      "now loss =  0.06579693042655108  accuracy =  0.921875\n",
      "now loss =  0.07538231759548436  accuracy =  0.921875\n",
      "now loss =  0.10036745227694176  accuracy =  0.828125\n",
      "now loss =  0.09836185222309389  accuracy =  0.875\n",
      "now loss =  0.08688048780081745  accuracy =  0.890625\n",
      "now loss =  0.08564701950449863  accuracy =  0.859375\n",
      "now loss =  0.10983216488208399  accuracy =  0.828125\n",
      "now loss =  0.08445793661920753  accuracy =  0.921875\n",
      "now loss =  0.08342836257974748  accuracy =  0.859375\n",
      "now loss =  0.10004216909093  accuracy =  0.890625\n",
      "now loss =  0.087080317047473  accuracy =  0.925\n",
      "now loss =  0.06124982759300649  accuracy =  0.921875\n",
      "now loss =  0.09039375362152528  accuracy =  0.859375\n",
      "now loss =  0.07088537744129762  accuracy =  0.9375\n",
      "now loss =  0.06293371353628804  accuracy =  0.921875\n",
      "now loss =  0.10861968917606561  accuracy =  0.875\n",
      "now loss =  0.09806199099073251  accuracy =  0.828125\n",
      "now loss =  0.08753954925536021  accuracy =  0.890625\n",
      "now loss =  0.09944924454597012  accuracy =  0.875\n",
      "now loss =  0.08638257146790121  accuracy =  0.875\n",
      "now loss =  0.09865970459939877  accuracy =  0.859375\n",
      "now loss =  0.07959877070269306  accuracy =  0.875\n",
      "now loss =  0.0875110444069119  accuracy =  0.890625\n",
      "now loss =  0.07427709961506149  accuracy =  0.921875\n",
      "now loss =  0.0869027203084753  accuracy =  0.90625\n",
      "now loss =  0.0974400090467264  accuracy =  0.859375\n",
      "now loss =  0.08476282737630729  accuracy =  0.9\n",
      "now loss =  0.09161088005753788  accuracy =  0.90625\n",
      "now loss =  0.08793703174038417  accuracy =  0.890625\n",
      "now loss =  0.0916844296836841  accuracy =  0.84375\n",
      "now loss =  0.082100772527672  accuracy =  0.890625\n",
      "now loss =  0.06331119212265593  accuracy =  0.921875\n",
      "now loss =  0.061696851866746436  accuracy =  0.921875\n",
      "now loss =  0.10289332936789795  accuracy =  0.859375\n",
      "now loss =  0.11228448385121002  accuracy =  0.84375\n",
      "now loss =  0.07970173132619339  accuracy =  0.921875\n",
      "now loss =  0.12001060900918137  accuracy =  0.8125\n",
      "now loss =  0.0801324876464032  accuracy =  0.875\n",
      "now loss =  0.06058937205632541  accuracy =  0.953125\n",
      "now loss =  0.06744162898397858  accuracy =  0.921875\n",
      "now loss =  0.09961449425406113  accuracy =  0.875\n",
      "now loss =  0.09926011307282669  accuracy =  0.859375\n",
      "now loss =  0.07530836215612234  accuracy =  0.85\n",
      "now loss =  0.09208827915698853  accuracy =  0.859375\n",
      "now loss =  0.0834905049090395  accuracy =  0.875\n",
      "now loss =  0.05898577850175126  accuracy =  0.9375\n",
      "now loss =  0.08745567205732539  accuracy =  0.890625\n",
      "now loss =  0.10121049153737333  accuracy =  0.84375\n",
      "now loss =  0.06911873096558402  accuracy =  0.953125\n",
      "now loss =  0.11014255778358616  accuracy =  0.828125\n",
      "now loss =  0.09386934061041154  accuracy =  0.859375\n",
      "now loss =  0.0703706627110812  accuracy =  0.921875\n",
      "now loss =  0.10428411063188933  accuracy =  0.859375\n",
      "now loss =  0.08629382730811799  accuracy =  0.921875\n",
      "now loss =  0.06659216010974318  accuracy =  0.90625\n",
      "now loss =  0.10117556767774963  accuracy =  0.859375\n",
      "now loss =  0.0628202717714757  accuracy =  0.921875\n",
      "now loss =  0.10345606388292133  accuracy =  0.828125\n",
      "now loss =  0.08775720426507191  accuracy =  0.9\n",
      "now loss =  0.10454929387078506  accuracy =  0.84375\n",
      "now loss =  0.0712365683515591  accuracy =  0.921875\n",
      "now loss =  0.08881588632122156  accuracy =  0.875\n",
      "now loss =  0.07640217490684445  accuracy =  0.890625\n",
      "now loss =  0.085167925450735  accuracy =  0.90625\n",
      "now loss =  0.10204911093644357  accuracy =  0.828125\n",
      "now loss =  0.08203195874445801  accuracy =  0.875\n",
      "now loss =  0.08958027716559583  accuracy =  0.84375\n",
      "now loss =  0.0648301950960746  accuracy =  0.9375\n",
      "now loss =  0.061089269987561826  accuracy =  0.921875\n",
      "now loss =  0.08686866195925216  accuracy =  0.859375\n",
      "now loss =  0.07983809696133279  accuracy =  0.90625\n",
      "now loss =  0.07894755751657244  accuracy =  0.90625\n",
      "now loss =  0.1307654281343425  accuracy =  0.796875\n",
      "now loss =  0.0703908098645337  accuracy =  0.921875\n",
      "now loss =  0.12256709013305618  accuracy =  0.9\n",
      "now loss =  0.0859346339894575  accuracy =  0.890625\n",
      "now loss =  0.07184334478098725  accuracy =  0.921875\n",
      "now loss =  0.11838278652273289  accuracy =  0.796875\n",
      "now loss =  0.08737937711102983  accuracy =  0.875\n",
      "now loss =  0.09336972060289496  accuracy =  0.859375\n",
      "now loss =  0.08726377294467108  accuracy =  0.859375\n",
      "now loss =  0.0963921973362991  accuracy =  0.890625\n",
      "now loss =  0.0853927786026392  accuracy =  0.875\n",
      "now loss =  0.0779192312303616  accuracy =  0.890625\n",
      "now loss =  0.07026760329350865  accuracy =  0.921875\n",
      "now loss =  0.09742244608662542  accuracy =  0.875\n",
      "now loss =  0.07160779143528348  accuracy =  0.9375\n",
      "now loss =  0.09005242343163447  accuracy =  0.890625\n",
      "now loss =  0.0997331587530161  accuracy =  0.890625\n",
      "now loss =  0.0648383670187363  accuracy =  0.90625\n",
      "now loss =  0.07598193014538004  accuracy =  0.9\n",
      "now loss =  0.0763413557550453  accuracy =  0.9375\n",
      "now loss =  0.08373439993228977  accuracy =  0.921875\n",
      "now loss =  0.1052270400873267  accuracy =  0.8125\n",
      "now loss =  0.10271789308225071  accuracy =  0.859375\n",
      "now loss =  0.07705321280319778  accuracy =  0.90625\n",
      "now loss =  0.07029799814236626  accuracy =  0.921875\n",
      "now loss =  0.08625674471182677  accuracy =  0.84375\n",
      "now loss =  0.11831228375011585  accuracy =  0.828125\n",
      "now loss =  0.0791340821942613  accuracy =  0.890625\n",
      "now loss =  0.09623348822278976  accuracy =  0.875\n",
      "now loss =  0.07335792867968655  accuracy =  0.921875\n",
      "now loss =  0.10158029730921869  accuracy =  0.875\n",
      "now loss =  0.09435168711057193  accuracy =  0.890625\n",
      "now loss =  0.07509220373985344  accuracy =  0.921875\n",
      "now loss =  0.06465652767931701  accuracy =  0.90625\n",
      "now loss =  0.0965124822552001  accuracy =  0.85\n",
      "now loss =  0.09004659565285962  accuracy =  0.90625\n",
      "now loss =  0.06225650067786734  accuracy =  0.9375\n",
      "now loss =  0.11943370869254497  accuracy =  0.78125\n",
      "now loss =  0.07336811648536548  accuracy =  0.9375\n",
      "now loss =  0.11004928431066766  accuracy =  0.84375\n",
      "now loss =  0.05841244315229702  accuracy =  0.9375\n",
      "now loss =  0.13755216417519828  accuracy =  0.796875\n",
      "now loss =  0.08981492768745092  accuracy =  0.859375\n",
      "now loss =  0.0635022218072567  accuracy =  0.9375\n",
      "now loss =  0.08794903957401422  accuracy =  0.875\n",
      "now loss =  0.0763244199405689  accuracy =  0.921875\n",
      "now loss =  0.06375206667627208  accuracy =  0.9375\n",
      "now loss =  0.08626077341342664  accuracy =  0.875\n",
      "now loss =  0.09075826756782866  accuracy =  0.859375\n",
      "now loss =  0.09206738057430047  accuracy =  0.890625\n",
      "now loss =  0.06827884806147903  accuracy =  0.9\n",
      "now loss =  0.08424464501063576  accuracy =  0.90625\n",
      "now loss =  0.06879347708569697  accuracy =  0.890625\n",
      "now loss =  0.11333089426841175  accuracy =  0.828125\n",
      "now loss =  0.06875857514257155  accuracy =  0.90625\n",
      "now loss =  0.09759016024563474  accuracy =  0.859375\n",
      "now loss =  0.11050032887010905  accuracy =  0.84375\n",
      "now loss =  0.064652546504648  accuracy =  0.90625\n",
      "now loss =  0.05353801706289964  accuracy =  0.984375\n",
      "now loss =  0.10624069001983436  accuracy =  0.84375\n",
      "now loss =  0.09448576768894615  accuracy =  0.90625\n",
      "now loss =  0.1089586391107366  accuracy =  0.859375\n",
      "now loss =  0.07195232921250347  accuracy =  0.90625\n",
      "now loss =  0.09028311612876153  accuracy =  0.859375\n",
      "now loss =  0.08731735167803437  accuracy =  0.890625\n",
      "now loss =  0.062239638348000136  accuracy =  0.921875\n",
      "now loss =  0.09475568738266468  accuracy =  0.85\n",
      "now loss =  0.04939296233834505  accuracy =  0.953125\n",
      "now loss =  0.09649178822591062  accuracy =  0.84375\n",
      "now loss =  0.0648072134164258  accuracy =  0.921875\n",
      "now loss =  0.09587315871511276  accuracy =  0.859375\n",
      "now loss =  0.08963400105680264  accuracy =  0.890625\n",
      "now loss =  0.07533841028445046  accuracy =  0.921875\n",
      "now loss =  0.09145778926475048  accuracy =  0.890625\n",
      "now loss =  0.07615880727560659  accuracy =  0.9375\n",
      "now loss =  0.08769510281924428  accuracy =  0.875\n",
      "now loss =  0.09540541038098362  accuracy =  0.84375\n",
      "now loss =  0.08808976746341554  accuracy =  0.84375\n",
      "now loss =  0.09201676464760071  accuracy =  0.921875\n",
      "now loss =  0.09510576646032473  accuracy =  0.84375\n",
      "now loss =  0.0894310196647237  accuracy =  0.859375\n",
      "now loss =  0.10930074784243107  accuracy =  0.875\n",
      "now loss =  0.08537596020355538  accuracy =  0.875\n",
      "now loss =  0.08408883407088422  accuracy =  0.90625\n",
      "now loss =  0.09757507446542413  accuracy =  0.875\n",
      "now loss =  0.07124424361847871  accuracy =  0.875\n",
      "now loss =  0.09988580067865233  accuracy =  0.859375\n",
      "now loss =  0.08657701715126898  accuracy =  0.90625\n",
      "now loss =  0.07065185396193238  accuracy =  0.890625\n",
      "now loss =  0.10208189915503066  accuracy =  0.84375\n",
      "now loss =  0.08150790018320382  accuracy =  0.90625\n",
      "now loss =  0.07868372244282969  accuracy =  0.890625\n",
      "now loss =  0.07054694396488824  accuracy =  0.921875\n",
      "now loss =  0.09388081858624786  accuracy =  0.859375\n",
      "now loss =  0.0730521253814095  accuracy =  0.921875\n",
      "now loss =  0.09554095330789403  accuracy =  0.875\n",
      "now loss =  0.0910719805811748  accuracy =  0.890625\n",
      "now loss =  0.0889207186548655  accuracy =  0.828125\n",
      "now loss =  0.10323810282232282  accuracy =  0.875\n",
      "now loss =  0.07686979554205357  accuracy =  0.90625\n",
      "now loss =  0.08881677383907169  accuracy =  0.890625\n",
      "now loss =  0.09502187629864028  accuracy =  0.859375\n",
      "now loss =  0.08225593429873268  accuracy =  0.90625\n",
      "now loss =  0.07522046177581378  accuracy =  0.90625\n",
      "now loss =  0.09574051660033348  accuracy =  0.875\n",
      "now loss =  0.07397059847029183  accuracy =  0.90625\n",
      "now loss =  0.06470191955847787  accuracy =  0.921875\n",
      "now loss =  0.12248710778022212  accuracy =  0.8125\n",
      "now loss =  0.08309613934215425  accuracy =  0.875\n",
      "now loss =  0.12098795488870998  accuracy =  0.78125\n",
      "now loss =  0.06855834156387358  accuracy =  0.90625\n",
      "now loss =  0.06485415051668598  accuracy =  0.953125\n",
      "now loss =  0.10657164988221447  accuracy =  0.828125\n",
      "now loss =  0.05756644661797382  accuracy =  0.953125\n",
      "now loss =  0.10664654260699284  accuracy =  0.825\n",
      "now loss =  0.08578049905425597  accuracy =  0.921875\n",
      "now loss =  0.07178839225015046  accuracy =  0.890625\n",
      "now loss =  0.08259860184162536  accuracy =  0.921875\n",
      "now loss =  0.09350972541243883  accuracy =  0.859375\n",
      "now loss =  0.07754778574628887  accuracy =  0.890625\n",
      "now loss =  0.07975833797225892  accuracy =  0.90625\n",
      "now loss =  0.08298939024562979  accuracy =  0.875\n",
      "now loss =  0.06965609162972164  accuracy =  0.921875\n",
      "now loss =  0.07698950330062757  accuracy =  0.90625\n",
      "now loss =  0.12472233536414692  accuracy =  0.8125\n",
      "now loss =  0.08671275099443679  accuracy =  0.84375\n",
      "now loss =  0.11808170717918559  accuracy =  0.8125\n",
      "now loss =  0.09301344761448754  accuracy =  0.875\n",
      "now loss =  0.1018293442156747  accuracy =  0.859375\n",
      "now loss =  0.05397739304006764  accuracy =  0.953125\n",
      "now loss =  0.08643635502583437  accuracy =  0.875\n",
      "now loss =  0.08045640549762836  accuracy =  0.875\n",
      "now loss =  0.10072525971274197  accuracy =  0.828125\n",
      "now loss =  0.055758077177438886  accuracy =  0.96875\n",
      "now loss =  0.12356016461368241  accuracy =  0.828125\n",
      "now loss =  0.07285346926233252  accuracy =  0.90625\n",
      "now loss =  0.10114004860517897  accuracy =  0.890625\n",
      "now loss =  0.1020676343039271  accuracy =  0.828125\n",
      "now loss =  0.08545976179372246  accuracy =  0.875\n",
      "now loss =  0.10184494157815614  accuracy =  0.828125\n",
      "now loss =  0.08974673910255189  accuracy =  0.875\n",
      "now loss =  0.07094366879887228  accuracy =  0.890625\n",
      "now loss =  0.08981083787922421  accuracy =  0.875\n",
      "now loss =  0.09876231556473612  accuracy =  0.875\n",
      "now loss =  0.06354179968884369  accuracy =  0.953125\n",
      "now loss =  0.06324271277268774  accuracy =  0.921875\n",
      "now loss =  0.0662990983017437  accuracy =  0.9\n",
      "now loss =  0.10656793981065575  accuracy =  0.8125\n",
      "now loss =  0.053225809423503245  accuracy =  0.9375\n",
      "now loss =  0.053423777146711704  accuracy =  0.953125\n",
      "now loss =  0.11545495858252208  accuracy =  0.828125\n",
      "now loss =  0.08836184390026328  accuracy =  0.875\n",
      "now loss =  0.1094424578863219  accuracy =  0.859375\n",
      "now loss =  0.07826562510274787  accuracy =  0.875\n",
      "now loss =  0.08128891920721072  accuracy =  0.890625\n",
      "now loss =  0.08337403979944444  accuracy =  0.875\n",
      "now loss =  0.08617028749149043  accuracy =  0.921875\n",
      "now loss =  0.07654851720636502  accuracy =  0.890625\n",
      "now loss =  0.09244962241836513  accuracy =  0.875\n",
      "now loss =  0.08340597084047  accuracy =  0.921875\n",
      "now loss =  0.10156891509559904  accuracy =  0.875\n",
      "now loss =  0.07053729781126433  accuracy =  0.921875\n",
      "now loss =  0.11159217560799253  accuracy =  0.825\n",
      "now loss =  0.0970474644995807  accuracy =  0.875\n",
      "now loss =  0.09066814055577758  accuracy =  0.875\n",
      "now loss =  0.0982950067822769  accuracy =  0.875\n",
      "now loss =  0.1100026943523155  accuracy =  0.828125\n",
      "now loss =  0.08768858787497982  accuracy =  0.90625\n",
      "now loss =  0.08889427467845362  accuracy =  0.859375\n",
      "now loss =  0.059383247240163306  accuracy =  0.953125\n",
      "now loss =  0.09103161334271778  accuracy =  0.84375\n",
      "now loss =  0.06091739253358204  accuracy =  0.9375\n",
      "now loss =  0.10622108282763454  accuracy =  0.828125\n",
      "now loss =  0.06287494839793673  accuracy =  0.890625\n",
      "now loss =  0.06830780090659906  accuracy =  0.921875\n",
      "now loss =  0.10429914007325924  accuracy =  0.828125\n",
      "now loss =  0.07243944866508104  accuracy =  0.90625\n",
      "now loss =  0.09875627516617884  accuracy =  0.890625\n",
      "now loss =  0.08617047443011616  accuracy =  0.9\n",
      "now loss =  0.09592320751200868  accuracy =  0.84375\n",
      "now loss =  0.1110390531408031  accuracy =  0.828125\n",
      "now loss =  0.08446442044047167  accuracy =  0.859375\n",
      "now loss =  0.0876485587741108  accuracy =  0.875\n",
      "now loss =  0.078399811419467  accuracy =  0.90625\n",
      "now loss =  0.09098366355058385  accuracy =  0.890625\n",
      "now loss =  0.07598541418629534  accuracy =  0.890625\n",
      "now loss =  0.0701614825311451  accuracy =  0.90625\n",
      "now loss =  0.09425605099394246  accuracy =  0.859375\n",
      "now loss =  0.07696423514625611  accuracy =  0.890625\n",
      "now loss =  0.07234435276847886  accuracy =  0.890625\n",
      "now loss =  0.07120414963482469  accuracy =  0.9375\n",
      "now loss =  0.07971740190317556  accuracy =  0.90625\n",
      "now loss =  0.07585491562168639  accuracy =  0.90625\n",
      "now loss =  0.08865768193228121  accuracy =  0.890625\n",
      "now loss =  0.135224497744417  accuracy =  0.8\n",
      "now loss =  0.06282264237436398  accuracy =  0.9375\n",
      "now loss =  0.06579526357503351  accuracy =  0.90625\n",
      "now loss =  0.10153167636464279  accuracy =  0.828125\n",
      "now loss =  0.10181914983630107  accuracy =  0.890625\n",
      "now loss =  0.09128099825083585  accuracy =  0.84375\n",
      "now loss =  0.06081751459404523  accuracy =  0.96875\n",
      "now loss =  0.10742182028350408  accuracy =  0.8125\n",
      "now loss =  0.09602698595387492  accuracy =  0.875\n",
      "now loss =  0.07638853985681268  accuracy =  0.90625\n",
      "now loss =  0.08488619229792152  accuracy =  0.90625\n",
      "now loss =  0.10003341292960666  accuracy =  0.84375\n",
      "now loss =  0.07831572996383981  accuracy =  0.90625\n",
      "now loss =  0.07799323877482006  accuracy =  0.90625\n",
      "now loss =  0.09516278519191768  accuracy =  0.84375\n",
      "now loss =  0.08503728048046941  accuracy =  0.90625\n",
      "now loss =  0.09151627167946866  accuracy =  0.875\n",
      "now loss =  0.08231029914854918  accuracy =  0.875\n",
      "now loss =  0.06396936319788181  accuracy =  0.953125\n",
      "now loss =  0.1140432378909271  accuracy =  0.8125\n",
      "now loss =  0.0993792470403457  accuracy =  0.859375\n",
      "now loss =  0.08925790971150437  accuracy =  0.875\n",
      "now loss =  0.08889335775740549  accuracy =  0.890625\n",
      "now loss =  0.06250831932605896  accuracy =  0.953125\n",
      "now loss =  0.09396258711292531  accuracy =  0.84375\n",
      "now loss =  0.0883914988607511  accuracy =  0.890625\n",
      "now loss =  0.07805599843067024  accuracy =  0.875\n",
      "now loss =  0.05591465977619832  accuracy =  0.921875\n",
      "now loss =  0.0789484205220951  accuracy =  0.90625\n",
      "now loss =  0.1034475677545528  accuracy =  0.84375\n",
      "now loss =  0.09483997650607864  accuracy =  0.890625\n",
      "now loss =  0.08974478431626534  accuracy =  0.875\n",
      "now loss =  0.08907034075635892  accuracy =  0.925\n",
      "now loss =  0.08107941788512141  accuracy =  0.890625\n",
      "now loss =  0.09570847141685837  accuracy =  0.84375\n",
      "now loss =  0.07964873028346586  accuracy =  0.890625\n",
      "now loss =  0.10993851017610826  accuracy =  0.859375\n",
      "now loss =  0.07249493087765206  accuracy =  0.890625\n",
      "now loss =  0.08365851789361624  accuracy =  0.875\n",
      "now loss =  0.08902415302035202  accuracy =  0.90625\n",
      "now loss =  0.0864757744491604  accuracy =  0.859375\n",
      "now loss =  0.06966525432269016  accuracy =  0.90625\n",
      "now loss =  0.08283759170933461  accuracy =  0.890625\n",
      "now loss =  0.07155698555991832  accuracy =  0.953125\n",
      "now loss =  0.08595415947527149  accuracy =  0.90625\n",
      "now loss =  0.08889325820511602  accuracy =  0.921875\n",
      "now loss =  0.09838926141896312  accuracy =  0.859375\n",
      "now loss =  0.08986794849238244  accuracy =  0.828125\n",
      "now loss =  0.08894959505205553  accuracy =  0.9\n",
      "now loss =  0.08023033906565166  accuracy =  0.90625\n",
      "now loss =  0.07925751034054537  accuracy =  0.90625\n",
      "now loss =  0.07759762861426642  accuracy =  0.921875\n",
      "now loss =  0.07656651202046125  accuracy =  0.90625\n",
      "now loss =  0.11990226747427304  accuracy =  0.78125\n",
      "now loss =  0.09748702408869964  accuracy =  0.875\n",
      "now loss =  0.08326178064829376  accuracy =  0.875\n",
      "now loss =  0.0876224080917954  accuracy =  0.890625\n",
      "now loss =  0.09937526520579146  accuracy =  0.875\n",
      "now loss =  0.05405389643898189  accuracy =  0.9375\n",
      "now loss =  0.06631374404305851  accuracy =  0.9375\n",
      "now loss =  0.09668584062116253  accuracy =  0.796875\n",
      "now loss =  0.11625901690176475  accuracy =  0.78125\n",
      "now loss =  0.0803654635070165  accuracy =  0.890625\n",
      "now loss =  0.09771271115310207  accuracy =  0.875\n",
      "now loss =  0.04891846687961273  accuracy =  0.975\n",
      "now loss =  0.09223606281515323  accuracy =  0.859375\n",
      "now loss =  0.07850799352870906  accuracy =  0.90625\n",
      "now loss =  0.1027952582611937  accuracy =  0.828125\n",
      "now loss =  0.08335010957753067  accuracy =  0.90625\n",
      "now loss =  0.0673269498228817  accuracy =  0.921875\n",
      "now loss =  0.09958097751002246  accuracy =  0.859375\n",
      "now loss =  0.09601610192288577  accuracy =  0.84375\n",
      "now loss =  0.08211364754729984  accuracy =  0.921875\n",
      "now loss =  0.06915322679883568  accuracy =  0.90625\n",
      "now loss =  0.0878302270309354  accuracy =  0.875\n",
      "now loss =  0.0993973652056906  accuracy =  0.875\n",
      "now loss =  0.06742625150747146  accuracy =  0.921875\n",
      "now loss =  0.07635231977046057  accuracy =  0.875\n",
      "now loss =  0.09110791429400694  accuracy =  0.875\n",
      "now loss =  0.08888084474653604  accuracy =  0.859375\n",
      "now loss =  0.0896422202841636  accuracy =  0.925\n",
      "now loss =  0.13687582827446923  accuracy =  0.734375\n",
      "now loss =  0.0663426308009302  accuracy =  0.9375\n",
      "now loss =  0.09165593315545016  accuracy =  0.875\n",
      "now loss =  0.09565471981049409  accuracy =  0.84375\n",
      "now loss =  0.07569824227823613  accuracy =  0.921875\n",
      "now loss =  0.1008729053004748  accuracy =  0.890625\n",
      "now loss =  0.06013994258690555  accuracy =  0.9375\n",
      "now loss =  0.10865456724168229  accuracy =  0.859375\n",
      "now loss =  0.06474398984498284  accuracy =  0.90625\n",
      "now loss =  0.08948646459906544  accuracy =  0.859375\n",
      "now loss =  0.09327466592595209  accuracy =  0.84375\n",
      "now loss =  0.08821427253595301  accuracy =  0.859375\n",
      "now loss =  0.06251500301641459  accuracy =  0.921875\n",
      "now loss =  0.07982304915474117  accuracy =  0.921875\n",
      "now loss =  0.08449175438596787  accuracy =  0.890625\n",
      "now loss =  0.06480300476879727  accuracy =  0.975\n",
      "now loss =  0.08295400490678187  accuracy =  0.875\n",
      "now loss =  0.09114581187471851  accuracy =  0.875\n",
      "now loss =  0.1297069496360649  accuracy =  0.78125\n",
      "now loss =  0.0992455156809582  accuracy =  0.859375\n",
      "now loss =  0.0731725188264034  accuracy =  0.921875\n",
      "now loss =  0.13182938937838934  accuracy =  0.859375\n",
      "now loss =  0.0619652518844439  accuracy =  0.921875\n",
      "now loss =  0.060355865214598674  accuracy =  0.921875\n",
      "now loss =  0.08320476040857913  accuracy =  0.890625\n",
      "now loss =  0.09335879607807701  accuracy =  0.875\n",
      "now loss =  0.08472536269703493  accuracy =  0.875\n",
      "now loss =  0.08939573156658413  accuracy =  0.90625\n",
      "now loss =  0.08328287068049375  accuracy =  0.875\n",
      "now loss =  0.09374574552608927  accuracy =  0.859375\n",
      "now loss =  0.05583104250714459  accuracy =  0.984375\n",
      "now loss =  0.05620710665904085  accuracy =  0.925\n",
      "now loss =  0.10870297312091168  accuracy =  0.84375\n",
      "now loss =  0.07338545082387082  accuracy =  0.890625\n",
      "now loss =  0.09298473121601816  accuracy =  0.890625\n",
      "now loss =  0.0870581364335013  accuracy =  0.859375\n",
      "now loss =  0.08043596106002612  accuracy =  0.875\n",
      "now loss =  0.07080573574150241  accuracy =  0.921875\n",
      "now loss =  0.0857094921085438  accuracy =  0.90625\n",
      "now loss =  0.06156800146292725  accuracy =  0.953125\n",
      "now loss =  0.0742748982977295  accuracy =  0.90625\n",
      "now loss =  0.07125800726718606  accuracy =  0.90625\n",
      "now loss =  0.0960278271521684  accuracy =  0.828125\n",
      "now loss =  0.11153585109530981  accuracy =  0.84375\n",
      "now loss =  0.10502455238100894  accuracy =  0.84375\n",
      "now loss =  0.08184888685344568  accuracy =  0.921875\n",
      "now loss =  0.08435993480215914  accuracy =  0.90625\n",
      "now loss =  0.08880937742122642  accuracy =  0.85\n",
      "now loss =  0.0648610495929156  accuracy =  0.9375\n",
      "now loss =  0.0672076471030815  accuracy =  0.9375\n",
      "now loss =  0.0769405314397946  accuracy =  0.890625\n",
      "now loss =  0.0818991138959411  accuracy =  0.890625\n",
      "now loss =  0.043709665124872676  accuracy =  0.9375\n",
      "now loss =  0.07465667462989072  accuracy =  0.90625\n",
      "now loss =  0.11093129585790308  accuracy =  0.828125\n",
      "now loss =  0.09529575198857625  accuracy =  0.890625\n",
      "now loss =  0.10531816135629882  accuracy =  0.8125\n",
      "now loss =  0.09965757953442014  accuracy =  0.875\n",
      "now loss =  0.09509189465576665  accuracy =  0.859375\n",
      "now loss =  0.08269272333897239  accuracy =  0.890625\n",
      "now loss =  0.09264664049214474  accuracy =  0.875\n",
      "now loss =  0.07840397295423956  accuracy =  0.890625\n",
      "now loss =  0.12089219108888061  accuracy =  0.84375\n",
      "now loss =  0.0775563307821711  accuracy =  0.875\n",
      "now loss =  0.06377908836922677  accuracy =  0.90625\n",
      "now loss =  0.08355019560207749  accuracy =  0.859375\n",
      "now loss =  0.07615527300461616  accuracy =  0.90625\n",
      "now loss =  0.07190234408122656  accuracy =  0.921875\n",
      "now loss =  0.08248974837362472  accuracy =  0.859375\n",
      "now loss =  0.08898748250208444  accuracy =  0.90625\n",
      "now loss =  0.07555350419021395  accuracy =  0.90625\n",
      "now loss =  0.079560983795952  accuracy =  0.90625\n",
      "now loss =  0.1053069205086695  accuracy =  0.84375\n",
      "now loss =  0.08189976624082798  accuracy =  0.890625\n",
      "now loss =  0.08179182842669223  accuracy =  0.90625\n",
      "now loss =  0.09396634313495425  accuracy =  0.875\n",
      "now loss =  0.09453303249415435  accuracy =  0.890625\n",
      "now loss =  0.10733845607111028  accuracy =  0.8125\n",
      "now loss =  0.10110337557579294  accuracy =  0.84375\n",
      "now loss =  0.08220766819896481  accuracy =  0.925\n",
      "now loss =  0.07062524293180998  accuracy =  0.953125\n",
      "now loss =  0.10745716502274345  accuracy =  0.828125\n",
      "now loss =  0.05531385110123241  accuracy =  0.9375\n",
      "now loss =  0.08765480635373935  accuracy =  0.859375\n",
      "now loss =  0.08891897859319745  accuracy =  0.84375\n",
      "now loss =  0.07804053928811523  accuracy =  0.953125\n",
      "now loss =  0.07754763435663144  accuracy =  0.921875\n",
      "now loss =  0.10056095884572741  accuracy =  0.8125\n",
      "now loss =  0.12988667759510328  accuracy =  0.765625\n",
      "now loss =  0.07842715897134533  accuracy =  0.890625\n",
      "now loss =  0.09097524687707395  accuracy =  0.859375\n",
      "now loss =  0.07752339112456946  accuracy =  0.875\n",
      "now loss =  0.07095989134589137  accuracy =  0.921875\n",
      "now loss =  0.09642064071000177  accuracy =  0.875\n",
      "now loss =  0.08290476758202521  accuracy =  0.890625\n",
      "now loss =  0.07294769958299008  accuracy =  0.925\n",
      "now loss =  0.07304278513160808  accuracy =  0.90625\n",
      "now loss =  0.09866022514797111  accuracy =  0.828125\n",
      "now loss =  0.1208845915033255  accuracy =  0.828125\n",
      "now loss =  0.08286057712354533  accuracy =  0.875\n",
      "now loss =  0.09701389243413978  accuracy =  0.859375\n",
      "now loss =  0.0654187393624171  accuracy =  0.921875\n",
      "now loss =  0.08324951878176896  accuracy =  0.875\n",
      "now loss =  0.07595358141440726  accuracy =  0.90625\n",
      "now loss =  0.08080000399240447  accuracy =  0.890625\n",
      "now loss =  0.09134760984054567  accuracy =  0.859375\n",
      "now loss =  0.09553381853431521  accuracy =  0.859375\n",
      "now loss =  0.11127222890317646  accuracy =  0.859375\n",
      "now loss =  0.06767343444069795  accuracy =  0.921875\n",
      "now loss =  0.05908257326054045  accuracy =  0.953125\n",
      "now loss =  0.07434359136046252  accuracy =  0.9375\n",
      "now loss =  0.10019712360840476  accuracy =  0.85\n",
      "now loss =  0.08072709032920192  accuracy =  0.890625\n",
      "now loss =  0.11991646259188879  accuracy =  0.8125\n",
      "now loss =  0.08130238622277969  accuracy =  0.90625\n",
      "now loss =  0.06451020048727137  accuracy =  0.90625\n",
      "now loss =  0.08661416587643642  accuracy =  0.890625\n",
      "now loss =  0.09775967658866552  accuracy =  0.859375\n",
      "now loss =  0.08638712710012478  accuracy =  0.828125\n",
      "now loss =  0.10538793853173195  accuracy =  0.875\n",
      "now loss =  0.08502035245937581  accuracy =  0.859375\n",
      "now loss =  0.08050086683024787  accuracy =  0.90625\n",
      "now loss =  0.09759022338526611  accuracy =  0.8125\n",
      "now loss =  0.0591080612819665  accuracy =  0.96875\n",
      "now loss =  0.06938406212632921  accuracy =  0.953125\n",
      "now loss =  0.09173061461382136  accuracy =  0.890625\n",
      "now loss =  0.09219264068141905  accuracy =  0.859375\n",
      "now loss =  0.06274344179560967  accuracy =  0.925\n",
      "now loss =  0.08594544870603774  accuracy =  0.890625\n",
      "now loss =  0.08480910346295337  accuracy =  0.90625\n",
      "now loss =  0.0777564612453975  accuracy =  0.921875\n",
      "now loss =  0.09766578123828468  accuracy =  0.890625\n",
      "now loss =  0.08045996072454195  accuracy =  0.875\n",
      "now loss =  0.11096466721582067  accuracy =  0.84375\n",
      "now loss =  0.07920200685275672  accuracy =  0.875\n",
      "now loss =  0.09285350336945934  accuracy =  0.875\n",
      "now loss =  0.10533665418868426  accuracy =  0.859375\n",
      "now loss =  0.07260879946732737  accuracy =  0.890625\n",
      "now loss =  0.054744580276573196  accuracy =  0.9375\n",
      "now loss =  0.07855991944026615  accuracy =  0.875\n",
      "now loss =  0.11711220726887905  accuracy =  0.8125\n",
      "now loss =  0.07751496388655205  accuracy =  0.890625\n",
      "now loss =  0.07382684021094713  accuracy =  0.90625\n",
      "now loss =  0.08301251284307753  accuracy =  0.9\n",
      "now loss =  0.10966766589915786  accuracy =  0.859375\n",
      "now loss =  0.07306850266205114  accuracy =  0.890625\n",
      "now loss =  0.08099374649921508  accuracy =  0.890625\n",
      "now loss =  0.09519038855851855  accuracy =  0.828125\n",
      "now loss =  0.08155499756200013  accuracy =  0.890625\n",
      "now loss =  0.08379501077957718  accuracy =  0.9375\n",
      "now loss =  0.10746155192999095  accuracy =  0.859375\n",
      "now loss =  0.05783587356792407  accuracy =  0.9375\n",
      "now loss =  0.08848357045155146  accuracy =  0.90625\n",
      "now loss =  0.07920267008174234  accuracy =  0.875\n",
      "now loss =  0.07729172714837518  accuracy =  0.921875\n",
      "now loss =  0.11247362051457502  accuracy =  0.8125\n",
      "now loss =  0.09174646156256952  accuracy =  0.875\n",
      "now loss =  0.06915200420596507  accuracy =  0.9375\n",
      "now loss =  0.09047104767322439  accuracy =  0.890625\n",
      "now loss =  0.06352781527782261  accuracy =  0.925\n",
      "now loss =  0.08569844861306367  accuracy =  0.90625\n",
      "now loss =  0.09619422562792113  accuracy =  0.875\n",
      "now loss =  0.06345468571381283  accuracy =  0.9375\n",
      "now loss =  0.06643889765163881  accuracy =  0.90625\n",
      "now loss =  0.08307812236653314  accuracy =  0.890625\n",
      "now loss =  0.10069942812820919  accuracy =  0.828125\n",
      "now loss =  0.08733875172158292  accuracy =  0.90625\n",
      "now loss =  0.06608308905037573  accuracy =  0.9375\n",
      "now loss =  0.09367326973838506  accuracy =  0.859375\n",
      "now loss =  0.09974181883850383  accuracy =  0.84375\n",
      "now loss =  0.09278086431696511  accuracy =  0.921875\n",
      "now loss =  0.09178872517238217  accuracy =  0.84375\n",
      "now loss =  0.10486516523729822  accuracy =  0.84375\n",
      "now loss =  0.08275035366043507  accuracy =  0.890625\n",
      "now loss =  0.054436003530325495  accuracy =  0.96875\n",
      "now loss =  0.13426964077937634  accuracy =  0.75\n",
      "now loss =  0.07701368752293344  accuracy =  0.9375\n",
      "now loss =  0.10302554799158674  accuracy =  0.859375\n",
      "now loss =  0.07513505039398162  accuracy =  0.90625\n",
      "now loss =  0.07668923330396119  accuracy =  0.890625\n",
      "now loss =  0.08692534907498281  accuracy =  0.890625\n",
      "now loss =  0.10126420302776414  accuracy =  0.84375\n",
      "now loss =  0.06483439409118939  accuracy =  0.90625\n",
      "now loss =  0.09230269177558585  accuracy =  0.84375\n",
      "now loss =  0.10285272608072273  accuracy =  0.84375\n",
      "now loss =  0.08809688028681813  accuracy =  0.875\n",
      "now loss =  0.11693126011196539  accuracy =  0.84375\n",
      "now loss =  0.0899753721580677  accuracy =  0.890625\n",
      "now loss =  0.05305630569214124  accuracy =  0.96875\n",
      "now loss =  0.0714073058897858  accuracy =  0.90625\n",
      "now loss =  0.08212996720190907  accuracy =  0.875\n",
      "now loss =  0.08592020716414901  accuracy =  0.875\n",
      "now loss =  0.08732882397704189  accuracy =  0.859375\n",
      "now loss =  0.08988839363896896  accuracy =  0.84375\n",
      "now loss =  0.09483402390638497  accuracy =  0.828125\n",
      "now loss =  0.08635786593336668  accuracy =  0.875\n",
      "now loss =  0.08360721935467907  accuracy =  0.921875\n",
      "now loss =  0.07804320200450443  accuracy =  0.90625\n",
      "now loss =  0.0698796594683563  accuracy =  0.90625\n",
      "now loss =  0.055919708108675206  accuracy =  0.921875\n",
      "now loss =  0.10168751394958843  accuracy =  0.84375\n",
      "now loss =  0.062142493744080395  accuracy =  0.9375\n",
      "now loss =  0.0845186294425225  accuracy =  0.90625\n",
      "now loss =  0.0924376990391739  accuracy =  0.828125\n",
      "now loss =  0.12080671012583477  accuracy =  0.8125\n",
      "now loss =  0.1155772524861938  accuracy =  0.84375\n",
      "now loss =  0.07881203382297589  accuracy =  0.90625\n",
      "now loss =  0.07599518267550866  accuracy =  0.925\n",
      "now loss =  0.08863080962585344  accuracy =  0.921875\n",
      "now loss =  0.08281002327268538  accuracy =  0.890625\n",
      "now loss =  0.09393645963027536  accuracy =  0.875\n",
      "now loss =  0.08268423335475475  accuracy =  0.890625\n",
      "now loss =  0.06353822018075606  accuracy =  0.953125\n",
      "now loss =  0.08647147901014682  accuracy =  0.890625\n",
      "now loss =  0.08315045212532138  accuracy =  0.921875\n",
      "now loss =  0.08750782621314497  accuracy =  0.859375\n",
      "now loss =  0.07093994879300061  accuracy =  0.9375\n",
      "now loss =  0.08744773101546277  accuracy =  0.890625\n",
      "now loss =  0.10717583814447708  accuracy =  0.8125\n",
      "now loss =  0.08529108064685852  accuracy =  0.890625\n",
      "now loss =  0.08820473556051414  accuracy =  0.859375\n",
      "now loss =  0.08691755058042644  accuracy =  0.828125\n",
      "now loss =  0.09050795138019196  accuracy =  0.84375\n",
      "now loss =  0.08975601383993131  accuracy =  0.9\n",
      "now loss =  0.09698564522494177  accuracy =  0.859375\n",
      "now loss =  0.0786370896782077  accuracy =  0.890625\n",
      "now loss =  0.0785321789883629  accuracy =  0.890625\n",
      "now loss =  0.07927281802218278  accuracy =  0.875\n",
      "now loss =  0.06303766568209454  accuracy =  0.921875\n",
      "now loss =  0.07650861001800882  accuracy =  0.921875\n",
      "now loss =  0.08184815328936962  accuracy =  0.921875\n",
      "now loss =  0.10944819685213154  accuracy =  0.84375\n",
      "now loss =  0.07818801860829055  accuracy =  0.921875\n",
      "now loss =  0.09443482303885486  accuracy =  0.875\n",
      "now loss =  0.1203390673308802  accuracy =  0.796875\n",
      "now loss =  0.08469236322904738  accuracy =  0.90625\n",
      "now loss =  0.07836691434622606  accuracy =  0.90625\n",
      "now loss =  0.08126465050489534  accuracy =  0.890625\n",
      "now loss =  0.09175829480866368  accuracy =  0.84375\n",
      "now loss =  0.08037068324086866  accuracy =  0.9\n",
      "now loss =  0.04530590352430032  accuracy =  0.953125\n",
      "now loss =  0.11554007412656109  accuracy =  0.828125\n",
      "now loss =  0.10040208448420601  accuracy =  0.859375\n",
      "now loss =  0.09151484431421919  accuracy =  0.859375\n",
      "now loss =  0.09251689977180508  accuracy =  0.890625\n",
      "now loss =  0.11380232949081086  accuracy =  0.8125\n",
      "now loss =  0.07364354372903788  accuracy =  0.921875\n",
      "now loss =  0.08853956452856346  accuracy =  0.859375\n",
      "now loss =  0.071360135616127  accuracy =  0.9375\n",
      "now loss =  0.09090314550718247  accuracy =  0.875\n",
      "now loss =  0.06881616983438113  accuracy =  0.90625\n",
      "now loss =  0.08713807222894002  accuracy =  0.875\n",
      "now loss =  0.06792639576359863  accuracy =  0.9375\n",
      "now loss =  0.08215029672766828  accuracy =  0.859375\n",
      "now loss =  0.09476314825029358  accuracy =  0.859375\n",
      "now loss =  0.09027608094733208  accuracy =  0.875\n",
      "now loss =  0.0836570960563041  accuracy =  0.921875\n",
      "now loss =  0.09060166744739007  accuracy =  0.890625\n",
      "now loss =  0.11385807014050042  accuracy =  0.859375\n",
      "now loss =  0.10408252573238785  accuracy =  0.828125\n",
      "now loss =  0.1149335743835627  accuracy =  0.8125\n",
      "now loss =  0.06637644758455004  accuracy =  0.90625\n",
      "now loss =  0.07145109932142352  accuracy =  0.921875\n",
      "now loss =  0.057465228945594415  accuracy =  0.953125\n",
      "now loss =  0.08415005279562449  accuracy =  0.890625\n",
      "now loss =  0.07242574401853263  accuracy =  0.890625\n",
      "now loss =  0.07808396879851462  accuracy =  0.890625\n",
      "now loss =  0.0877971360425705  accuracy =  0.859375\n",
      "now loss =  0.09291059026939635  accuracy =  0.859375\n",
      "now loss =  0.08879404816825817  accuracy =  0.84375\n",
      "now loss =  0.08393576272386928  accuracy =  0.890625\n",
      "now loss =  0.07752245970265789  accuracy =  0.9\n",
      "now loss =  0.08805216064590496  accuracy =  0.84375\n",
      "now loss =  0.10322440702886515  accuracy =  0.828125\n",
      "now loss =  0.10607111933848035  accuracy =  0.84375\n",
      "now loss =  0.10562609218236407  accuracy =  0.84375\n",
      "now loss =  0.05129154954470112  accuracy =  0.953125\n",
      "now loss =  0.08837227146233068  accuracy =  0.875\n",
      "now loss =  0.07770329168332062  accuracy =  0.90625\n",
      "now loss =  0.09505017625421472  accuracy =  0.890625\n",
      "now loss =  0.06646654454244205  accuracy =  0.921875\n",
      "now loss =  0.11019533139900424  accuracy =  0.84375\n",
      "now loss =  0.05888642567075352  accuracy =  0.921875\n",
      "now loss =  0.047953419223449624  accuracy =  0.953125\n",
      "now loss =  0.07271822200249407  accuracy =  0.90625\n",
      "now loss =  0.131880139105175  accuracy =  0.8125\n",
      "now loss =  0.10200458622673805  accuracy =  0.828125\n",
      "now loss =  0.05483981657180603  accuracy =  0.95\n",
      "now loss =  0.0895755364485509  accuracy =  0.875\n",
      "now loss =  0.09638476325205228  accuracy =  0.84375\n",
      "now loss =  0.0571674792931196  accuracy =  0.921875\n",
      "now loss =  0.09720400900131072  accuracy =  0.84375\n",
      "now loss =  0.08320191154355078  accuracy =  0.921875\n",
      "now loss =  0.11383492824621608  accuracy =  0.8125\n",
      "now loss =  0.08044369042870074  accuracy =  0.90625\n",
      "now loss =  0.07462169668257851  accuracy =  0.890625\n",
      "now loss =  0.07987134723679563  accuracy =  0.890625\n",
      "now loss =  0.0881991956655547  accuracy =  0.90625\n",
      "now loss =  0.07208370683372886  accuracy =  0.9375\n",
      "now loss =  0.07071559390882748  accuracy =  0.921875\n",
      "now loss =  0.07630590759482533  accuracy =  0.890625\n",
      "now loss =  0.09236609184953107  accuracy =  0.875\n",
      "now loss =  0.09430521153547268  accuracy =  0.890625\n",
      "now loss =  0.11851827394030896  accuracy =  0.825\n",
      "now loss =  0.08792857936644698  accuracy =  0.90625\n",
      "now loss =  0.09425853279411997  accuracy =  0.859375\n",
      "now loss =  0.07309839461442383  accuracy =  0.890625\n",
      "now loss =  0.08382469238872739  accuracy =  0.875\n",
      "now loss =  0.08099898468720602  accuracy =  0.921875\n",
      "now loss =  0.1160727328914963  accuracy =  0.8125\n",
      "now loss =  0.09727210017101157  accuracy =  0.84375\n",
      "now loss =  0.08574836116515058  accuracy =  0.875\n",
      "now loss =  0.06076743274628512  accuracy =  0.953125\n",
      "now loss =  0.07827266340470179  accuracy =  0.90625\n",
      "now loss =  0.06580597806701721  accuracy =  0.90625\n",
      "now loss =  0.0894457055699809  accuracy =  0.875\n",
      "now loss =  0.09125960328874305  accuracy =  0.84375\n",
      "now loss =  0.10576132911809888  accuracy =  0.859375\n",
      "now loss =  0.08810905793530344  accuracy =  0.921875\n",
      "now loss =  0.07298832132133594  accuracy =  0.95\n",
      "now loss =  0.08640932365279247  accuracy =  0.921875\n",
      "now loss =  0.07127505296625467  accuracy =  0.90625\n",
      "now loss =  0.07261253204391353  accuracy =  0.90625\n",
      "now loss =  0.06932380055139586  accuracy =  0.921875\n",
      "now loss =  0.09831734715097423  accuracy =  0.828125\n",
      "now loss =  0.07818728059974414  accuracy =  0.90625\n",
      "now loss =  0.08884662093222759  accuracy =  0.921875\n",
      "now loss =  0.07959918715879517  accuracy =  0.90625\n",
      "now loss =  0.08323246479432843  accuracy =  0.890625\n",
      "now loss =  0.09667794982028081  accuracy =  0.890625\n",
      "now loss =  0.1013972472185633  accuracy =  0.796875\n",
      "now loss =  0.09301748341208027  accuracy =  0.84375\n",
      "now loss =  0.12122584643998618  accuracy =  0.8125\n",
      "now loss =  0.08225305930930948  accuracy =  0.921875\n",
      "now loss =  0.07578051828957673  accuracy =  0.90625\n",
      "now loss =  0.0642991409902021  accuracy =  0.925\n",
      "now loss =  0.09719676760233009  accuracy =  0.875\n",
      "now loss =  0.0810341589639218  accuracy =  0.859375\n",
      "now loss =  0.08966838203870729  accuracy =  0.890625\n",
      "now loss =  0.08189880495737739  accuracy =  0.859375\n",
      "now loss =  0.0924678367655338  accuracy =  0.875\n",
      "now loss =  0.0725559027300104  accuracy =  0.921875\n",
      "now loss =  0.07961952222934258  accuracy =  0.921875\n",
      "now loss =  0.0775863262120132  accuracy =  0.9375\n",
      "now loss =  0.0975408436481273  accuracy =  0.84375\n",
      "now loss =  0.10041413821647875  accuracy =  0.84375\n",
      "now loss =  0.09162972568711467  accuracy =  0.890625\n",
      "now loss =  0.08653250624856562  accuracy =  0.90625\n",
      "now loss =  0.07669026917569817  accuracy =  0.90625\n",
      "now loss =  0.09448723938644574  accuracy =  0.875\n",
      "now loss =  0.0851252610327712  accuracy =  0.84375\n",
      "now loss =  0.0607786266242608  accuracy =  0.925\n",
      "now loss =  0.11949734035969115  accuracy =  0.828125\n",
      "now loss =  0.05997933069310975  accuracy =  0.90625\n",
      "now loss =  0.09441121099636848  accuracy =  0.875\n",
      "now loss =  0.07399635225961053  accuracy =  0.921875\n",
      "now loss =  0.08240460248885978  accuracy =  0.890625\n",
      "now loss =  0.09863110985849972  accuracy =  0.875\n",
      "now loss =  0.07928523867589245  accuracy =  0.859375\n",
      "now loss =  0.09317382434290722  accuracy =  0.84375\n",
      "now loss =  0.09125171432409038  accuracy =  0.890625\n",
      "now loss =  0.05937453656662067  accuracy =  0.921875\n",
      "now loss =  0.08075716721985743  accuracy =  0.90625\n",
      "now loss =  0.09715748055900322  accuracy =  0.84375\n",
      "now loss =  0.08476838904231918  accuracy =  0.90625\n",
      "now loss =  0.09055366688576584  accuracy =  0.875\n",
      "now loss =  0.0858629569444258  accuracy =  0.9375\n",
      "now loss =  0.08479710416416267  accuracy =  0.875\n",
      "now loss =  0.08291317861946283  accuracy =  0.90625\n",
      "now loss =  0.08112186760070544  accuracy =  0.890625\n",
      "now loss =  0.122621083039007  accuracy =  0.84375\n",
      "now loss =  0.08971684366835546  accuracy =  0.859375\n",
      "now loss =  0.07158525962944226  accuracy =  0.90625\n",
      "now loss =  0.08235684606529325  accuracy =  0.859375\n",
      "now loss =  0.09148588484876892  accuracy =  0.84375\n",
      "now loss =  0.09560928109307472  accuracy =  0.859375\n",
      "now loss =  0.10782983389605236  accuracy =  0.828125\n",
      "now loss =  0.0631493218906084  accuracy =  0.921875\n",
      "now loss =  0.06972159427953932  accuracy =  0.921875\n",
      "now loss =  0.08252494596549592  accuracy =  0.90625\n",
      "now loss =  0.046117860170436537  accuracy =  0.96875\n",
      "now loss =  0.0947269612204362  accuracy =  0.859375\n",
      "now loss =  0.09814084124388306  accuracy =  0.890625\n",
      "now loss =  0.10274229426111932  accuracy =  0.9\n",
      "now loss =  0.13296308182315558  accuracy =  0.765625\n",
      "now loss =  0.08519304488934956  accuracy =  0.875\n",
      "now loss =  0.09242163255403349  accuracy =  0.875\n",
      "now loss =  0.10490686494111538  accuracy =  0.890625\n",
      "now loss =  0.06856994195407347  accuracy =  0.921875\n",
      "now loss =  0.07921931114430211  accuracy =  0.921875\n",
      "now loss =  0.08045665653048123  accuracy =  0.90625\n",
      "now loss =  0.10030714511959994  accuracy =  0.84375\n",
      "now loss =  0.06889477160471227  accuracy =  0.875\n",
      "now loss =  0.07426319141304288  accuracy =  0.921875\n",
      "now loss =  0.0747014689402902  accuracy =  0.90625\n",
      "now loss =  0.055156808125148823  accuracy =  0.921875\n",
      "now loss =  0.07137334727391723  accuracy =  0.921875\n",
      "now loss =  0.09516483624686567  accuracy =  0.875\n",
      "now loss =  0.1079055471599758  accuracy =  0.828125\n",
      "now loss =  0.08887143163579178  accuracy =  0.875\n",
      "now loss =  0.09957074391635533  accuracy =  0.875\n",
      "now loss =  0.09251089244638268  accuracy =  0.875\n",
      "now loss =  0.06991581692716368  accuracy =  0.921875\n",
      "now loss =  0.0877158259473867  accuracy =  0.859375\n",
      "now loss =  0.09007683451474302  accuracy =  0.921875\n",
      "now loss =  0.08416901264645812  accuracy =  0.859375\n",
      "now loss =  0.0774941218378957  accuracy =  0.90625\n",
      "now loss =  0.0716506589721746  accuracy =  0.890625\n",
      "now loss =  0.11883351860128101  accuracy =  0.8125\n",
      "now loss =  0.05970187713641878  accuracy =  0.9375\n",
      "now loss =  0.08247924222161798  accuracy =  0.875\n",
      "now loss =  0.07930236476910199  accuracy =  0.890625\n",
      "now loss =  0.07668588187442103  accuracy =  0.921875\n",
      "now loss =  0.10301207224574024  accuracy =  0.828125\n",
      "now loss =  0.08759982650062739  accuracy =  0.875\n",
      "now loss =  0.09709705130190197  accuracy =  0.85\n",
      "now loss =  0.09783527898268446  accuracy =  0.84375\n",
      "now loss =  0.08821061800826777  accuracy =  0.890625\n",
      "now loss =  0.07746236064023176  accuracy =  0.90625\n",
      "now loss =  0.07767473156527219  accuracy =  0.890625\n",
      "now loss =  0.06754921085073254  accuracy =  0.921875\n",
      "now loss =  0.07963778129137057  accuracy =  0.921875\n",
      "now loss =  0.07968101325397448  accuracy =  0.890625\n",
      "now loss =  0.07580921570580752  accuracy =  0.921875\n",
      "now loss =  0.1037364933620849  accuracy =  0.84375\n",
      "now loss =  0.08900920489140601  accuracy =  0.875\n",
      "now loss =  0.07818403916399905  accuracy =  0.890625\n",
      "now loss =  0.09572302914180245  accuracy =  0.84375\n",
      "now loss =  0.08771002733763159  accuracy =  0.890625\n",
      "now loss =  0.07811586625833997  accuracy =  0.90625\n",
      "now loss =  0.1085072905106971  accuracy =  0.828125\n",
      "now loss =  0.09577945925080081  accuracy =  0.875\n",
      "now loss =  0.0869195011839739  accuracy =  0.90625\n",
      "now loss =  0.0968405663496349  accuracy =  0.859375\n",
      "now loss =  0.10390608044388708  accuracy =  0.8125\n",
      "now loss =  0.08208620641314138  accuracy =  0.90625\n",
      "now loss =  0.08598655463393412  accuracy =  0.84375\n",
      "now loss =  0.074408581828017  accuracy =  0.90625\n",
      "now loss =  0.0780575626366392  accuracy =  0.9375\n",
      "now loss =  0.09241840780807037  accuracy =  0.90625\n",
      "now loss =  0.05246469057410014  accuracy =  0.953125\n",
      "now loss =  0.07946196736813312  accuracy =  0.875\n",
      "now loss =  0.1114545763752535  accuracy =  0.859375\n",
      "now loss =  0.09057262115587313  accuracy =  0.859375\n",
      "now loss =  0.0814929206616461  accuracy =  0.859375\n",
      "now loss =  0.0835870522959253  accuracy =  0.921875\n",
      "now loss =  0.1066135480985499  accuracy =  0.859375\n",
      "now loss =  0.05165190228879862  accuracy =  0.95\n",
      "now loss =  0.10123301148509423  accuracy =  0.828125\n",
      "now loss =  0.06788766759398816  accuracy =  0.90625\n",
      "now loss =  0.07723830070411819  accuracy =  0.90625\n",
      "now loss =  0.07458295561663195  accuracy =  0.890625\n",
      "now loss =  0.07604984642940749  accuracy =  0.90625\n",
      "now loss =  0.09558717710077523  accuracy =  0.859375\n",
      "now loss =  0.10053695969446119  accuracy =  0.828125\n",
      "now loss =  0.09178872694048903  accuracy =  0.890625\n",
      "now loss =  0.095931707563914  accuracy =  0.875\n",
      "now loss =  0.1082968258052095  accuracy =  0.859375\n",
      "now loss =  0.058502412871549524  accuracy =  0.953125\n",
      "now loss =  0.07992365168343657  accuracy =  0.890625\n",
      "now loss =  0.07870348415590911  accuracy =  0.875\n",
      "now loss =  0.09978443715190471  accuracy =  0.84375\n",
      "now loss =  0.08124525042617828  accuracy =  0.875\n",
      "now loss =  0.0843753567817674  accuracy =  0.925\n",
      "now loss =  0.08876272620859929  accuracy =  0.90625\n",
      "now loss =  0.060789560639318944  accuracy =  0.921875\n",
      "now loss =  0.0941504758886437  accuracy =  0.875\n",
      "now loss =  0.09547586421959063  accuracy =  0.859375\n",
      "now loss =  0.09604290006020008  accuracy =  0.859375\n",
      "now loss =  0.09869215613819439  accuracy =  0.828125\n",
      "now loss =  0.09125968678705837  accuracy =  0.859375\n",
      "now loss =  0.07225309572844435  accuracy =  0.90625\n",
      "now loss =  0.10064676137227926  accuracy =  0.859375\n",
      "now loss =  0.06835515939148196  accuracy =  0.921875\n",
      "now loss =  0.09215485721010369  accuracy =  0.859375\n",
      "now loss =  0.07343677917846617  accuracy =  0.953125\n",
      "now loss =  0.08576189421431102  accuracy =  0.859375\n",
      "now loss =  0.10000980961768695  accuracy =  0.84375\n",
      "now loss =  0.0692988100026774  accuracy =  0.921875\n",
      "now loss =  0.08073753045376278  accuracy =  0.875\n",
      "now loss =  0.0617300575220375  accuracy =  0.9375\n",
      "now loss =  0.08654067975088645  accuracy =  0.90625\n",
      "now loss =  0.07479885782130924  accuracy =  0.890625\n",
      "now loss =  0.09972666486233353  accuracy =  0.90625\n",
      "now loss =  0.08205161021347945  accuracy =  0.890625\n",
      "now loss =  0.12425020621878151  accuracy =  0.796875\n",
      "now loss =  0.08457613554017332  accuracy =  0.859375\n",
      "now loss =  0.06892010537962318  accuracy =  0.90625\n",
      "now loss =  0.08596715198709787  accuracy =  0.890625\n",
      "now loss =  0.09154567960720497  accuracy =  0.890625\n",
      "now loss =  0.07655432409137616  accuracy =  0.890625\n",
      "now loss =  0.07244173685526464  accuracy =  0.890625\n",
      "now loss =  0.1189496465481755  accuracy =  0.796875\n",
      "now loss =  0.06939771100434984  accuracy =  0.9375\n",
      "now loss =  0.07612598050393066  accuracy =  0.90625\n",
      "now loss =  0.10218587590852088  accuracy =  0.85\n",
      "now loss =  0.0882216937320677  accuracy =  0.859375\n",
      "now loss =  0.10836828306193058  accuracy =  0.828125\n",
      "now loss =  0.08421418125951768  accuracy =  0.890625\n",
      "now loss =  0.10460670228617877  accuracy =  0.828125\n",
      "now loss =  0.10094723669807676  accuracy =  0.828125\n",
      "now loss =  0.06885216579630393  accuracy =  0.90625\n",
      "now loss =  0.09445455631377465  accuracy =  0.859375\n",
      "now loss =  0.07548394699640389  accuracy =  0.890625\n",
      "now loss =  0.07958188971844676  accuracy =  0.9375\n",
      "now loss =  0.08077527479036896  accuracy =  0.90625\n",
      "now loss =  0.09565260945764417  accuracy =  0.859375\n",
      "now loss =  0.05874608256255644  accuracy =  0.9375\n",
      "now loss =  0.10094152616597588  accuracy =  0.859375\n",
      "now loss =  0.08163529831116555  accuracy =  0.890625\n",
      "now loss =  0.07798419489132707  accuracy =  0.921875\n",
      "now loss =  0.06573707565754479  accuracy =  0.95\n",
      "now loss =  0.1129089785434818  accuracy =  0.84375\n",
      "now loss =  0.09409457187720553  accuracy =  0.90625\n",
      "now loss =  0.11548219517367381  accuracy =  0.796875\n",
      "now loss =  0.0653179158594814  accuracy =  0.921875\n",
      "now loss =  0.06354576719593466  accuracy =  0.9375\n",
      "now loss =  0.08179497031197347  accuracy =  0.890625\n",
      "now loss =  0.0692970962278483  accuracy =  0.921875\n",
      "now loss =  0.07033768831887938  accuracy =  0.890625\n",
      "now loss =  0.0957930857448687  accuracy =  0.875\n",
      "now loss =  0.08809041718949444  accuracy =  0.921875\n",
      "now loss =  0.07493668161025926  accuracy =  0.90625\n",
      "now loss =  0.08338646832091928  accuracy =  0.890625\n",
      "now loss =  0.05579638521249641  accuracy =  0.921875\n",
      "now loss =  0.08917116952849252  accuracy =  0.875\n",
      "now loss =  0.08294935743330539  accuracy =  0.90625\n",
      "now loss =  0.1513131637628958  accuracy =  0.725\n",
      "now loss =  0.08903318566837976  accuracy =  0.890625\n",
      "now loss =  0.08801504245481678  accuracy =  0.875\n",
      "now loss =  0.07282756087046598  accuracy =  0.921875\n",
      "now loss =  0.10426313898898876  accuracy =  0.8125\n",
      "now loss =  0.09265045173840411  accuracy =  0.875\n",
      "now loss =  0.06836598245168318  accuracy =  0.90625\n",
      "now loss =  0.06263822962547977  accuracy =  0.9375\n",
      "now loss =  0.07307311508093658  accuracy =  0.921875\n",
      "now loss =  0.08598438505718282  accuracy =  0.890625\n",
      "now loss =  0.13540554581099334  accuracy =  0.765625\n",
      "now loss =  0.07243456599498918  accuracy =  0.90625\n",
      "now loss =  0.05537367481390672  accuracy =  0.953125\n",
      "now loss =  0.09129898382536353  accuracy =  0.875\n",
      "now loss =  0.11412834467150494  accuracy =  0.828125\n",
      "now loss =  0.08760432434579704  accuracy =  0.875\n",
      "now loss =  0.07543439350334669  accuracy =  0.875\n",
      "now loss =  0.07226554283578687  accuracy =  0.90625\n",
      "now loss =  0.084723703226384  accuracy =  0.859375\n",
      "now loss =  0.10129535513481655  accuracy =  0.859375\n",
      "now loss =  0.07524154165440039  accuracy =  0.921875\n",
      "now loss =  0.08905824025402403  accuracy =  0.890625\n",
      "now loss =  0.09629977009265606  accuracy =  0.890625\n",
      "now loss =  0.06685074128139139  accuracy =  0.875\n",
      "now loss =  0.10220646445325374  accuracy =  0.84375\n",
      "now loss =  0.11849118930632269  accuracy =  0.8125\n",
      "now loss =  0.07651144009885719  accuracy =  0.921875\n",
      "now loss =  0.09002541681901027  accuracy =  0.875\n",
      "now loss =  0.09292924540959227  accuracy =  0.84375\n",
      "now loss =  0.08904166225907524  accuracy =  0.890625\n",
      "now loss =  0.08199965820465319  accuracy =  0.90625\n",
      "now loss =  0.05627383957154769  accuracy =  0.921875\n",
      "now loss =  0.08179753157452094  accuracy =  0.9\n",
      "now loss =  0.07934297499772458  accuracy =  0.90625\n",
      "now loss =  0.0731142802322247  accuracy =  0.9375\n",
      "now loss =  0.06757586753299623  accuracy =  0.890625\n",
      "now loss =  0.09265739298825301  accuracy =  0.875\n",
      "now loss =  0.11499957022104289  accuracy =  0.84375\n",
      "now loss =  0.11783085093015452  accuracy =  0.796875\n",
      "now loss =  0.059203517755239264  accuracy =  0.96875\n",
      "now loss =  0.12432610475356329  accuracy =  0.78125\n",
      "now loss =  0.07272996751706806  accuracy =  0.890625\n",
      "now loss =  0.07040698738145468  accuracy =  0.90625\n",
      "now loss =  0.07432568075763982  accuracy =  0.875\n",
      "now loss =  0.10268292061376541  accuracy =  0.859375\n",
      "now loss =  0.07613046755763564  accuracy =  0.921875\n",
      "now loss =  0.0680957220606381  accuracy =  0.890625\n",
      "now loss =  0.09943029368392345  accuracy =  0.875\n",
      "now loss =  0.08027722996701896  accuracy =  0.875\n",
      "now loss =  0.0730061204364861  accuracy =  0.90625\n",
      "now loss =  0.07855864951562284  accuracy =  0.921875\n",
      "now loss =  0.10087873442570008  accuracy =  0.859375\n",
      "now loss =  0.08173240739823769  accuracy =  0.890625\n",
      "now loss =  0.05504840302497602  accuracy =  0.953125\n",
      "now loss =  0.10983627979869617  accuracy =  0.84375\n",
      "now loss =  0.0789389283895828  accuracy =  0.9375\n",
      "now loss =  0.08695417634849942  accuracy =  0.90625\n",
      "now loss =  0.0829043450622845  accuracy =  0.859375\n",
      "now loss =  0.07322903553425418  accuracy =  0.90625\n",
      "now loss =  0.09702467437164493  accuracy =  0.828125\n",
      "now loss =  0.09463313494045832  accuracy =  0.875\n",
      "now loss =  0.06765925568270588  accuracy =  0.890625\n",
      "now loss =  0.10100971963418753  accuracy =  0.84375\n",
      "now loss =  0.10827805527960954  accuracy =  0.8125\n",
      "now loss =  0.10071545675402485  accuracy =  0.85\n",
      "now loss =  0.07888865939954393  accuracy =  0.921875\n",
      "now loss =  0.06261822505193378  accuracy =  0.9375\n",
      "now loss =  0.08697044622583092  accuracy =  0.859375\n",
      "now loss =  0.09473988560402  accuracy =  0.875\n",
      "now loss =  0.08212784973193572  accuracy =  0.90625\n",
      "now loss =  0.07179018564723283  accuracy =  0.9375\n",
      "now loss =  0.08842288429855397  accuracy =  0.84375\n",
      "now loss =  0.09991113477903549  accuracy =  0.859375\n",
      "now loss =  0.07278044055322451  accuracy =  0.890625\n",
      "now loss =  0.11285677288217384  accuracy =  0.796875\n",
      "now loss =  0.07859903724684345  accuracy =  0.90625\n",
      "now loss =  0.103013711193889  accuracy =  0.890625\n",
      "now loss =  0.11046829578778974  accuracy =  0.84375\n",
      "now loss =  0.07209300629791306  accuracy =  0.921875\n",
      "now loss =  0.08761153770746502  accuracy =  0.90625\n",
      "now loss =  0.06528515821952005  accuracy =  0.9\n",
      "now loss =  0.09075699519240712  accuracy =  0.859375\n",
      "now loss =  0.06246780945084579  accuracy =  0.953125\n",
      "now loss =  0.060366540156265816  accuracy =  0.921875\n",
      "now loss =  0.09842151136088612  accuracy =  0.859375\n",
      "now loss =  0.06749164741330171  accuracy =  0.953125\n",
      "now loss =  0.1084914467637341  accuracy =  0.84375\n",
      "now loss =  0.08062098745156465  accuracy =  0.90625\n",
      "now loss =  0.07577570821002083  accuracy =  0.90625\n",
      "now loss =  0.09394663254673213  accuracy =  0.84375\n",
      "now loss =  0.11437313174541908  accuracy =  0.828125\n",
      "now loss =  0.04242214962712275  accuracy =  0.984375\n",
      "now loss =  0.07001956981676526  accuracy =  0.921875\n",
      "now loss =  0.09954023003927447  accuracy =  0.875\n",
      "now loss =  0.09460598325970535  accuracy =  0.875\n",
      "now loss =  0.10697535266186495  accuracy =  0.828125\n",
      "now loss =  0.10809431518232031  accuracy =  0.85\n",
      "now loss =  0.0937529812163182  accuracy =  0.859375\n",
      "now loss =  0.0954126026397693  accuracy =  0.875\n",
      "now loss =  0.08291250173462938  accuracy =  0.90625\n",
      "now loss =  0.1166294834209804  accuracy =  0.8125\n",
      "now loss =  0.08558738909882235  accuracy =  0.859375\n",
      "now loss =  0.08288129881727518  accuracy =  0.921875\n",
      "now loss =  0.08058333683493045  accuracy =  0.890625\n",
      "now loss =  0.06596193786972385  accuracy =  0.921875\n",
      "now loss =  0.07126492826667802  accuracy =  0.9375\n",
      "now loss =  0.08070972834038931  accuracy =  0.9375\n",
      "now loss =  0.07728087151075791  accuracy =  0.875\n",
      "now loss =  0.08886307575391941  accuracy =  0.84375\n",
      "now loss =  0.07013291721998126  accuracy =  0.921875\n",
      "now loss =  0.09222302415695585  accuracy =  0.875\n",
      "now loss =  0.08689396621256562  accuracy =  0.890625\n",
      "now loss =  0.10964175041033823  accuracy =  0.825\n",
      "now loss =  0.06831445873127512  accuracy =  0.9375\n",
      "now loss =  0.06547356348197791  accuracy =  0.921875\n",
      "now loss =  0.07378797707644312  accuracy =  0.90625\n",
      "now loss =  0.0914795510513624  accuracy =  0.859375\n",
      "now loss =  0.08404988117821593  accuracy =  0.890625\n",
      "now loss =  0.09160634586685619  accuracy =  0.890625\n",
      "now loss =  0.09397092409682897  accuracy =  0.875\n",
      "now loss =  0.10244418750945207  accuracy =  0.859375\n",
      "now loss =  0.09988197953740552  accuracy =  0.84375\n",
      "now loss =  0.09184875909982315  accuracy =  0.890625\n",
      "now loss =  0.10327910730506706  accuracy =  0.859375\n",
      "now loss =  0.06975148270907788  accuracy =  0.90625\n",
      "now loss =  0.06479152960755441  accuracy =  0.890625\n",
      "now loss =  0.08566057310422914  accuracy =  0.875\n",
      "now loss =  0.11699348986130782  accuracy =  0.8125\n",
      "now loss =  0.07646992394317487  accuracy =  0.925\n",
      "now loss =  0.10442092390942523  accuracy =  0.84375\n",
      "now loss =  0.07097327815270724  accuracy =  0.90625\n",
      "now loss =  0.10489428062710857  accuracy =  0.875\n",
      "now loss =  0.08527715434245733  accuracy =  0.890625\n",
      "now loss =  0.07367153491087591  accuracy =  0.90625\n",
      "now loss =  0.07120939339671072  accuracy =  0.953125\n",
      "now loss =  0.07612652835647413  accuracy =  0.875\n",
      "now loss =  0.08624379038057757  accuracy =  0.875\n",
      "now loss =  0.09095883838786946  accuracy =  0.84375\n",
      "now loss =  0.09624028722584399  accuracy =  0.875\n",
      "now loss =  0.052312995531887535  accuracy =  0.96875\n",
      "now loss =  0.09915326135384292  accuracy =  0.875\n",
      "now loss =  0.0954808847046193  accuracy =  0.890625\n",
      "now loss =  0.08869180739682538  accuracy =  0.859375\n",
      "now loss =  0.09173880679954816  accuracy =  0.84375\n",
      "now loss =  0.08606664025610947  accuracy =  0.875\n",
      "now loss =  0.09312627947144225  accuracy =  0.859375\n",
      "now loss =  0.08118161569841877  accuracy =  0.890625\n",
      "now loss =  0.09693040518468735  accuracy =  0.828125\n",
      "now loss =  0.08675290256791185  accuracy =  0.90625\n",
      "now loss =  0.07432506785819945  accuracy =  0.890625\n",
      "now loss =  0.08219441249329769  accuracy =  0.90625\n",
      "now loss =  0.07648954875098077  accuracy =  0.921875\n",
      "now loss =  0.09798192652947804  accuracy =  0.84375\n",
      "now loss =  0.09819431792830233  accuracy =  0.875\n",
      "now loss =  0.07241558851325214  accuracy =  0.921875\n",
      "now loss =  0.09546153471021535  accuracy =  0.875\n",
      "now loss =  0.08023512957878831  accuracy =  0.890625\n",
      "now loss =  0.08603373884458063  accuracy =  0.90625\n",
      "now loss =  0.12002390169447101  accuracy =  0.8125\n",
      "now loss =  0.070435515860198  accuracy =  0.90625\n",
      "now loss =  0.0722474449464241  accuracy =  0.925\n",
      "now loss =  0.07301139558185682  accuracy =  0.890625\n",
      "now loss =  0.07480643017023553  accuracy =  0.90625\n",
      "now loss =  0.08419681423008413  accuracy =  0.90625\n",
      "now loss =  0.07721113750531611  accuracy =  0.890625\n",
      "now loss =  0.10812311044665382  accuracy =  0.828125\n",
      "now loss =  0.058803112005959876  accuracy =  0.96875\n",
      "now loss =  0.08771744695435302  accuracy =  0.890625\n",
      "now loss =  0.1181297165623846  accuracy =  0.796875\n",
      "now loss =  0.07331027304806963  accuracy =  0.921875\n",
      "now loss =  0.08416675873568302  accuracy =  0.90625\n",
      "now loss =  0.07684464073273367  accuracy =  0.90625\n",
      "now loss =  0.11080022217965554  accuracy =  0.859375\n",
      "now loss =  0.09024855812452204  accuracy =  0.84375\n",
      "now loss =  0.05958996106681874  accuracy =  0.953125\n",
      "now loss =  0.07776624605734597  accuracy =  0.890625\n",
      "now loss =  0.14504412195401825  accuracy =  0.75\n",
      "now loss =  0.10427931222810152  accuracy =  0.859375\n",
      "now loss =  0.08981004148357813  accuracy =  0.890625\n",
      "now loss =  0.08419803497667375  accuracy =  0.890625\n",
      "now loss =  0.09037089998417125  accuracy =  0.890625\n",
      "now loss =  0.08113712583430932  accuracy =  0.90625\n",
      "now loss =  0.0862964627681437  accuracy =  0.859375\n",
      "now loss =  0.06106094138377368  accuracy =  0.953125\n",
      "now loss =  0.0930412527682587  accuracy =  0.9375\n",
      "now loss =  0.10245946356865945  accuracy =  0.859375\n",
      "now loss =  0.07594220470318791  accuracy =  0.875\n",
      "now loss =  0.09843699484763625  accuracy =  0.84375\n",
      "now loss =  0.07165783282978423  accuracy =  0.921875\n",
      "now loss =  0.09762995704180878  accuracy =  0.84375\n",
      "now loss =  0.06469577010197915  accuracy =  0.9375\n",
      "now loss =  0.0777436507179788  accuracy =  0.90625\n",
      "now loss =  0.09009751865666109  accuracy =  0.85\n",
      "now loss =  0.0912988441012686  accuracy =  0.859375\n",
      "now loss =  0.06567599346062403  accuracy =  0.96875\n",
      "now loss =  0.06454713046627858  accuracy =  0.890625\n",
      "now loss =  0.0877574067674789  accuracy =  0.890625\n",
      "now loss =  0.10691384700588175  accuracy =  0.84375\n",
      "now loss =  0.08244095391521919  accuracy =  0.890625\n",
      "now loss =  0.04142986418980914  accuracy =  1.0\n",
      "now loss =  0.07100163460232378  accuracy =  0.90625\n",
      "now loss =  0.10266221426668945  accuracy =  0.84375\n",
      "now loss =  0.07213136812776656  accuracy =  0.953125\n",
      "now loss =  0.10164223090787064  accuracy =  0.84375\n",
      "now loss =  0.10586824398341774  accuracy =  0.875\n",
      "now loss =  0.07793181809175798  accuracy =  0.9375\n",
      "now loss =  0.09841173665768103  accuracy =  0.84375\n",
      "now loss =  0.11128108851005829  accuracy =  0.8125\n",
      "now loss =  0.10036577589027348  accuracy =  0.825\n",
      "now loss =  0.065556205579185  accuracy =  0.921875\n",
      "now loss =  0.09422497089270045  accuracy =  0.890625\n",
      "now loss =  0.08980220157222979  accuracy =  0.890625\n",
      "now loss =  0.0864241864589097  accuracy =  0.890625\n",
      "now loss =  0.07450114541817508  accuracy =  0.890625\n",
      "now loss =  0.07149008685899422  accuracy =  0.9375\n",
      "now loss =  0.11329501955954456  accuracy =  0.8125\n",
      "now loss =  0.12138737981664856  accuracy =  0.796875\n",
      "now loss =  0.0926654110438864  accuracy =  0.875\n",
      "now loss =  0.05458000806317853  accuracy =  0.9375\n",
      "now loss =  0.12117340912716773  accuracy =  0.8125\n",
      "now loss =  0.0956063254881779  accuracy =  0.84375\n",
      "now loss =  0.06846205048105737  accuracy =  0.96875\n",
      "now loss =  0.08826830942688671  accuracy =  0.875\n",
      "now loss =  0.07355518047507112  accuracy =  0.921875\n",
      "now loss =  0.04764072687963691  accuracy =  0.95\n",
      "now loss =  0.0849783137638348  accuracy =  0.859375\n",
      "now loss =  0.06840192796648459  accuracy =  0.953125\n",
      "now loss =  0.10340894133104789  accuracy =  0.859375\n",
      "now loss =  0.06003536448536999  accuracy =  0.9375\n",
      "now loss =  0.09229199725256639  accuracy =  0.84375\n",
      "now loss =  0.11513843813193483  accuracy =  0.828125\n",
      "now loss =  0.0756524963338399  accuracy =  0.890625\n",
      "now loss =  0.10616875710695639  accuracy =  0.875\n",
      "now loss =  0.06032111810387929  accuracy =  0.953125\n",
      "now loss =  0.10389616290107367  accuracy =  0.78125\n",
      "now loss =  0.0736794392049561  accuracy =  0.921875\n",
      "now loss =  0.10899069494146571  accuracy =  0.890625\n",
      "now loss =  0.08344449677886129  accuracy =  0.890625\n",
      "now loss =  0.09036749524003848  accuracy =  0.875\n",
      "now loss =  0.08353964442970323  accuracy =  0.921875\n",
      "now loss =  0.0655044220975856  accuracy =  0.9\n",
      "now loss =  0.11162928042911974  accuracy =  0.84375\n",
      "now loss =  0.09731405326072752  accuracy =  0.875\n",
      "now loss =  0.08058444260731135  accuracy =  0.890625\n",
      "now loss =  0.0650284247320314  accuracy =  0.9375\n",
      "now loss =  0.08895853684369448  accuracy =  0.875\n",
      "now loss =  0.06856656810115799  accuracy =  0.90625\n",
      "now loss =  0.08425511696646944  accuracy =  0.875\n",
      "now loss =  0.1105336769711883  accuracy =  0.828125\n",
      "now loss =  0.08369546888985535  accuracy =  0.90625\n",
      "now loss =  0.0863556608743522  accuracy =  0.890625\n",
      "now loss =  0.08704577560073928  accuracy =  0.859375\n",
      "now loss =  0.10218196742247526  accuracy =  0.859375\n",
      "now loss =  0.07624266784778408  accuracy =  0.90625\n",
      "now loss =  0.11145235856760546  accuracy =  0.828125\n",
      "now loss =  0.046934076891035056  accuracy =  0.953125\n",
      "now loss =  0.07429593530004677  accuracy =  0.9\n",
      "now loss =  0.06733661393038007  accuracy =  0.90625\n",
      "now loss =  0.09792348481398003  accuracy =  0.859375\n",
      "now loss =  0.09469482600310655  accuracy =  0.84375\n",
      "now loss =  0.0890478467762874  accuracy =  0.875\n",
      "now loss =  0.08514481618502269  accuracy =  0.875\n",
      "now loss =  0.08434625070399109  accuracy =  0.921875\n",
      "now loss =  0.09829913257952545  accuracy =  0.84375\n",
      "now loss =  0.07692003093386958  accuracy =  0.90625\n",
      "now loss =  0.06521525179685585  accuracy =  0.921875\n",
      "now loss =  0.09191179542053302  accuracy =  0.875\n",
      "now loss =  0.0805577933306825  accuracy =  0.890625\n",
      "now loss =  0.08224044369280503  accuracy =  0.90625\n",
      "now loss =  0.09107208250950063  accuracy =  0.890625\n",
      "now loss =  0.10441296469489147  accuracy =  0.828125\n",
      "now loss =  0.09129019381177331  accuracy =  0.859375\n",
      "now loss =  0.06214544113441687  accuracy =  0.925\n",
      "now loss =  0.055887382102555214  accuracy =  0.9375\n",
      "now loss =  0.08819081750656212  accuracy =  0.84375\n",
      "now loss =  0.09018746353503307  accuracy =  0.90625\n",
      "now loss =  0.10203917250337984  accuracy =  0.875\n",
      "now loss =  0.08503347248498327  accuracy =  0.859375\n",
      "now loss =  0.0870002231924824  accuracy =  0.890625\n",
      "now loss =  0.12583617790696458  accuracy =  0.828125\n",
      "now loss =  0.0730240198478835  accuracy =  0.9375\n",
      "now loss =  0.07450973365396266  accuracy =  0.859375\n",
      "now loss =  0.07677198907176239  accuracy =  0.90625\n",
      "now loss =  0.08183333358997574  accuracy =  0.875\n",
      "now loss =  0.07128947998679085  accuracy =  0.890625\n",
      "now loss =  0.07476612322100479  accuracy =  0.921875\n",
      "now loss =  0.09922580338129952  accuracy =  0.859375\n",
      "now loss =  0.0928125877953221  accuracy =  0.890625\n",
      "now loss =  0.10098510335014037  accuracy =  0.85\n",
      "now loss =  0.07071173186519307  accuracy =  0.953125\n",
      "now loss =  0.08726453229144496  accuracy =  0.875\n",
      "now loss =  0.08227741519153652  accuracy =  0.859375\n",
      "now loss =  0.06845168235995952  accuracy =  0.921875\n",
      "now loss =  0.06723896009233812  accuracy =  0.9375\n",
      "now loss =  0.08518358625107413  accuracy =  0.890625\n",
      "now loss =  0.0911597716131417  accuracy =  0.890625\n",
      "now loss =  0.10179345583934529  accuracy =  0.84375\n",
      "now loss =  0.07415210505479172  accuracy =  0.890625\n",
      "now loss =  0.08846669300847462  accuracy =  0.84375\n",
      "now loss =  0.1010252651916523  accuracy =  0.8125\n",
      "now loss =  0.09294412123893062  accuracy =  0.875\n",
      "now loss =  0.10868015418147187  accuracy =  0.8125\n",
      "now loss =  0.10472163012996513  accuracy =  0.875\n",
      "now loss =  0.07203174795667966  accuracy =  0.921875\n",
      "now loss =  0.07689276822713037  accuracy =  0.9\n",
      "now loss =  0.10561481111211139  accuracy =  0.828125\n",
      "now loss =  0.09450934990217172  accuracy =  0.859375\n",
      "now loss =  0.07783024751098608  accuracy =  0.890625\n",
      "now loss =  0.0913656899301496  accuracy =  0.859375\n",
      "now loss =  0.08613553382870101  accuracy =  0.890625\n",
      "now loss =  0.059952092190796676  accuracy =  0.953125\n",
      "now loss =  0.07381588547148234  accuracy =  0.90625\n",
      "now loss =  0.07744250331014099  accuracy =  0.90625\n",
      "now loss =  0.07586012310646448  accuracy =  0.921875\n",
      "now loss =  0.06745913873679754  accuracy =  0.9375\n",
      "now loss =  0.08641484786041158  accuracy =  0.859375\n",
      "now loss =  0.09986002265911988  accuracy =  0.8125\n",
      "now loss =  0.11215407871376545  accuracy =  0.828125\n",
      "now loss =  0.09789314969330928  accuracy =  0.859375\n",
      "now loss =  0.0755731007637229  accuracy =  0.921875\n",
      "now loss =  0.10037058984046862  accuracy =  0.875\n",
      "now loss =  0.10027916522485572  accuracy =  0.84375\n",
      "now loss =  0.07291567615474609  accuracy =  0.90625\n",
      "now loss =  0.07825129075655876  accuracy =  0.875\n",
      "now loss =  0.08380941548627385  accuracy =  0.875\n",
      "now loss =  0.0856589468536876  accuracy =  0.921875\n",
      "now loss =  0.07789991715374571  accuracy =  0.90625\n",
      "now loss =  0.08776306325443131  accuracy =  0.890625\n",
      "now loss =  0.11070057271273287  accuracy =  0.84375\n",
      "now loss =  0.07732625117886774  accuracy =  0.890625\n",
      "now loss =  0.06371004460940895  accuracy =  0.9375\n",
      "now loss =  0.07321800883859104  accuracy =  0.90625\n",
      "now loss =  0.11590988240367121  accuracy =  0.828125\n",
      "now loss =  0.06543069868451029  accuracy =  0.875\n",
      "now loss =  0.09555990306615345  accuracy =  0.875\n",
      "now loss =  0.09865039709238643  accuracy =  0.875\n",
      "now loss =  0.07712299560337024  accuracy =  0.9\n",
      "now loss =  0.11321024198695975  accuracy =  0.828125\n",
      "now loss =  0.0651696699048499  accuracy =  0.9375\n",
      "now loss =  0.08412611137334541  accuracy =  0.875\n",
      "now loss =  0.08579012435586353  accuracy =  0.84375\n",
      "now loss =  0.09858103519486276  accuracy =  0.859375\n",
      "now loss =  0.07095647068926153  accuracy =  0.921875\n",
      "now loss =  0.09949184395979725  accuracy =  0.859375\n",
      "now loss =  0.11185013512379025  accuracy =  0.8125\n",
      "now loss =  0.054545851216756785  accuracy =  0.9375\n",
      "now loss =  0.0753546050753634  accuracy =  0.953125\n",
      "now loss =  0.09353341044075511  accuracy =  0.84375\n",
      "now loss =  0.08255812169014198  accuracy =  0.90625\n",
      "now loss =  0.08196358954217736  accuracy =  0.890625\n",
      "now loss =  0.08083157360210565  accuracy =  0.90625\n",
      "now loss =  0.08645132159793595  accuracy =  0.875\n",
      "now loss =  0.09345057072691046  accuracy =  0.875\n",
      "now loss =  0.07568279044856183  accuracy =  0.921875\n",
      "now loss =  0.06651134214727837  accuracy =  0.953125\n",
      "now loss =  0.08366340134727798  accuracy =  0.921875\n",
      "now loss =  0.09050156278414109  accuracy =  0.859375\n",
      "now loss =  0.07862907603915015  accuracy =  0.9375\n",
      "now loss =  0.08299704371969262  accuracy =  0.890625\n",
      "now loss =  0.07928056529753018  accuracy =  0.875\n",
      "now loss =  0.08250314351805293  accuracy =  0.890625\n",
      "now loss =  0.10805564754408728  accuracy =  0.796875\n",
      "now loss =  0.0800560255645288  accuracy =  0.890625\n",
      "now loss =  0.09018957607334113  accuracy =  0.921875\n",
      "now loss =  0.1036799577265107  accuracy =  0.828125\n",
      "now loss =  0.09987632474210435  accuracy =  0.828125\n",
      "now loss =  0.08878335904093423  accuracy =  0.875\n",
      "now loss =  0.10238005310699567  accuracy =  0.859375\n",
      "now loss =  0.05113059563309508  accuracy =  0.925\n",
      "now loss =  0.08661438503398525  accuracy =  0.875\n",
      "now loss =  0.08292568414607787  accuracy =  0.9375\n",
      "now loss =  0.07171971222041972  accuracy =  0.90625\n",
      "now loss =  0.10219749144934577  accuracy =  0.828125\n",
      "now loss =  0.10630532793355786  accuracy =  0.8125\n",
      "now loss =  0.08067477225940713  accuracy =  0.921875\n",
      "now loss =  0.08337487102170213  accuracy =  0.890625\n",
      "now loss =  0.09992746659967042  accuracy =  0.859375\n",
      "now loss =  0.0817861793927552  accuracy =  0.890625\n",
      "now loss =  0.08661827100578712  accuracy =  0.84375\n",
      "now loss =  0.05722477231375114  accuracy =  0.953125\n",
      "now loss =  0.08515791828518525  accuracy =  0.90625\n",
      "now loss =  0.05951050032480833  accuracy =  0.921875\n",
      "now loss =  0.09200406821589134  accuracy =  0.859375\n",
      "now loss =  0.1092349985861833  accuracy =  0.84375\n",
      "now loss =  0.08929638243997487  accuracy =  0.875\n",
      "now loss =  0.08392767397760456  accuracy =  0.890625\n",
      "now loss =  0.09324633555500297  accuracy =  0.859375\n",
      "now loss =  0.08443669309957746  accuracy =  0.859375\n",
      "now loss =  0.10144799557805337  accuracy =  0.828125\n",
      "now loss =  0.07609045742397277  accuracy =  0.90625\n",
      "now loss =  0.06147118981861237  accuracy =  0.9375\n",
      "now loss =  0.09625383982713238  accuracy =  0.859375\n",
      "now loss =  0.06604278081970133  accuracy =  0.921875\n",
      "now loss =  0.07655870525309333  accuracy =  0.921875\n",
      "now loss =  0.08070755956374284  accuracy =  0.875\n",
      "now loss =  0.08121390543305769  accuracy =  0.90625\n",
      "now loss =  0.11259104229657883  accuracy =  0.828125\n",
      "now loss =  0.0515913445676707  accuracy =  0.96875\n",
      "now loss =  0.10744287069542231  accuracy =  0.828125\n",
      "now loss =  0.12024466937508813  accuracy =  0.8125\n",
      "now loss =  0.08240997301840969  accuracy =  0.9\n",
      "now loss =  0.06907928630933938  accuracy =  0.90625\n",
      "now loss =  0.08512993409337744  accuracy =  0.875\n",
      "now loss =  0.08489325158541143  accuracy =  0.90625\n",
      "now loss =  0.07198931494813132  accuracy =  0.921875\n",
      "now loss =  0.10571403241929664  accuracy =  0.828125\n",
      "now loss =  0.08196274100845541  accuracy =  0.90625\n",
      "now loss =  0.08623486923645915  accuracy =  0.890625\n",
      "now loss =  0.06734137507029786  accuracy =  0.9375\n",
      "now loss =  0.09246411195436008  accuracy =  0.84375\n",
      "now loss =  0.0850801607294387  accuracy =  0.90625\n",
      "now loss =  0.08351882922641181  accuracy =  0.875\n",
      "now loss =  0.10041038278685072  accuracy =  0.84375\n",
      "now loss =  0.08334331516181283  accuracy =  0.890625\n",
      "now loss =  0.10115572209884731  accuracy =  0.84375\n",
      "now loss =  0.0739863653765443  accuracy =  0.890625\n",
      "now loss =  0.10541382809912672  accuracy =  0.85\n",
      "now loss =  0.0716391460649678  accuracy =  0.90625\n",
      "now loss =  0.11089029745376278  accuracy =  0.8125\n",
      "now loss =  0.0801268776354727  accuracy =  0.921875\n",
      "now loss =  0.09109723501411937  accuracy =  0.875\n",
      "now loss =  0.09358203271552828  accuracy =  0.890625\n",
      "now loss =  0.06490260419210767  accuracy =  0.9375\n",
      "now loss =  0.08512854783615018  accuracy =  0.875\n",
      "now loss =  0.08706547531303627  accuracy =  0.890625\n",
      "now loss =  0.08601507533815175  accuracy =  0.859375\n",
      "now loss =  0.09708351175730301  accuracy =  0.890625\n",
      "now loss =  0.06691826556502758  accuracy =  0.890625\n",
      "now loss =  0.10107918037436209  accuracy =  0.875\n",
      "now loss =  0.08347739686843622  accuracy =  0.890625\n",
      "now loss =  0.06281954058555093  accuracy =  0.921875\n",
      "now loss =  0.11508279892295922  accuracy =  0.84375\n",
      "now loss =  0.07586896760973551  accuracy =  0.875\n",
      "now loss =  0.07387107544933057  accuracy =  0.90625\n",
      "now loss =  0.08755289390416861  accuracy =  0.90625\n",
      "now loss =  0.06246577004694909  accuracy =  0.90625\n",
      "now loss =  0.06425595335294018  accuracy =  0.9375\n",
      "now loss =  0.10589497397094735  accuracy =  0.859375\n",
      "now loss =  0.08259074188050565  accuracy =  0.859375\n",
      "now loss =  0.09253573218726545  accuracy =  0.875\n",
      "now loss =  0.08113369848825848  accuracy =  0.921875\n",
      "now loss =  0.08923508769848013  accuracy =  0.859375\n",
      "now loss =  0.07469861120230041  accuracy =  0.890625\n",
      "now loss =  0.09958981110971904  accuracy =  0.828125\n",
      "now loss =  0.06263799705420803  accuracy =  0.96875\n",
      "now loss =  0.08023891040690216  accuracy =  0.90625\n",
      "now loss =  0.12943444132448126  accuracy =  0.796875\n",
      "now loss =  0.07983113184130469  accuracy =  0.921875\n",
      "now loss =  0.12102207736585206  accuracy =  0.725\n",
      "now loss =  0.058187138542776136  accuracy =  0.9375\n",
      "now loss =  0.07491923471071049  accuracy =  0.890625\n",
      "now loss =  0.12535872492728395  accuracy =  0.8125\n",
      "now loss =  0.08484890444896706  accuracy =  0.890625\n",
      "now loss =  0.07797498956570117  accuracy =  0.890625\n",
      "now loss =  0.08752684297646027  accuracy =  0.859375\n",
      "now loss =  0.07190951233194946  accuracy =  0.875\n",
      "now loss =  0.1154663632617133  accuracy =  0.828125\n",
      "now loss =  0.0761074766563634  accuracy =  0.875\n",
      "now loss =  0.10061495712024453  accuracy =  0.875\n",
      "now loss =  0.0873211679719178  accuracy =  0.890625\n",
      "now loss =  0.0729744325348975  accuracy =  0.890625\n",
      "now loss =  0.08945844591736596  accuracy =  0.890625\n",
      "now loss =  0.07933583196530383  accuracy =  0.953125\n",
      "now loss =  0.08502629021361904  accuracy =  0.890625\n",
      "now loss =  0.0801826165782821  accuracy =  0.925\n",
      "now loss =  0.08465295337448511  accuracy =  0.875\n",
      "now loss =  0.10303734038448971  accuracy =  0.859375\n",
      "now loss =  0.09351489379470491  accuracy =  0.859375\n",
      "now loss =  0.10415102659742706  accuracy =  0.859375\n",
      "now loss =  0.11203417387140249  accuracy =  0.796875\n",
      "now loss =  0.05890762279516117  accuracy =  0.921875\n",
      "now loss =  0.05318947665951268  accuracy =  0.96875\n",
      "now loss =  0.08299133106997539  accuracy =  0.875\n",
      "now loss =  0.11289383967791408  accuracy =  0.828125\n",
      "now loss =  0.07794694270221271  accuracy =  0.921875\n",
      "now loss =  0.0901872818109954  accuracy =  0.90625\n",
      "now loss =  0.10033807923320168  accuracy =  0.875\n",
      "now loss =  0.07349659245835882  accuracy =  0.90625\n",
      "now loss =  0.041744581683278256  accuracy =  0.96875\n",
      "now loss =  0.1088285604823549  accuracy =  0.859375\n",
      "now loss =  0.08175883558833685  accuracy =  0.875\n",
      "now loss =  0.07026704881046146  accuracy =  0.921875\n",
      "now loss =  0.06139660988350513  accuracy =  0.9375\n",
      "now loss =  0.10630446843434914  accuracy =  0.84375\n",
      "now loss =  0.06568037872332738  accuracy =  0.921875\n",
      "now loss =  0.08260477862138757  accuracy =  0.890625\n",
      "now loss =  0.08616923578520362  accuracy =  0.890625\n",
      "now loss =  0.08063530367646185  accuracy =  0.875\n",
      "now loss =  0.08387233407631814  accuracy =  0.90625\n",
      "now loss =  0.08021195281452764  accuracy =  0.90625\n",
      "now loss =  0.05920384548386884  accuracy =  0.9375\n",
      "now loss =  0.1044011729296708  accuracy =  0.84375\n",
      "now loss =  0.09867656382707193  accuracy =  0.84375\n",
      "now loss =  0.10679038767073298  accuracy =  0.796875\n",
      "now loss =  0.11794847836915229  accuracy =  0.796875\n",
      "now loss =  0.07696928178722028  accuracy =  0.90625\n",
      "now loss =  0.10329277539364945  accuracy =  0.875\n",
      "now loss =  0.07404547566970202  accuracy =  0.921875\n",
      "now loss =  0.096898156591756  accuracy =  0.890625\n",
      "now loss =  0.08565730970645208  accuracy =  0.875\n",
      "now loss =  0.0937348569633234  accuracy =  0.859375\n",
      "now loss =  0.07835408060273841  accuracy =  0.859375\n",
      "now loss =  0.09287559039422824  accuracy =  0.875\n",
      "now loss =  0.0837180275558748  accuracy =  0.875\n",
      "now loss =  0.0488446033250715  accuracy =  0.9375\n",
      "now loss =  0.10472636962157773  accuracy =  0.859375\n",
      "now loss =  0.07065685925495521  accuracy =  0.921875\n",
      "now loss =  0.08983739346000941  accuracy =  0.859375\n",
      "now loss =  0.07899671218256288  accuracy =  0.890625\n",
      "now loss =  0.09100576053621356  accuracy =  0.859375\n",
      "now loss =  0.10176745541397625  accuracy =  0.828125\n",
      "now loss =  0.0783274233760819  accuracy =  0.921875\n",
      "now loss =  0.10743888559725856  accuracy =  0.825\n",
      "now loss =  0.07626453139113885  accuracy =  0.90625\n",
      "now loss =  0.05607403391691967  accuracy =  0.953125\n",
      "now loss =  0.10102327313154645  accuracy =  0.859375\n",
      "now loss =  0.13715259598139357  accuracy =  0.78125\n",
      "now loss =  0.0837934588734717  accuracy =  0.90625\n",
      "now loss =  0.07680317842374951  accuracy =  0.890625\n",
      "now loss =  0.061356333354239526  accuracy =  0.921875\n",
      "now loss =  0.06612924679568191  accuracy =  0.921875\n",
      "now loss =  0.0820022383207216  accuracy =  0.890625\n",
      "now loss =  0.096718661045022  accuracy =  0.84375\n",
      "now loss =  0.08176987414408535  accuracy =  0.921875\n",
      "now loss =  0.08417703228597906  accuracy =  0.890625\n",
      "now loss =  0.11699533720209199  accuracy =  0.8125\n",
      "now loss =  0.0784030729636638  accuracy =  0.90625\n",
      "now loss =  0.0715224896274703  accuracy =  0.90625\n",
      "now loss =  0.11433801536779861  accuracy =  0.825\n",
      "now loss =  0.08285401878096915  accuracy =  0.875\n",
      "now loss =  0.09496820320099034  accuracy =  0.84375\n",
      "now loss =  0.07060958374969473  accuracy =  0.921875\n",
      "now loss =  0.08864004783976996  accuracy =  0.90625\n",
      "now loss =  0.07667221778572922  accuracy =  0.890625\n",
      "now loss =  0.08926767460423342  accuracy =  0.890625\n",
      "now loss =  0.12198523379170823  accuracy =  0.78125\n",
      "now loss =  0.06641973561999136  accuracy =  0.90625\n",
      "now loss =  0.07353417287953146  accuracy =  0.9375\n",
      "now loss =  0.10395797931102467  accuracy =  0.84375\n",
      "now loss =  0.10974558991470502  accuracy =  0.84375\n",
      "now loss =  0.05739081804552626  accuracy =  0.9375\n",
      "now loss =  0.10843911218068805  accuracy =  0.859375\n",
      "now loss =  0.06611068983969198  accuracy =  0.9375\n",
      "now loss =  0.08739705623936704  accuracy =  0.875\n",
      "now loss =  0.07049034327417336  accuracy =  0.925\n",
      "now loss =  0.08373032866545735  accuracy =  0.890625\n",
      "now loss =  0.057322434594146314  accuracy =  0.9375\n",
      "now loss =  0.06632510763826241  accuracy =  0.921875\n",
      "now loss =  0.07387621128661637  accuracy =  0.90625\n",
      "now loss =  0.10560785792604221  accuracy =  0.859375\n",
      "now loss =  0.07370969692129165  accuracy =  0.9375\n",
      "now loss =  0.09151691423020206  accuracy =  0.890625\n",
      "now loss =  0.10174815761085618  accuracy =  0.828125\n",
      "now loss =  0.09668474673038394  accuracy =  0.875\n",
      "now loss =  0.08400511122594795  accuracy =  0.890625\n",
      "now loss =  0.1357106138471579  accuracy =  0.796875\n",
      "now loss =  0.08420730656884938  accuracy =  0.875\n",
      "now loss =  0.09336398064414372  accuracy =  0.890625\n",
      "now loss =  0.061530771113964204  accuracy =  0.921875\n",
      "now loss =  0.09045186411384992  accuracy =  0.890625\n",
      "now loss =  0.07602126854526407  accuracy =  0.875\n",
      "now loss =  0.08455015639720923  accuracy =  0.90625\n",
      "now loss =  0.08406192271536941  accuracy =  0.875\n",
      "now loss =  0.062117407057247685  accuracy =  0.9375\n",
      "now loss =  0.06023191886992866  accuracy =  0.9375\n",
      "now loss =  0.08937115533542309  accuracy =  0.890625\n",
      "now loss =  0.06899872822837143  accuracy =  0.90625\n",
      "now loss =  0.08761593360975876  accuracy =  0.859375\n",
      "now loss =  0.10725962213782597  accuracy =  0.8125\n",
      "now loss =  0.07672901485339263  accuracy =  0.90625\n",
      "now loss =  0.08397152020871929  accuracy =  0.890625\n",
      "now loss =  0.1168241699310523  accuracy =  0.828125\n",
      "now loss =  0.0946055223642035  accuracy =  0.875\n",
      "now loss =  0.11209715679602879  accuracy =  0.828125\n",
      "now loss =  0.06026498783372951  accuracy =  0.953125\n",
      "now loss =  0.0934977444189384  accuracy =  0.859375\n",
      "now loss =  0.10176992487218228  accuracy =  0.875\n",
      "now loss =  0.08637806771105379  accuracy =  0.875\n",
      "now loss =  0.08088090646019895  accuracy =  0.90625\n",
      "now loss =  0.06914910025000268  accuracy =  0.921875\n",
      "now loss =  0.0958234286810042  accuracy =  0.890625\n",
      "now loss =  0.10622428271815229  accuracy =  0.796875\n",
      "now loss =  0.08483334859343761  accuracy =  0.890625\n",
      "now loss =  0.08267892087993181  accuracy =  0.90625\n",
      "now loss =  0.07196234485270012  accuracy =  0.921875\n",
      "now loss =  0.11075227000638216  accuracy =  0.875\n",
      "now loss =  0.06894646808609074  accuracy =  0.921875\n",
      "now loss =  0.07344769014684442  accuracy =  0.90625\n",
      "now loss =  0.07250785645497135  accuracy =  0.921875\n",
      "now loss =  0.10808119557546252  accuracy =  0.828125\n",
      "now loss =  0.07783287324580411  accuracy =  0.890625\n",
      "now loss =  0.1092275075161944  accuracy =  0.8125\n",
      "now loss =  0.07269194687428551  accuracy =  0.925\n",
      "now loss =  0.09966626130319689  accuracy =  0.84375\n",
      "now loss =  0.10319656268210517  accuracy =  0.828125\n",
      "now loss =  0.09858268731039896  accuracy =  0.875\n",
      "now loss =  0.07940344287152086  accuracy =  0.90625\n",
      "now loss =  0.08134367261797043  accuracy =  0.875\n",
      "now loss =  0.08142144863296288  accuracy =  0.90625\n",
      "now loss =  0.09948172301474993  accuracy =  0.875\n",
      "now loss =  0.058225338655945355  accuracy =  0.921875\n",
      "now loss =  0.07165235080631253  accuracy =  0.890625\n",
      "now loss =  0.0817123339619262  accuracy =  0.90625\n",
      "now loss =  0.07838956311357953  accuracy =  0.90625\n",
      "now loss =  0.09282490180322554  accuracy =  0.859375\n",
      "now loss =  0.06922070960397492  accuracy =  0.9375\n",
      "now loss =  0.1226590862829236  accuracy =  0.796875\n",
      "now loss =  0.06549125727201659  accuracy =  0.953125\n",
      "now loss =  0.0886040695560382  accuracy =  0.9\n",
      "now loss =  0.09914618294226335  accuracy =  0.859375\n",
      "now loss =  0.08602914064033507  accuracy =  0.875\n",
      "now loss =  0.0656173901750031  accuracy =  0.921875\n",
      "now loss =  0.08561491842733224  accuracy =  0.875\n",
      "now loss =  0.09710266254694537  accuracy =  0.859375\n",
      "now loss =  0.06643069108171379  accuracy =  0.9375\n",
      "now loss =  0.08408700453514958  accuracy =  0.890625\n",
      "now loss =  0.11543024354825654  accuracy =  0.84375\n",
      "now loss =  0.10218022747373932  accuracy =  0.828125\n",
      "now loss =  0.08429993512289735  accuracy =  0.875\n",
      "now loss =  0.09262140956596061  accuracy =  0.875\n",
      "now loss =  0.09257481091527608  accuracy =  0.84375\n",
      "now loss =  0.04473889726738369  accuracy =  0.96875\n",
      "now loss =  0.07394281607674903  accuracy =  0.9375\n",
      "now loss =  0.09893204732826832  accuracy =  0.859375\n",
      "now loss =  0.07883879827250202  accuracy =  0.875\n",
      "now loss =  0.056020691342363746  accuracy =  0.953125\n",
      "now loss =  0.07038222259448447  accuracy =  0.90625\n",
      "now loss =  0.09445442518060763  accuracy =  0.875\n",
      "now loss =  0.07020394931613805  accuracy =  0.90625\n",
      "now loss =  0.09933306724040661  accuracy =  0.859375\n",
      "now loss =  0.09640327264107766  accuracy =  0.875\n",
      "now loss =  0.0810623465148948  accuracy =  0.90625\n",
      "now loss =  0.1079162250945726  accuracy =  0.84375\n",
      "now loss =  0.08726644318622662  accuracy =  0.84375\n",
      "now loss =  0.1258569204772978  accuracy =  0.84375\n",
      "now loss =  0.07242156234833819  accuracy =  0.90625\n",
      "now loss =  0.07800824661346695  accuracy =  0.875\n",
      "now loss =  0.0886322846022776  accuracy =  0.875\n",
      "now loss =  0.08239325604108282  accuracy =  0.90625\n",
      "now loss =  0.08524801867948806  accuracy =  0.875\n",
      "now loss =  0.07364174645447881  accuracy =  0.9\n",
      "now loss =  0.082138126126821  accuracy =  0.921875\n",
      "now loss =  0.08286163910068722  accuracy =  0.875\n",
      "now loss =  0.08013392158743847  accuracy =  0.875\n",
      "now loss =  0.0796138724411724  accuracy =  0.875\n",
      "now loss =  0.06587717142330893  accuracy =  0.9375\n",
      "now loss =  0.07376593416892861  accuracy =  0.890625\n",
      "now loss =  0.0791797777026893  accuracy =  0.890625\n",
      "now loss =  0.08122377095701167  accuracy =  0.875\n",
      "now loss =  0.12160153206118053  accuracy =  0.84375\n",
      "now loss =  0.10324441542064577  accuracy =  0.8125\n",
      "now loss =  0.1157264078795644  accuracy =  0.8125\n",
      "now loss =  0.0754637718031955  accuracy =  0.90625\n",
      "now loss =  0.08267214312321974  accuracy =  0.90625\n",
      "now loss =  0.05279930783742938  accuracy =  0.9375\n",
      "now loss =  0.11137812955501758  accuracy =  0.84375\n",
      "now loss =  0.0940302601159884  accuracy =  0.9\n",
      "now loss =  0.07797209626840824  accuracy =  0.90625\n",
      "now loss =  0.08328797625357867  accuracy =  0.890625\n",
      "now loss =  0.08341250988339845  accuracy =  0.875\n",
      "now loss =  0.07577288546486587  accuracy =  0.921875\n",
      "now loss =  0.11642954505584359  accuracy =  0.84375\n",
      "now loss =  0.07643056794203212  accuracy =  0.890625\n",
      "now loss =  0.07133219190803787  accuracy =  0.90625\n",
      "now loss =  0.11431108250094027  accuracy =  0.8125\n",
      "now loss =  0.09878778348105662  accuracy =  0.890625\n",
      "now loss =  0.06683875215825016  accuracy =  0.921875\n",
      "now loss =  0.05883479013884155  accuracy =  0.953125\n",
      "now loss =  0.14684638824181762  accuracy =  0.765625\n",
      "now loss =  0.10027113473361834  accuracy =  0.875\n",
      "now loss =  0.08261838619747178  accuracy =  0.890625\n",
      "now loss =  0.062279915193191634  accuracy =  0.9375\n",
      "now loss =  0.0462351006620204  accuracy =  0.95\n",
      "now loss =  0.07317346063876856  accuracy =  0.90625\n",
      "now loss =  0.10139242300238059  accuracy =  0.859375\n",
      "now loss =  0.09555267102641173  accuracy =  0.875\n",
      "now loss =  0.0730104852515272  accuracy =  0.9375\n",
      "now loss =  0.11021102091096688  accuracy =  0.828125\n",
      "now loss =  0.07964135433618154  accuracy =  0.90625\n",
      "now loss =  0.08071389576267986  accuracy =  0.90625\n",
      "now loss =  0.08439607578732104  accuracy =  0.890625\n",
      "now loss =  0.08253665332341006  accuracy =  0.890625\n",
      "now loss =  0.11464968865332979  accuracy =  0.84375\n",
      "now loss =  0.072824645431324  accuracy =  0.890625\n",
      "now loss =  0.08468933983037229  accuracy =  0.84375\n",
      "now loss =  0.0788943345607053  accuracy =  0.90625\n",
      "now loss =  0.08485248034079701  accuracy =  0.890625\n",
      "now loss =  0.07864849187464598  accuracy =  0.90625\n",
      "now loss =  0.07577224085786467  accuracy =  0.95\n",
      "now loss =  0.06313954216690656  accuracy =  0.953125\n",
      "now loss =  0.07826213376521446  accuracy =  0.9375\n",
      "now loss =  0.11595844007011141  accuracy =  0.796875\n",
      "now loss =  0.0815619741570128  accuracy =  0.875\n",
      "now loss =  0.08923281097322647  accuracy =  0.84375\n",
      "now loss =  0.08572467301332114  accuracy =  0.90625\n",
      "now loss =  0.08417071971494033  accuracy =  0.90625\n",
      "now loss =  0.062371195944359636  accuracy =  0.9375\n",
      "now loss =  0.12037154014253233  accuracy =  0.78125\n",
      "now loss =  0.07389631074456021  accuracy =  0.890625\n",
      "now loss =  0.09214719952310962  accuracy =  0.875\n",
      "now loss =  0.09010337155152534  accuracy =  0.875\n",
      "now loss =  0.059645597943898045  accuracy =  0.9375\n",
      "now loss =  0.09582260952161041  accuracy =  0.84375\n",
      "now loss =  0.08478952416173595  accuracy =  0.90625\n",
      "now loss =  0.10208999587324803  accuracy =  0.85\n",
      "now loss =  0.10493561600839958  accuracy =  0.890625\n",
      "now loss =  0.11332227573327655  accuracy =  0.8125\n",
      "now loss =  0.06999617474013976  accuracy =  0.921875\n",
      "now loss =  0.08931996825550825  accuracy =  0.859375\n",
      "now loss =  0.05835647712310193  accuracy =  0.953125\n",
      "now loss =  0.08765815479821862  accuracy =  0.890625\n",
      "now loss =  0.09859276088978114  accuracy =  0.859375\n",
      "now loss =  0.07967020849106415  accuracy =  0.921875\n",
      "now loss =  0.09560431544382533  accuracy =  0.84375\n",
      "now loss =  0.08033593494178888  accuracy =  0.890625\n",
      "now loss =  0.08858751739387405  accuracy =  0.890625\n",
      "now loss =  0.08473229100269086  accuracy =  0.890625\n",
      "now loss =  0.06575731080739426  accuracy =  0.921875\n",
      "now loss =  0.0708795769640589  accuracy =  0.90625\n",
      "now loss =  0.11506475142072292  accuracy =  0.828125\n",
      "now loss =  0.08622735290160066  accuracy =  0.875\n",
      "now loss =  0.07827107895141476  accuracy =  0.90625\n",
      "now loss =  0.1032091331771588  accuracy =  0.859375\n",
      "now loss =  0.07359405627095225  accuracy =  0.90625\n",
      "now loss =  0.067653096923247  accuracy =  0.921875\n",
      "now loss =  0.060960803368279484  accuracy =  0.921875\n",
      "now loss =  0.08669328320976337  accuracy =  0.890625\n",
      "now loss =  0.09039237001471663  accuracy =  0.921875\n",
      "now loss =  0.08764216105555428  accuracy =  0.875\n",
      "now loss =  0.05933040780656086  accuracy =  0.9375\n",
      "now loss =  0.07141991491864039  accuracy =  0.90625\n",
      "now loss =  0.1120496386275189  accuracy =  0.84375\n",
      "now loss =  0.09156551290633362  accuracy =  0.875\n",
      "now loss =  0.1254690969285447  accuracy =  0.8125\n",
      "now loss =  0.09394525485473232  accuracy =  0.84375\n",
      "now loss =  0.08536720263143802  accuracy =  0.875\n",
      "now loss =  0.08914843477449912  accuracy =  0.875\n",
      "now loss =  0.07408043450409439  accuracy =  0.90625\n",
      "now loss =  0.09900452648585083  accuracy =  0.84375\n",
      "now loss =  0.06793772409307013  accuracy =  0.90625\n",
      "now loss =  0.09297445449639141  accuracy =  0.859375\n",
      "now loss =  0.10564618690652476  accuracy =  0.84375\n",
      "now loss =  0.08839550672283936  accuracy =  0.859375\n",
      "now loss =  0.08343531815546437  accuracy =  0.90625\n",
      "now loss =  0.08194041172702009  accuracy =  0.890625\n",
      "now loss =  0.11533949901034793  accuracy =  0.828125\n",
      "now loss =  0.07219158937373116  accuracy =  0.921875\n",
      "now loss =  0.07090776056071724  accuracy =  0.921875\n",
      "now loss =  0.08649587032202957  accuracy =  0.890625\n",
      "now loss =  0.08818104838665239  accuracy =  0.890625\n",
      "now loss =  0.0816819802605682  accuracy =  0.875\n",
      "now loss =  0.09647728596980645  accuracy =  0.828125\n",
      "now loss =  0.07439457782994545  accuracy =  0.95\n",
      "now loss =  0.08117049318957628  accuracy =  0.890625\n",
      "now loss =  0.08737127408329133  accuracy =  0.859375\n",
      "now loss =  0.08434051230102524  accuracy =  0.921875\n",
      "now loss =  0.10581380287145267  accuracy =  0.84375\n",
      "now loss =  0.07308799842729943  accuracy =  0.921875\n",
      "now loss =  0.07840044231272554  accuracy =  0.90625\n",
      "now loss =  0.06867793596566343  accuracy =  0.921875\n",
      "now loss =  0.08779007915272079  accuracy =  0.890625\n",
      "now loss =  0.09505454721934481  accuracy =  0.84375\n",
      "now loss =  0.07298997042848056  accuracy =  0.921875\n",
      "now loss =  0.08910274014744013  accuracy =  0.890625\n",
      "now loss =  0.0649081503110534  accuracy =  0.90625\n",
      "now loss =  0.08464037902514042  accuracy =  0.890625\n",
      "now loss =  0.1299787512114976  accuracy =  0.796875\n",
      "now loss =  0.08887209286378586  accuracy =  0.84375\n",
      "now loss =  0.09406432373974336  accuracy =  0.875\n",
      "now loss =  0.08143416593075498  accuracy =  0.921875\n",
      "now loss =  0.0854532085725741  accuracy =  0.890625\n",
      "now loss =  0.08150057926348225  accuracy =  0.90625\n",
      "now loss =  0.07909401365494667  accuracy =  0.90625\n",
      "now loss =  0.09706337389841925  accuracy =  0.859375\n",
      "now loss =  0.0644350115983976  accuracy =  0.90625\n",
      "now loss =  0.0827852199681225  accuracy =  0.90625\n",
      "now loss =  0.08425254185861433  accuracy =  0.84375\n",
      "now loss =  0.10169649360508982  accuracy =  0.921875\n",
      "now loss =  0.07718310721009428  accuracy =  0.890625\n",
      "now loss =  0.08940470138367679  accuracy =  0.890625\n",
      "now loss =  0.09773639483274638  accuracy =  0.859375\n",
      "now loss =  0.09978832173911953  accuracy =  0.8125\n",
      "now loss =  0.10167250219951605  accuracy =  0.84375\n",
      "now loss =  0.06330081761166412  accuracy =  0.921875\n",
      "now loss =  0.08170451477347385  accuracy =  0.875\n",
      "now loss =  0.09569662581830722  accuracy =  0.859375\n",
      "now loss =  0.08512590724306633  accuracy =  0.890625\n",
      "now loss =  0.08907374857896852  accuracy =  0.859375\n",
      "now loss =  0.07542839162687823  accuracy =  0.921875\n",
      "now loss =  0.0525624607541122  accuracy =  0.953125\n",
      "now loss =  0.08020308749309317  accuracy =  0.90625\n",
      "now loss =  0.070135977816831  accuracy =  0.953125\n",
      "now loss =  0.08630421262171137  accuracy =  0.84375\n",
      "now loss =  0.10666361530011695  accuracy =  0.828125\n",
      "now loss =  0.09932635855512678  accuracy =  0.890625\n",
      "now loss =  0.07527555443125755  accuracy =  0.890625\n",
      "now loss =  0.08654192143556222  accuracy =  0.875\n",
      "now loss =  0.10208781447968451  accuracy =  0.84375\n",
      "now loss =  0.0670623246897773  accuracy =  0.890625\n",
      "now loss =  0.0994143613816939  accuracy =  0.84375\n",
      "now loss =  0.10904883884889102  accuracy =  0.85\n",
      "now loss =  0.0979118398534573  accuracy =  0.875\n",
      "now loss =  0.0878720311861198  accuracy =  0.890625\n",
      "now loss =  0.08428761293793724  accuracy =  0.875\n",
      "now loss =  0.09550667323301615  accuracy =  0.859375\n",
      "now loss =  0.08707469967390566  accuracy =  0.90625\n",
      "now loss =  0.12384214517790575  accuracy =  0.75\n",
      "now loss =  0.09637265077366802  accuracy =  0.84375\n",
      "now loss =  0.0745253937223068  accuracy =  0.90625\n",
      "now loss =  0.08775879660922759  accuracy =  0.875\n",
      "now loss =  0.09110073710728145  accuracy =  0.859375\n",
      "now loss =  0.08982564281527108  accuracy =  0.9375\n",
      "now loss =  0.05467506867954065  accuracy =  0.953125\n",
      "now loss =  0.07140803779109492  accuracy =  0.9375\n",
      "now loss =  0.10716177133846425  accuracy =  0.8125\n",
      "now loss =  0.060640678072401054  accuracy =  0.9375\n",
      "now loss =  0.06893397437259888  accuracy =  0.925\n",
      "now loss =  0.11907223882787635  accuracy =  0.8125\n",
      "now loss =  0.10437265992193204  accuracy =  0.859375\n",
      "now loss =  0.1040452058296838  accuracy =  0.859375\n",
      "now loss =  0.08379081540307885  accuracy =  0.890625\n",
      "now loss =  0.10259662251900101  accuracy =  0.859375\n",
      "now loss =  0.09959111532706899  accuracy =  0.828125\n",
      "now loss =  0.07141737122676078  accuracy =  0.90625\n",
      "now loss =  0.07077709502160595  accuracy =  0.9375\n",
      "now loss =  0.10117129904970171  accuracy =  0.875\n",
      "now loss =  0.0919764952265743  accuracy =  0.84375\n",
      "now loss =  0.09863867827308571  accuracy =  0.859375\n",
      "now loss =  0.057100289740809766  accuracy =  0.9375\n",
      "now loss =  0.047273687684358495  accuracy =  0.953125\n",
      "now loss =  0.0789639533480894  accuracy =  0.9375\n",
      "now loss =  0.06827255610036853  accuracy =  0.890625\n",
      "now loss =  0.07712281869103414  accuracy =  0.85\n",
      "now loss =  0.06975723981039438  accuracy =  0.9375\n",
      "now loss =  0.08939036352765357  accuracy =  0.90625\n",
      "now loss =  0.07364769010155083  accuracy =  0.90625\n",
      "now loss =  0.07163896354687777  accuracy =  0.921875\n",
      "now loss =  0.08561479348956252  accuracy =  0.875\n",
      "now loss =  0.0819937671139821  accuracy =  0.90625\n",
      "now loss =  0.09925447111846838  accuracy =  0.875\n",
      "now loss =  0.0979892341119599  accuracy =  0.875\n",
      "now loss =  0.0822614587245356  accuracy =  0.890625\n",
      "now loss =  0.060685588195178324  accuracy =  0.921875\n",
      "now loss =  0.08222283272634737  accuracy =  0.890625\n",
      "now loss =  0.11289661332443765  accuracy =  0.796875\n",
      "now loss =  0.07803979088929991  accuracy =  0.90625\n",
      "now loss =  0.10486990737738702  accuracy =  0.84375\n",
      "now loss =  0.08987275103948698  accuracy =  0.859375\n",
      "now loss =  0.10064516790389977  accuracy =  0.825\n",
      "now loss =  0.06133588058645678  accuracy =  0.953125\n",
      "now loss =  0.10457037460074006  accuracy =  0.859375\n",
      "now loss =  0.11114833922660475  accuracy =  0.84375\n",
      "now loss =  0.08925542451456467  accuracy =  0.890625\n",
      "now loss =  0.07168732011303608  accuracy =  0.890625\n",
      "now loss =  0.11759916300634177  accuracy =  0.828125\n",
      "now loss =  0.0874625880761784  accuracy =  0.828125\n",
      "now loss =  0.09768224125455574  accuracy =  0.84375\n",
      "now loss =  0.08386437655311857  accuracy =  0.921875\n",
      "now loss =  0.07658913503440937  accuracy =  0.921875\n",
      "now loss =  0.09765506199028728  accuracy =  0.859375\n",
      "now loss =  0.08928031587721376  accuracy =  0.859375\n",
      "now loss =  0.07920177575487945  accuracy =  0.859375\n",
      "now loss =  0.06251201952042136  accuracy =  0.953125\n",
      "now loss =  0.055326696268151315  accuracy =  0.953125\n",
      "now loss =  0.07869031102091109  accuracy =  0.9\n",
      "now loss =  0.05443179511756933  accuracy =  0.953125\n",
      "now loss =  0.06209178901561546  accuracy =  0.90625\n",
      "now loss =  0.09024119332725972  accuracy =  0.90625\n",
      "now loss =  0.10764473438913455  accuracy =  0.8125\n",
      "now loss =  0.10856695570640554  accuracy =  0.875\n",
      "now loss =  0.09148738201280393  accuracy =  0.890625\n",
      "now loss =  0.07418602892927736  accuracy =  0.90625\n",
      "now loss =  0.10794305972024548  accuracy =  0.78125\n",
      "now loss =  0.06918547479804335  accuracy =  0.921875\n",
      "now loss =  0.11277256002712445  accuracy =  0.78125\n",
      "now loss =  0.08483903849256524  accuracy =  0.90625\n",
      "now loss =  0.07211530363937854  accuracy =  0.90625\n",
      "now loss =  0.0804653938369821  accuracy =  0.84375\n",
      "now loss =  0.0958532649268945  accuracy =  0.859375\n",
      "now loss =  0.09211795667308234  accuracy =  0.921875\n",
      "now loss =  0.06330868385126656  accuracy =  0.925\n",
      "now loss =  0.0941945698525731  accuracy =  0.890625\n",
      "now loss =  0.09159385462353836  accuracy =  0.859375\n",
      "now loss =  0.07971988313575451  accuracy =  0.921875\n",
      "now loss =  0.10328460365427611  accuracy =  0.828125\n",
      "now loss =  0.07873238696167695  accuracy =  0.890625\n",
      "now loss =  0.08493797614363258  accuracy =  0.90625\n",
      "now loss =  0.08787627212175583  accuracy =  0.875\n",
      "now loss =  0.08863473473905731  accuracy =  0.875\n",
      "now loss =  0.08753110126773213  accuracy =  0.890625\n",
      "now loss =  0.07628035230435917  accuracy =  0.921875\n",
      "now loss =  0.08626946161048032  accuracy =  0.90625\n",
      "now loss =  0.10448361558563346  accuracy =  0.859375\n",
      "now loss =  0.091671497910034  accuracy =  0.859375\n",
      "now loss =  0.08130562736045735  accuracy =  0.84375\n",
      "now loss =  0.06659225857820575  accuracy =  0.921875\n",
      "now loss =  0.07167980274839361  accuracy =  0.925\n",
      "now loss =  0.07134176984769505  accuracy =  0.890625\n",
      "now loss =  0.09377680807419403  accuracy =  0.890625\n",
      "now loss =  0.07219757706600027  accuracy =  0.890625\n",
      "now loss =  0.06643276048244762  accuracy =  0.921875\n",
      "now loss =  0.0830860797329452  accuracy =  0.90625\n",
      "now loss =  0.10109020341523335  accuracy =  0.875\n",
      "now loss =  0.11236622410535836  accuracy =  0.84375\n",
      "now loss =  0.08760404815657681  accuracy =  0.859375\n",
      "now loss =  0.07198184877160217  accuracy =  0.90625\n",
      "now loss =  0.07342986707568085  accuracy =  0.921875\n",
      "now loss =  0.0701248786894113  accuracy =  0.9375\n",
      "now loss =  0.09062601075546267  accuracy =  0.875\n",
      "now loss =  0.09453983281126001  accuracy =  0.875\n",
      "now loss =  0.12084711515037487  accuracy =  0.8125\n",
      "now loss =  0.08393474136940628  accuracy =  0.890625\n",
      "now loss =  0.0787033407875447  accuracy =  0.875\n",
      "now loss =  0.09517742646045299  accuracy =  0.84375\n",
      "now loss =  0.07946347882751609  accuracy =  0.921875\n",
      "now loss =  0.12281084247611013  accuracy =  0.78125\n",
      "now loss =  0.0833965910063862  accuracy =  0.890625\n",
      "now loss =  0.09685571279915442  accuracy =  0.90625\n",
      "now loss =  0.11093246343363208  accuracy =  0.8125\n",
      "now loss =  0.09071488104303678  accuracy =  0.875\n",
      "now loss =  0.09620531704093066  accuracy =  0.890625\n",
      "now loss =  0.06744771423843816  accuracy =  0.921875\n",
      "now loss =  0.0725358337855184  accuracy =  0.921875\n",
      "now loss =  0.06839922370045681  accuracy =  0.921875\n",
      "now loss =  0.08337333932861499  accuracy =  0.90625\n",
      "now loss =  0.08080750001063605  accuracy =  0.890625\n",
      "now loss =  0.07938404710391939  accuracy =  0.90625\n",
      "now loss =  0.08309559986247655  accuracy =  0.875\n",
      "now loss =  0.06507204218100564  accuracy =  0.95\n",
      "now loss =  0.08144493892505413  accuracy =  0.890625\n",
      "now loss =  0.10327682729259537  accuracy =  0.828125\n",
      "now loss =  0.0826115241891539  accuracy =  0.9375\n",
      "now loss =  0.07475471903189462  accuracy =  0.90625\n",
      "now loss =  0.0969325903902502  accuracy =  0.890625\n",
      "now loss =  0.07391482813688541  accuracy =  0.90625\n",
      "now loss =  0.06348392185911357  accuracy =  0.921875\n",
      "now loss =  0.08705930146211452  accuracy =  0.859375\n",
      "now loss =  0.10988214112564161  accuracy =  0.8125\n",
      "now loss =  0.08750932875919748  accuracy =  0.890625\n",
      "now loss =  0.105272925746797  accuracy =  0.828125\n",
      "now loss =  0.09019219296680206  accuracy =  0.875\n",
      "now loss =  0.10666628254675187  accuracy =  0.859375\n",
      "now loss =  0.07032643926392322  accuracy =  0.90625\n",
      "now loss =  0.07755568708469908  accuracy =  0.890625\n",
      "now loss =  0.06026363745624082  accuracy =  0.925\n",
      "now loss =  0.1122339831346651  accuracy =  0.84375\n",
      "now loss =  0.10987986442790375  accuracy =  0.859375\n",
      "now loss =  0.06985373617020872  accuracy =  0.890625\n",
      "now loss =  0.05056691042338259  accuracy =  0.96875\n",
      "now loss =  0.08001573347504518  accuracy =  0.921875\n",
      "now loss =  0.10332214868238745  accuracy =  0.875\n",
      "now loss =  0.07091613650845825  accuracy =  0.890625\n",
      "now loss =  0.06933631224908107  accuracy =  0.9375\n",
      "now loss =  0.08574477793065532  accuracy =  0.875\n",
      "now loss =  0.10627918302744817  accuracy =  0.828125\n",
      "now loss =  0.07163125318430996  accuracy =  0.90625\n",
      "now loss =  0.060018210844849304  accuracy =  0.9375\n",
      "now loss =  0.08690803399571251  accuracy =  0.875\n",
      "now loss =  0.10341333638054881  accuracy =  0.859375\n",
      "now loss =  0.08895177340644654  accuracy =  0.859375\n",
      "now loss =  0.10879217751569921  accuracy =  0.825\n",
      "now loss =  0.07268148023092098  accuracy =  0.921875\n",
      "now loss =  0.10407982341352903  accuracy =  0.828125\n",
      "now loss =  0.08657017524458743  accuracy =  0.890625\n",
      "now loss =  0.06825948476054942  accuracy =  0.953125\n",
      "now loss =  0.08331501724972605  accuracy =  0.890625\n",
      "now loss =  0.05920309635037908  accuracy =  0.9375\n",
      "now loss =  0.08931234966616768  accuracy =  0.875\n",
      "now loss =  0.09572551339804372  accuracy =  0.859375\n",
      "now loss =  0.07162704947944197  accuracy =  0.890625\n",
      "now loss =  0.09178867610891406  accuracy =  0.875\n",
      "now loss =  0.07259898060964802  accuracy =  0.890625\n",
      "now loss =  0.09830016491288884  accuracy =  0.859375\n",
      "now loss =  0.07480957411194025  accuracy =  0.953125\n",
      "now loss =  0.07957518507765887  accuracy =  0.90625\n",
      "now loss =  0.09098706094915449  accuracy =  0.84375\n",
      "now loss =  0.15409511054624914  accuracy =  0.75\n",
      "now loss =  0.09378949974991736  accuracy =  0.859375\n",
      "now loss =  0.0663964460236793  accuracy =  0.953125\n",
      "now loss =  0.07688428742929523  accuracy =  0.890625\n",
      "now loss =  0.09354192965732609  accuracy =  0.84375\n",
      "now loss =  0.08924406522880862  accuracy =  0.890625\n",
      "now loss =  0.0746419459095975  accuracy =  0.921875\n",
      "now loss =  0.07952282094990923  accuracy =  0.921875\n",
      "now loss =  0.09577680235885573  accuracy =  0.875\n",
      "now loss =  0.0846384044973106  accuracy =  0.890625\n",
      "now loss =  0.053487526874148886  accuracy =  0.953125\n",
      "now loss =  0.09090955132706571  accuracy =  0.84375\n",
      "now loss =  0.0831474557981712  accuracy =  0.9375\n",
      "now loss =  0.13225157036528196  accuracy =  0.75\n",
      "now loss =  0.08750582448867619  accuracy =  0.890625\n",
      "now loss =  0.07705587310835894  accuracy =  0.90625\n",
      "now loss =  0.10308155941883075  accuracy =  0.9\n",
      "now loss =  0.0739170743680348  accuracy =  0.890625\n",
      "now loss =  0.061753616401545794  accuracy =  0.9375\n",
      "now loss =  0.07087603764265377  accuracy =  0.921875\n",
      "now loss =  0.11824909551798457  accuracy =  0.828125\n",
      "now loss =  0.09179406336903044  accuracy =  0.859375\n",
      "now loss =  0.08637833154073934  accuracy =  0.875\n",
      "now loss =  0.09407030253492672  accuracy =  0.859375\n",
      "now loss =  0.08151266687083857  accuracy =  0.90625\n",
      "now loss =  0.0710609104507483  accuracy =  0.921875\n",
      "now loss =  0.0911116288403547  accuracy =  0.890625\n",
      "now loss =  0.08673156521733086  accuracy =  0.875\n",
      "now loss =  0.08934828406372076  accuracy =  0.875\n",
      "now loss =  0.09858719132311942  accuracy =  0.828125\n",
      "now loss =  0.08775582462693547  accuracy =  0.859375\n",
      "now loss =  0.09063795664236904  accuracy =  0.875\n",
      "now loss =  0.09298297397804552  accuracy =  0.925\n",
      "now loss =  0.07706894581614909  accuracy =  0.875\n",
      "now loss =  0.10667297360204624  accuracy =  0.859375\n",
      "now loss =  0.09206790596014765  accuracy =  0.875\n",
      "now loss =  0.10487807558294762  accuracy =  0.875\n",
      "now loss =  0.07851966571219252  accuracy =  0.90625\n",
      "now loss =  0.07517979198353938  accuracy =  0.890625\n",
      "now loss =  0.07576040916018645  accuracy =  0.90625\n",
      "now loss =  0.10534071644524692  accuracy =  0.828125\n",
      "now loss =  0.07734258224867746  accuracy =  0.90625\n",
      "now loss =  0.0706369369099987  accuracy =  0.921875\n",
      "now loss =  0.09390134358947365  accuracy =  0.828125\n",
      "now loss =  0.11662725903457115  accuracy =  0.828125\n",
      "now loss =  0.06851559451411418  accuracy =  0.921875\n",
      "now loss =  0.0794168255208957  accuracy =  0.890625\n",
      "now loss =  0.07755358805185131  accuracy =  0.90625\n",
      "now loss =  0.09180261751476836  accuracy =  0.925\n",
      "now loss =  0.08850412389116274  accuracy =  0.875\n",
      "now loss =  0.1145654977313526  accuracy =  0.84375\n",
      "now loss =  0.07929908280048534  accuracy =  0.890625\n",
      "now loss =  0.08007581887349283  accuracy =  0.890625\n",
      "now loss =  0.09794496349366931  accuracy =  0.84375\n",
      "now loss =  0.11602231516910604  accuracy =  0.828125\n",
      "now loss =  0.06832954420772143  accuracy =  0.921875\n",
      "now loss =  0.09643706467595016  accuracy =  0.890625\n",
      "now loss =  0.08087981288093171  accuracy =  0.90625\n",
      "now loss =  0.09965418977121983  accuracy =  0.84375\n",
      "now loss =  0.057921921068238444  accuracy =  0.953125\n",
      "now loss =  0.059973383322764584  accuracy =  0.953125\n",
      "now loss =  0.09041568136535247  accuracy =  0.875\n",
      "now loss =  0.07796411006772272  accuracy =  0.890625\n",
      "now loss =  0.09157602867400823  accuracy =  0.859375\n",
      "now loss =  0.06220456256496909  accuracy =  0.95\n",
      "now loss =  0.08555313857127744  accuracy =  0.875\n",
      "now loss =  0.05986260117511068  accuracy =  0.96875\n",
      "now loss =  0.08148993955229303  accuracy =  0.875\n",
      "now loss =  0.08430134048109494  accuracy =  0.921875\n",
      "now loss =  0.08240452273513613  accuracy =  0.921875\n",
      "now loss =  0.08546393396025291  accuracy =  0.890625\n",
      "now loss =  0.09495529873912884  accuracy =  0.859375\n",
      "now loss =  0.08646465966026681  accuracy =  0.90625\n",
      "now loss =  0.06959029260990457  accuracy =  0.90625\n",
      "now loss =  0.10169112480971945  accuracy =  0.875\n",
      "now loss =  0.07127392133639485  accuracy =  0.890625\n",
      "now loss =  0.0791894441327598  accuracy =  0.890625\n",
      "now loss =  0.10273466519056246  accuracy =  0.859375\n",
      "now loss =  0.07814689682688167  accuracy =  0.90625\n",
      "now loss =  0.11577915338639397  accuracy =  0.8125\n",
      "now loss =  0.09555624578803044  accuracy =  0.775\n",
      "now loss =  0.07060264677440416  accuracy =  0.90625\n",
      "now loss =  0.0963392859843877  accuracy =  0.84375\n",
      "now loss =  0.12073419773778536  accuracy =  0.796875\n",
      "now loss =  0.08784780697399383  accuracy =  0.90625\n",
      "now loss =  0.0424283881355321  accuracy =  0.96875\n",
      "now loss =  0.061587964078706516  accuracy =  0.90625\n",
      "now loss =  0.09858968122024374  accuracy =  0.84375\n",
      "now loss =  0.08047245446327506  accuracy =  0.890625\n",
      "now loss =  0.10665070762883508  accuracy =  0.84375\n",
      "now loss =  0.11204651533774795  accuracy =  0.828125\n",
      "now loss =  0.09023457458021289  accuracy =  0.90625\n",
      "now loss =  0.07927154791269497  accuracy =  0.90625\n",
      "now loss =  0.09508628032184578  accuracy =  0.890625\n",
      "now loss =  0.07955842836262753  accuracy =  0.875\n",
      "now loss =  0.0862424318431134  accuracy =  0.875\n",
      "now loss =  0.05610935921416075  accuracy =  0.925\n",
      "now loss =  0.09235648216600009  accuracy =  0.890625\n",
      "now loss =  0.08730201892597426  accuracy =  0.9375\n",
      "now loss =  0.06852090726432637  accuracy =  0.90625\n",
      "now loss =  0.09223331731707438  accuracy =  0.890625\n",
      "now loss =  0.06641532107264342  accuracy =  0.9375\n",
      "now loss =  0.10882856461011445  accuracy =  0.828125\n",
      "now loss =  0.08951224315269349  accuracy =  0.859375\n",
      "now loss =  0.08409287689123204  accuracy =  0.875\n",
      "now loss =  0.08983005003988964  accuracy =  0.875\n",
      "now loss =  0.08740677070073852  accuracy =  0.890625\n",
      "now loss =  0.07700741992404866  accuracy =  0.890625\n",
      "now loss =  0.09358682378997196  accuracy =  0.859375\n",
      "now loss =  0.06668375161257331  accuracy =  0.921875\n",
      "now loss =  0.09651210840186525  accuracy =  0.828125\n",
      "now loss =  0.08538852401534969  accuracy =  0.890625\n",
      "now loss =  0.09669231139787439  accuracy =  0.85\n",
      "now loss =  0.08547722440661025  accuracy =  0.890625\n",
      "now loss =  0.06559299470406565  accuracy =  0.921875\n",
      "now loss =  0.10032689816333987  accuracy =  0.828125\n",
      "now loss =  0.07479975234016273  accuracy =  0.890625\n",
      "now loss =  0.08705069182715587  accuracy =  0.875\n",
      "now loss =  0.10197674542677874  accuracy =  0.859375\n",
      "now loss =  0.09583097206037218  accuracy =  0.890625\n",
      "now loss =  0.05496040572130441  accuracy =  0.9375\n",
      "now loss =  0.08497441668196404  accuracy =  0.890625\n",
      "now loss =  0.061337272603323764  accuracy =  0.9375\n",
      "now loss =  0.06444303400150285  accuracy =  0.9375\n",
      "now loss =  0.08071088226909134  accuracy =  0.875\n",
      "now loss =  0.10498699476544263  accuracy =  0.890625\n",
      "now loss =  0.08754692193711933  accuracy =  0.859375\n",
      "now loss =  0.09076458268757844  accuracy =  0.859375\n",
      "now loss =  0.1716958530957735  accuracy =  0.725\n",
      "now loss =  0.09879572730570559  accuracy =  0.890625\n",
      "now loss =  0.06346325085324203  accuracy =  0.890625\n",
      "now loss =  0.08613103375938055  accuracy =  0.90625\n",
      "now loss =  0.08544655802728235  accuracy =  0.890625\n",
      "now loss =  0.07802338125893457  accuracy =  0.90625\n",
      "now loss =  0.08915927411103403  accuracy =  0.875\n",
      "now loss =  0.07658647617444059  accuracy =  0.875\n",
      "now loss =  0.09180919481087571  accuracy =  0.875\n",
      "now loss =  0.08020155817463803  accuracy =  0.875\n",
      "now loss =  0.1008428677678572  accuracy =  0.859375\n",
      "now loss =  0.05699228063211252  accuracy =  0.953125\n",
      "now loss =  0.09799791659338859  accuracy =  0.84375\n",
      "now loss =  0.08777324813938012  accuracy =  0.90625\n",
      "now loss =  0.11397775700208079  accuracy =  0.828125\n",
      "now loss =  0.08817253906679925  accuracy =  0.84375\n",
      "now loss =  0.08496244628683056  accuracy =  0.925\n",
      "now loss =  0.08600397298137955  accuracy =  0.890625\n",
      "now loss =  0.09852788915463631  accuracy =  0.859375\n",
      "now loss =  0.11121432739227541  accuracy =  0.859375\n",
      "now loss =  0.0846048436039949  accuracy =  0.875\n",
      "now loss =  0.0710031047896365  accuracy =  0.875\n",
      "now loss =  0.06410164212151624  accuracy =  0.90625\n",
      "now loss =  0.07369202354410506  accuracy =  0.90625\n",
      "now loss =  0.09416349299164099  accuracy =  0.90625\n",
      "now loss =  0.0942248523105413  accuracy =  0.859375\n",
      "now loss =  0.09230177044893512  accuracy =  0.859375\n",
      "now loss =  0.06387657726834182  accuracy =  0.953125\n",
      "now loss =  0.07481065358662023  accuracy =  0.90625\n",
      "now loss =  0.06917073377517675  accuracy =  0.921875\n",
      "now loss =  0.10119403103322915  accuracy =  0.875\n",
      "now loss =  0.09197246455933003  accuracy =  0.890625\n",
      "now loss =  0.1106175305254562  accuracy =  0.825\n",
      "now loss =  0.08192248159085996  accuracy =  0.890625\n",
      "now loss =  0.12014189821707358  accuracy =  0.796875\n",
      "now loss =  0.08444059361157234  accuracy =  0.890625\n",
      "now loss =  0.07294876579867253  accuracy =  0.90625\n",
      "now loss =  0.07683936815480533  accuracy =  0.90625\n",
      "now loss =  0.08589852300638587  accuracy =  0.890625\n",
      "now loss =  0.09566586555965861  accuracy =  0.859375\n",
      "now loss =  0.07801830774136304  accuracy =  0.90625\n",
      "now loss =  0.07760867312327296  accuracy =  0.890625\n",
      "now loss =  0.09429400201847951  accuracy =  0.890625\n",
      "now loss =  0.11281176534682107  accuracy =  0.859375\n",
      "now loss =  0.06658006556732805  accuracy =  0.90625\n",
      "now loss =  0.07014650127321048  accuracy =  0.921875\n",
      "now loss =  0.08737842345419415  accuracy =  0.890625\n",
      "now loss =  0.0904429942050897  accuracy =  0.828125\n",
      "now loss =  0.07355081722976367  accuracy =  0.875\n",
      "now loss =  0.08209541793368502  accuracy =  0.890625\n",
      "now loss =  0.08108085557652706  accuracy =  0.875\n",
      "now loss =  0.07909788979777092  accuracy =  0.921875\n",
      "now loss =  0.07604882211908948  accuracy =  0.875\n",
      "now loss =  0.06225212527404331  accuracy =  0.9375\n",
      "now loss =  0.10816546840773805  accuracy =  0.84375\n",
      "now loss =  0.08040363524653117  accuracy =  0.921875\n",
      "now loss =  0.10715943164031456  accuracy =  0.828125\n",
      "now loss =  0.1022506594882535  accuracy =  0.84375\n",
      "now loss =  0.07341697563891374  accuracy =  0.875\n",
      "now loss =  0.10611857250453209  accuracy =  0.859375\n",
      "now loss =  0.06536303452950244  accuracy =  0.9375\n",
      "now loss =  0.08402121895617934  accuracy =  0.90625\n",
      "now loss =  0.08468795108294805  accuracy =  0.90625\n",
      "now loss =  0.08880732929745581  accuracy =  0.890625\n",
      "now loss =  0.098019383000477  accuracy =  0.85\n",
      "now loss =  0.11410361206453115  accuracy =  0.84375\n",
      "now loss =  0.06999070644009829  accuracy =  0.9375\n",
      "now loss =  0.07548449911431629  accuracy =  0.921875\n",
      "now loss =  0.09546623422010389  accuracy =  0.84375\n",
      "now loss =  0.09005209408610473  accuracy =  0.859375\n",
      "now loss =  0.0756832409292213  accuracy =  0.90625\n",
      "now loss =  0.06693815167234238  accuracy =  0.9375\n",
      "now loss =  0.04642455589164382  accuracy =  0.984375\n",
      "now loss =  0.08141241051263884  accuracy =  0.921875\n",
      "now loss =  0.08861993640860316  accuracy =  0.890625\n",
      "now loss =  0.09510841044398424  accuracy =  0.859375\n",
      "now loss =  0.09287706267505774  accuracy =  0.84375\n",
      "now loss =  0.11699790304959874  accuracy =  0.8125\n",
      "now loss =  0.08721292422271669  accuracy =  0.875\n",
      "now loss =  0.09848826464960761  accuracy =  0.8125\n",
      "now loss =  0.08826573006470989  accuracy =  0.875\n",
      "now loss =  0.08491619414822306  accuracy =  0.875\n",
      "now loss =  0.09630947107792699  accuracy =  0.84375\n",
      "now loss =  0.08925320330730198  accuracy =  0.859375\n",
      "now loss =  0.08635133481043916  accuracy =  0.875\n",
      "now loss =  0.09124749710509716  accuracy =  0.859375\n",
      "now loss =  0.08093582449957998  accuracy =  0.90625\n",
      "now loss =  0.10312204396634672  accuracy =  0.859375\n",
      "now loss =  0.0773795895179372  accuracy =  0.921875\n",
      "now loss =  0.09120264562807273  accuracy =  0.875\n",
      "now loss =  0.09230563976488819  accuracy =  0.890625\n",
      "now loss =  0.06634239703361078  accuracy =  0.921875\n",
      "now loss =  0.10451285828649114  accuracy =  0.859375\n",
      "now loss =  0.09286054274879944  accuracy =  0.859375\n",
      "now loss =  0.08232454586203486  accuracy =  0.90625\n",
      "now loss =  0.048487301723523044  accuracy =  0.96875\n",
      "now loss =  0.06767194161347928  accuracy =  0.925\n",
      "now loss =  0.0888444252723559  accuracy =  0.875\n",
      "now loss =  0.08276146337121337  accuracy =  0.90625\n",
      "now loss =  0.07438303992090724  accuracy =  0.9375\n",
      "now loss =  0.08076032483855701  accuracy =  0.890625\n",
      "now loss =  0.10869978743884218  accuracy =  0.84375\n",
      "now loss =  0.07396069643027803  accuracy =  0.90625\n",
      "now loss =  0.09324197119864784  accuracy =  0.875\n",
      "now loss =  0.07700980237525004  accuracy =  0.90625\n",
      "now loss =  0.1183831666041216  accuracy =  0.828125\n",
      "now loss =  0.09489223574744632  accuracy =  0.84375\n",
      "now loss =  0.06845199282082273  accuracy =  0.890625\n",
      "now loss =  0.10163520496202706  accuracy =  0.921875\n",
      "now loss =  0.06550607534071619  accuracy =  0.90625\n",
      "now loss =  0.061047632119016565  accuracy =  0.953125\n",
      "now loss =  0.09167075892181266  accuracy =  0.84375\n",
      "now loss =  0.09734365310434828  accuracy =  0.875\n",
      "now loss =  0.08730518685273732  accuracy =  0.875\n",
      "now loss =  0.05826265312901414  accuracy =  0.953125\n",
      "now loss =  0.0875970743347887  accuracy =  0.921875\n",
      "now loss =  0.1114917625616387  accuracy =  0.828125\n",
      "now loss =  0.0823284338053707  accuracy =  0.890625\n",
      "now loss =  0.08581062406751828  accuracy =  0.90625\n",
      "now loss =  0.07517603005465859  accuracy =  0.921875\n",
      "now loss =  0.08858466502712728  accuracy =  0.875\n",
      "now loss =  0.07482435735923884  accuracy =  0.890625\n",
      "now loss =  0.08752894982547976  accuracy =  0.859375\n",
      "now loss =  0.0703476469778615  accuracy =  0.859375\n",
      "now loss =  0.09145454531360404  accuracy =  0.875\n",
      "now loss =  0.1434704672132861  accuracy =  0.71875\n",
      "now loss =  0.07308063763982739  accuracy =  0.890625\n",
      "now loss =  0.09563267833332706  accuracy =  0.875\n",
      "now loss =  0.04322209127024311  accuracy =  0.95\n",
      "now loss =  0.0796517557448919  accuracy =  0.875\n",
      "now loss =  0.08472366149987412  accuracy =  0.890625\n",
      "now loss =  0.09004747568449155  accuracy =  0.890625\n",
      "now loss =  0.09023514689623999  accuracy =  0.890625\n",
      "now loss =  0.06366984136060096  accuracy =  0.96875\n",
      "now loss =  0.09088854858725542  accuracy =  0.890625\n",
      "now loss =  0.0897443501904211  accuracy =  0.875\n",
      "now loss =  0.09742681810634646  accuracy =  0.859375\n",
      "now loss =  0.09489936472592596  accuracy =  0.875\n",
      "now loss =  0.08513244514926281  accuracy =  0.890625\n",
      "now loss =  0.1010844904741014  accuracy =  0.875\n",
      "now loss =  0.09385016089377049  accuracy =  0.859375\n",
      "now loss =  0.0710551208447535  accuracy =  0.890625\n",
      "now loss =  0.08079112604900025  accuracy =  0.84375\n",
      "now loss =  0.06898373760540712  accuracy =  0.921875\n",
      "now loss =  0.09470338338585746  accuracy =  0.875\n",
      "now loss =  0.07618140561423561  accuracy =  0.9375\n",
      "now loss =  0.04706132294013467  accuracy =  0.9375\n",
      "now loss =  0.09016797915539988  accuracy =  0.875\n",
      "now loss =  0.0797358448660529  accuracy =  0.875\n",
      "now loss =  0.08307274738208556  accuracy =  0.875\n",
      "now loss =  0.07112195152293073  accuracy =  0.96875\n",
      "now loss =  0.07182572339974065  accuracy =  0.890625\n",
      "now loss =  0.08550074433097919  accuracy =  0.875\n",
      "now loss =  0.07101019627260073  accuracy =  0.90625\n",
      "now loss =  0.07481638014084531  accuracy =  0.921875\n",
      "now loss =  0.10853475691056148  accuracy =  0.84375\n",
      "now loss =  0.07703587176906782  accuracy =  0.90625\n",
      "now loss =  0.13188595183058013  accuracy =  0.828125\n",
      "now loss =  0.11577193235175597  accuracy =  0.84375\n",
      "now loss =  0.09302805851461521  accuracy =  0.859375\n",
      "now loss =  0.11007203688899221  accuracy =  0.825\n",
      "now loss =  0.07562363286636016  accuracy =  0.875\n",
      "now loss =  0.054830830119074414  accuracy =  0.953125\n",
      "now loss =  0.09163635624200236  accuracy =  0.890625\n",
      "now loss =  0.0873885472393015  accuracy =  0.859375\n",
      "now loss =  0.09319567284967328  accuracy =  0.859375\n",
      "now loss =  0.06503926221030723  accuracy =  0.9375\n",
      "now loss =  0.09169266096770289  accuracy =  0.859375\n",
      "now loss =  0.07850424539795492  accuracy =  0.9375\n",
      "now loss =  0.07667122950933386  accuracy =  0.90625\n",
      "now loss =  0.07444799034556468  accuracy =  0.9375\n",
      "now loss =  0.10094094892586726  accuracy =  0.875\n",
      "now loss =  0.10789935951981867  accuracy =  0.828125\n",
      "now loss =  0.08728689792337545  accuracy =  0.859375\n",
      "now loss =  0.11431532989538956  accuracy =  0.796875\n",
      "now loss =  0.08676718793219962  accuracy =  0.859375\n",
      "now loss =  0.08894326896395513  accuracy =  0.9\n",
      "now loss =  0.11115283602763049  accuracy =  0.859375\n",
      "now loss =  0.07672149586591483  accuracy =  0.9375\n",
      "now loss =  0.07442987449920652  accuracy =  0.875\n",
      "now loss =  0.07049625126000204  accuracy =  0.90625\n",
      "now loss =  0.09051352280352207  accuracy =  0.859375\n",
      "now loss =  0.0631638156716878  accuracy =  0.921875\n",
      "now loss =  0.12613850955679923  accuracy =  0.8125\n",
      "now loss =  0.09990936029262096  accuracy =  0.828125\n",
      "now loss =  0.08011234065679287  accuracy =  0.890625\n",
      "now loss =  0.08308546725528278  accuracy =  0.90625\n",
      "now loss =  0.08838573878419856  accuracy =  0.90625\n",
      "now loss =  0.07331124359735852  accuracy =  0.90625\n",
      "now loss =  0.08324234533855074  accuracy =  0.875\n",
      "now loss =  0.07395362635646867  accuracy =  0.921875\n",
      "now loss =  0.09388241584939797  accuracy =  0.84375\n",
      "now loss =  0.09645757755059607  accuracy =  0.9\n",
      "now loss =  0.05885770508685628  accuracy =  0.953125\n",
      "now loss =  0.11168321717293939  accuracy =  0.828125\n",
      "now loss =  0.08005877971420725  accuracy =  0.90625\n",
      "now loss =  0.07078614587209178  accuracy =  0.9375\n",
      "now loss =  0.08745206115101045  accuracy =  0.890625\n",
      "now loss =  0.07802013069230476  accuracy =  0.90625\n",
      "now loss =  0.08940959478571159  accuracy =  0.859375\n",
      "now loss =  0.07361396793086614  accuracy =  0.9375\n",
      "now loss =  0.09091308213484971  accuracy =  0.84375\n",
      "now loss =  0.0871491754245103  accuracy =  0.84375\n",
      "now loss =  0.07711721622816567  accuracy =  0.875\n",
      "now loss =  0.07999472521356805  accuracy =  0.875\n",
      "now loss =  0.10674741970974344  accuracy =  0.859375\n",
      "now loss =  0.0989237378372835  accuracy =  0.859375\n",
      "now loss =  0.10141482750893033  accuracy =  0.859375\n",
      "now loss =  0.07926998877588826  accuracy =  0.9\n",
      "now loss =  0.09496424277918143  accuracy =  0.859375\n",
      "now loss =  0.08015108118465958  accuracy =  0.890625\n",
      "now loss =  0.06191087789870971  accuracy =  0.921875\n",
      "now loss =  0.10315878062435738  accuracy =  0.828125\n",
      "now loss =  0.07372788458096935  accuracy =  0.90625\n",
      "now loss =  0.09595597157500044  accuracy =  0.875\n",
      "now loss =  0.06351026261344467  accuracy =  0.9375\n",
      "now loss =  0.0833599758143695  accuracy =  0.84375\n",
      "now loss =  0.08264429522732444  accuracy =  0.921875\n",
      "now loss =  0.10022564937950022  accuracy =  0.859375\n",
      "now loss =  0.09073347752041164  accuracy =  0.828125\n",
      "now loss =  0.08248832795774859  accuracy =  0.875\n",
      "now loss =  0.08967481223705925  accuracy =  0.890625\n",
      "now loss =  0.09689311922462066  accuracy =  0.90625\n",
      "now loss =  0.05838576167848863  accuracy =  0.9375\n",
      "now loss =  0.1362780104453068  accuracy =  0.775\n",
      "now loss =  0.10042580241562357  accuracy =  0.84375\n",
      "now loss =  0.09448707275636786  accuracy =  0.859375\n",
      "now loss =  0.1083717313608541  accuracy =  0.84375\n",
      "now loss =  0.0735571482951927  accuracy =  0.921875\n",
      "now loss =  0.09245422571778047  accuracy =  0.859375\n",
      "now loss =  0.10132146073672746  accuracy =  0.84375\n",
      "now loss =  0.0755764943070747  accuracy =  0.90625\n",
      "now loss =  0.05759352864094605  accuracy =  0.953125\n",
      "now loss =  0.08374832171738816  accuracy =  0.90625\n",
      "now loss =  0.09057220003689376  accuracy =  0.859375\n",
      "now loss =  0.08433255546681508  accuracy =  0.90625\n",
      "now loss =  0.0784227948128827  accuracy =  0.890625\n",
      "now loss =  0.08973060615372065  accuracy =  0.875\n",
      "now loss =  0.10106742877112791  accuracy =  0.890625\n",
      "now loss =  0.08102726094971727  accuracy =  0.890625\n",
      "now loss =  0.054330490608496707  accuracy =  0.925\n",
      "now loss =  0.09135316542426553  accuracy =  0.875\n",
      "now loss =  0.09478004526763922  accuracy =  0.875\n",
      "now loss =  0.10825716964707796  accuracy =  0.859375\n",
      "now loss =  0.07149069857412237  accuracy =  0.875\n",
      "now loss =  0.08185543912100424  accuracy =  0.890625\n",
      "now loss =  0.08930735785984079  accuracy =  0.84375\n",
      "now loss =  0.10270404023259197  accuracy =  0.859375\n",
      "now loss =  0.07514690508678079  accuracy =  0.90625\n",
      "now loss =  0.07932757994263116  accuracy =  0.890625\n",
      "now loss =  0.08644058731772956  accuracy =  0.875\n",
      "now loss =  0.06578254868943259  accuracy =  0.921875\n",
      "now loss =  0.0936657960866788  accuracy =  0.859375\n",
      "now loss =  0.07963182686599676  accuracy =  0.9375\n",
      "now loss =  0.05495188764655744  accuracy =  0.921875\n",
      "now loss =  0.10351271417468189  accuracy =  0.859375\n",
      "now loss =  0.09410254923987538  accuracy =  0.875\n",
      "now loss =  0.07720656332932374  accuracy =  0.921875\n",
      "now loss =  0.10613095755645122  accuracy =  0.828125\n",
      "now loss =  0.09967165931936067  accuracy =  0.84375\n",
      "now loss =  0.08823386628292006  accuracy =  0.90625\n",
      "now loss =  0.0679374022855074  accuracy =  0.921875\n",
      "now loss =  0.07218779635645509  accuracy =  0.890625\n",
      "now loss =  0.08640887806863345  accuracy =  0.890625\n",
      "now loss =  0.11351970215505323  accuracy =  0.78125\n",
      "now loss =  0.07227973779857108  accuracy =  0.90625\n",
      "now loss =  0.10784015862626317  accuracy =  0.828125\n",
      "now loss =  0.07389601863333833  accuracy =  0.921875\n",
      "now loss =  0.08529790197146733  accuracy =  0.875\n",
      "now loss =  0.09920802163095396  accuracy =  0.90625\n",
      "now loss =  0.06910773930153247  accuracy =  0.9375\n",
      "now loss =  0.07630455894309277  accuracy =  0.921875\n",
      "now loss =  0.07688257249130201  accuracy =  0.925\n",
      "now loss =  0.05596766726966475  accuracy =  0.921875\n",
      "now loss =  0.0859170885986203  accuracy =  0.890625\n",
      "now loss =  0.09008277886659284  accuracy =  0.859375\n",
      "now loss =  0.08643065948908872  accuracy =  0.875\n",
      "now loss =  0.0481013522071855  accuracy =  0.953125\n",
      "now loss =  0.10812509680383722  accuracy =  0.828125\n",
      "now loss =  0.07915557716017765  accuracy =  0.90625\n",
      "now loss =  0.11402413229696884  accuracy =  0.78125\n",
      "now loss =  0.05470270068271077  accuracy =  0.953125\n",
      "now loss =  0.11538651041162028  accuracy =  0.84375\n",
      "now loss =  0.10434659612868605  accuracy =  0.859375\n",
      "now loss =  0.07877955654225535  accuracy =  0.890625\n",
      "now loss =  0.07333324036775155  accuracy =  0.921875\n",
      "now loss =  0.09785795395171717  accuracy =  0.875\n",
      "now loss =  0.09566373975078393  accuracy =  0.875\n",
      "now loss =  0.08045733893459969  accuracy =  0.9\n",
      "now loss =  0.07347288608582327  accuracy =  0.953125\n",
      "now loss =  0.09129468065377475  accuracy =  0.84375\n",
      "now loss =  0.05554857833685467  accuracy =  0.953125\n",
      "now loss =  0.06993838502403338  accuracy =  0.90625\n",
      "now loss =  0.10820634971695303  accuracy =  0.828125\n",
      "now loss =  0.11507684671999774  accuracy =  0.828125\n",
      "now loss =  0.09778460364382166  accuracy =  0.84375\n",
      "now loss =  0.07533316554688561  accuracy =  0.921875\n",
      "now loss =  0.08717717110010637  accuracy =  0.84375\n",
      "now loss =  0.07208561297441299  accuracy =  0.90625\n",
      "now loss =  0.10255123431584698  accuracy =  0.828125\n",
      "now loss =  0.0971746211123722  accuracy =  0.828125\n",
      "now loss =  0.07789605783323914  accuracy =  0.90625\n",
      "now loss =  0.0798355389849872  accuracy =  0.890625\n",
      "now loss =  0.09356069591114267  accuracy =  0.875\n",
      "now loss =  0.06127350044917568  accuracy =  0.925\n",
      "now loss =  0.08746279092092171  accuracy =  0.875\n",
      "now loss =  0.09659803787288634  accuracy =  0.859375\n",
      "now loss =  0.08400787578007302  accuracy =  0.875\n",
      "now loss =  0.0776102904572262  accuracy =  0.859375\n",
      "now loss =  0.08318083452547038  accuracy =  0.875\n",
      "now loss =  0.09699904731902953  accuracy =  0.875\n",
      "now loss =  0.0955243716842491  accuracy =  0.875\n",
      "now loss =  0.0853981940965315  accuracy =  0.875\n",
      "now loss =  0.06612246501181915  accuracy =  0.90625\n",
      "now loss =  0.08981917608236656  accuracy =  0.859375\n",
      "now loss =  0.08733856785815625  accuracy =  0.875\n",
      "now loss =  0.07847974800004594  accuracy =  0.890625\n",
      "now loss =  0.08626262393827114  accuracy =  0.890625\n",
      "now loss =  0.0878944574782895  accuracy =  0.890625\n",
      "now loss =  0.09000564767636107  accuracy =  0.890625\n",
      "now loss =  0.07515464891841064  accuracy =  0.95\n",
      "now loss =  0.051535387676659515  accuracy =  0.921875\n",
      "now loss =  0.0584231368100087  accuracy =  0.90625\n",
      "now loss =  0.08943182871230257  accuracy =  0.859375\n",
      "now loss =  0.09532294085940254  accuracy =  0.859375\n",
      "now loss =  0.08551149023703458  accuracy =  0.859375\n",
      "now loss =  0.09887154151551514  accuracy =  0.890625\n",
      "now loss =  0.10275272401583907  accuracy =  0.875\n",
      "now loss =  0.0757861527365103  accuracy =  0.921875\n",
      "now loss =  0.0790701809105219  accuracy =  0.890625\n",
      "now loss =  0.07478890144495398  accuracy =  0.90625\n",
      "now loss =  0.09204344001768638  accuracy =  0.859375\n",
      "now loss =  0.07616901840837682  accuracy =  0.90625\n",
      "now loss =  0.0916336679050794  accuracy =  0.90625\n",
      "now loss =  0.11507406263513423  accuracy =  0.828125\n",
      "now loss =  0.08671063980346985  accuracy =  0.90625\n",
      "now loss =  0.11416668940764416  accuracy =  0.85\n",
      "now loss =  0.11191142089037187  accuracy =  0.84375\n",
      "now loss =  0.08201755198220545  accuracy =  0.9375\n",
      "now loss =  0.1197698121169791  accuracy =  0.765625\n",
      "now loss =  0.07062774600826333  accuracy =  0.921875\n",
      "now loss =  0.08119947822049592  accuracy =  0.859375\n",
      "now loss =  0.08590848700342206  accuracy =  0.875\n",
      "now loss =  0.09948427786568355  accuracy =  0.875\n",
      "now loss =  0.09060860351543065  accuracy =  0.859375\n",
      "now loss =  0.06768232302456192  accuracy =  0.9375\n",
      "now loss =  0.05923054816583166  accuracy =  0.953125\n",
      "now loss =  0.06972822372493098  accuracy =  0.90625\n",
      "now loss =  0.09546215066775227  accuracy =  0.875\n",
      "now loss =  0.08555796969698347  accuracy =  0.875\n",
      "now loss =  0.09073960571809966  accuracy =  0.875\n",
      "now loss =  0.07388676257450746  accuracy =  0.90625\n",
      "now loss =  0.08833811339260532  accuracy =  0.875\n",
      "now loss =  0.074756291661538  accuracy =  0.921875\n",
      "now loss =  0.09003911401339798  accuracy =  0.859375\n",
      "now loss =  0.08335963682409783  accuracy =  0.875\n",
      "now loss =  0.10850656036523287  accuracy =  0.859375\n",
      "now loss =  0.07555639607993613  accuracy =  0.9375\n",
      "now loss =  0.08432129297319647  accuracy =  0.90625\n",
      "now loss =  0.06945503694166448  accuracy =  0.921875\n",
      "now loss =  0.09353421787149394  accuracy =  0.875\n",
      "now loss =  0.11444241416558151  accuracy =  0.828125\n",
      "now loss =  0.08961125903414213  accuracy =  0.859375\n",
      "now loss =  0.07855764771192454  accuracy =  0.859375\n",
      "now loss =  0.08120684631423156  accuracy =  0.90625\n",
      "now loss =  0.07836801069857384  accuracy =  0.921875\n",
      "now loss =  0.07496657678225846  accuracy =  0.90625\n",
      "now loss =  0.08943741743275148  accuracy =  0.859375\n",
      "now loss =  0.08941926161362164  accuracy =  0.825\n",
      "now loss =  0.09770320046491629  accuracy =  0.875\n",
      "now loss =  0.14198032414708012  accuracy =  0.78125\n",
      "now loss =  0.03980661550307408  accuracy =  0.984375\n",
      "now loss =  0.07442454651293895  accuracy =  0.921875\n",
      "now loss =  0.057149414819180025  accuracy =  0.921875\n",
      "now loss =  0.09338616563775853  accuracy =  0.890625\n",
      "now loss =  0.08414248203426825  accuracy =  0.875\n",
      "now loss =  0.030210521777687113  accuracy =  0.984375\n",
      "now loss =  0.09565879673589722  accuracy =  0.84375\n",
      "now loss =  0.08547113282503745  accuracy =  0.921875\n",
      "now loss =  0.0607026118642081  accuracy =  0.9375\n",
      "now loss =  0.11839562754112415  accuracy =  0.828125\n",
      "now loss =  0.11187851846589518  accuracy =  0.8125\n",
      "now loss =  0.09112524664986885  accuracy =  0.859375\n",
      "now loss =  0.08412382411044164  accuracy =  0.890625\n",
      "now loss =  0.1178197181322533  accuracy =  0.775\n",
      "now loss =  0.06865937309845752  accuracy =  0.9375\n",
      "now loss =  0.1187787171437055  accuracy =  0.828125\n",
      "now loss =  0.09595301745037177  accuracy =  0.84375\n",
      "now loss =  0.07289967870549546  accuracy =  0.90625\n",
      "now loss =  0.07573629960443713  accuracy =  0.875\n",
      "now loss =  0.08413362956978351  accuracy =  0.921875\n",
      "now loss =  0.09411729731316355  accuracy =  0.875\n",
      "now loss =  0.06849706733709778  accuracy =  0.953125\n",
      "now loss =  0.11192293179632838  accuracy =  0.828125\n",
      "now loss =  0.055398369734481714  accuracy =  0.9375\n",
      "now loss =  0.08568163131911391  accuracy =  0.890625\n",
      "now loss =  0.08246480586070273  accuracy =  0.875\n",
      "now loss =  0.0629269412730529  accuracy =  0.9375\n",
      "now loss =  0.0998213557932996  accuracy =  0.859375\n",
      "now loss =  0.10470408436051702  accuracy =  0.859375\n",
      "now loss =  0.10837447097736301  accuracy =  0.825\n",
      "now loss =  0.07449708883817582  accuracy =  0.875\n",
      "now loss =  0.1033956328383667  accuracy =  0.828125\n",
      "now loss =  0.09101634101978848  accuracy =  0.859375\n",
      "now loss =  0.0915845768265903  accuracy =  0.875\n",
      "now loss =  0.06974239300128046  accuracy =  0.890625\n",
      "now loss =  0.10224489222687363  accuracy =  0.859375\n",
      "now loss =  0.08710729883193291  accuracy =  0.875\n",
      "now loss =  0.08621477095697747  accuracy =  0.890625\n",
      "now loss =  0.058225120823018  accuracy =  0.9375\n",
      "now loss =  0.07243513354989457  accuracy =  0.921875\n",
      "now loss =  0.0809523052891245  accuracy =  0.90625\n",
      "now loss =  0.0810418371533772  accuracy =  0.90625\n",
      "now loss =  0.09325770318145721  accuracy =  0.84375\n",
      "now loss =  0.09256521725531841  accuracy =  0.890625\n",
      "now loss =  0.08997446147976879  accuracy =  0.890625\n",
      "now loss =  0.1045385285004721  accuracy =  0.875\n",
      "now loss =  0.09789405403209835  accuracy =  0.875\n",
      "now loss =  0.08208916002754559  accuracy =  0.890625\n",
      "now loss =  0.062160493950860964  accuracy =  0.90625\n",
      "now loss =  0.09973162772599387  accuracy =  0.875\n",
      "now loss =  0.06003041826352436  accuracy =  0.921875\n",
      "now loss =  0.11038960570817698  accuracy =  0.84375\n",
      "now loss =  0.07226079300886559  accuracy =  0.90625\n",
      "now loss =  0.09090494506289085  accuracy =  0.890625\n",
      "now loss =  0.09518002714388249  accuracy =  0.859375\n",
      "now loss =  0.07570309382828916  accuracy =  0.90625\n",
      "now loss =  0.08571059253804747  accuracy =  0.875\n",
      "now loss =  0.09110373284827808  accuracy =  0.859375\n",
      "now loss =  0.08537417351428794  accuracy =  0.921875\n",
      "now loss =  0.11142401387721668  accuracy =  0.84375\n",
      "now loss =  0.07477775009733056  accuracy =  0.875\n",
      "now loss =  0.058632948740113176  accuracy =  0.925\n",
      "now loss =  0.08620061730059529  accuracy =  0.859375\n",
      "now loss =  0.07200396083857147  accuracy =  0.90625\n",
      "now loss =  0.09840353901025582  accuracy =  0.859375\n",
      "now loss =  0.06043845850383518  accuracy =  0.953125\n",
      "now loss =  0.08046017282259282  accuracy =  0.90625\n",
      "now loss =  0.10762148882526609  accuracy =  0.8125\n",
      "now loss =  0.07990185032585653  accuracy =  0.90625\n",
      "now loss =  0.07265793481084704  accuracy =  0.890625\n",
      "now loss =  0.08414054492655898  accuracy =  0.875\n",
      "now loss =  0.07942481028003705  accuracy =  0.890625\n",
      "now loss =  0.06901315230249155  accuracy =  0.90625\n",
      "now loss =  0.07266833326358155  accuracy =  0.9375\n",
      "now loss =  0.11846995622934114  accuracy =  0.8125\n",
      "now loss =  0.09953390319538502  accuracy =  0.828125\n",
      "now loss =  0.08714801113193435  accuracy =  0.890625\n",
      "now loss =  0.12525401222238297  accuracy =  0.85\n",
      "now loss =  0.06146038075910251  accuracy =  0.9375\n",
      "now loss =  0.08537824435225508  accuracy =  0.90625\n",
      "now loss =  0.07813090342207571  accuracy =  0.890625\n",
      "now loss =  0.07516796917561946  accuracy =  0.90625\n",
      "now loss =  0.11076872624098599  accuracy =  0.828125\n",
      "now loss =  0.0827683338840823  accuracy =  0.890625\n",
      "now loss =  0.0959356730228066  accuracy =  0.8125\n",
      "now loss =  0.10046168463125327  accuracy =  0.828125\n",
      "now loss =  0.10353081258406314  accuracy =  0.8125\n",
      "now loss =  0.08541142561987519  accuracy =  0.859375\n",
      "now loss =  0.08900656543743259  accuracy =  0.890625\n",
      "now loss =  0.10804263205274461  accuracy =  0.84375\n",
      "now loss =  0.06296836352700605  accuracy =  0.9375\n",
      "now loss =  0.08894573599113285  accuracy =  0.921875\n",
      "now loss =  0.0701930350512833  accuracy =  0.921875\n",
      "now loss =  0.06778748658938685  accuracy =  0.9\n",
      "now loss =  0.059050665496354966  accuracy =  0.9375\n",
      "now loss =  0.08460213935398413  accuracy =  0.90625\n",
      "now loss =  0.08423879378179058  accuracy =  0.9375\n",
      "now loss =  0.08074728941931429  accuracy =  0.90625\n",
      "now loss =  0.06795981029161208  accuracy =  0.90625\n",
      "now loss =  0.08254434141937633  accuracy =  0.890625\n",
      "now loss =  0.10306521622724064  accuracy =  0.875\n",
      "now loss =  0.0797032821635914  accuracy =  0.875\n",
      "now loss =  0.09753430056747556  accuracy =  0.828125\n",
      "now loss =  0.10471855592376578  accuracy =  0.8125\n",
      "now loss =  0.07117971328186598  accuracy =  0.921875\n",
      "now loss =  0.09648698735209292  accuracy =  0.875\n",
      "now loss =  0.08125576438876275  accuracy =  0.875\n",
      "now loss =  0.10739531089512468  accuracy =  0.828125\n",
      "now loss =  0.0847876898860762  accuracy =  0.890625\n",
      "now loss =  0.09460914215056879  accuracy =  0.9\n",
      "now loss =  0.07109397122887443  accuracy =  0.890625\n",
      "now loss =  0.0762834832247024  accuracy =  0.90625\n",
      "now loss =  0.06910884338219733  accuracy =  0.921875\n",
      "now loss =  0.12993167491548344  accuracy =  0.765625\n",
      "now loss =  0.09993481531177413  accuracy =  0.921875\n",
      "now loss =  0.11624799572688693  accuracy =  0.8125\n",
      "now loss =  0.06244152907459677  accuracy =  0.921875\n",
      "now loss =  0.0912816142149589  accuracy =  0.90625\n",
      "now loss =  0.09032347679595643  accuracy =  0.875\n",
      "now loss =  0.11245576154972897  accuracy =  0.828125\n",
      "now loss =  0.0655007236775838  accuracy =  0.9375\n",
      "now loss =  0.09418112298440007  accuracy =  0.859375\n",
      "now loss =  0.07463856340359848  accuracy =  0.890625\n",
      "now loss =  0.08819503291189681  accuracy =  0.875\n",
      "now loss =  0.06777186834471018  accuracy =  0.90625\n",
      "now loss =  0.04860636981479286  accuracy =  0.975\n",
      "now loss =  0.09781075054223502  accuracy =  0.890625\n",
      "now loss =  0.07625858416078529  accuracy =  0.875\n",
      "now loss =  0.1078082375581711  accuracy =  0.84375\n",
      "now loss =  0.07719362242930267  accuracy =  0.859375\n",
      "now loss =  0.0840629814751348  accuracy =  0.875\n",
      "now loss =  0.07014262429317743  accuracy =  0.921875\n",
      "now loss =  0.09435540269434975  accuracy =  0.875\n",
      "now loss =  0.08580797014123316  accuracy =  0.890625\n",
      "now loss =  0.09846315769324486  accuracy =  0.875\n",
      "now loss =  0.07769070243873935  accuracy =  0.921875\n",
      "now loss =  0.07001209642905248  accuracy =  0.9375\n",
      "now loss =  0.054548924783067  accuracy =  0.921875\n",
      "now loss =  0.1287016929061192  accuracy =  0.78125\n",
      "now loss =  0.09126510719995662  accuracy =  0.859375\n",
      "now loss =  0.09220666650418827  accuracy =  0.875\n",
      "now loss =  0.07395061073611  accuracy =  0.95\n",
      "now loss =  0.08454987664401688  accuracy =  0.90625\n",
      "now loss =  0.07973860239106563  accuracy =  0.921875\n",
      "now loss =  0.09297453146978432  accuracy =  0.859375\n",
      "now loss =  0.08186020068199806  accuracy =  0.921875\n",
      "now loss =  0.11269776369447972  accuracy =  0.828125\n",
      "now loss =  0.10491816345947502  accuracy =  0.84375\n",
      "now loss =  0.08072966789968843  accuracy =  0.921875\n",
      "now loss =  0.08366122059866761  accuracy =  0.890625\n",
      "now loss =  0.0917333735342102  accuracy =  0.84375\n",
      "now loss =  0.07050144815676115  accuracy =  0.921875\n",
      "now loss =  0.09091811603825423  accuracy =  0.84375\n",
      "now loss =  0.08064859568152025  accuracy =  0.890625\n",
      "now loss =  0.06749475623032797  accuracy =  0.9375\n",
      "now loss =  0.0823329082494296  accuracy =  0.859375\n",
      "now loss =  0.10645511157864854  accuracy =  0.859375\n",
      "now loss =  0.04172859494411144  accuracy =  1.0\n",
      "now loss =  0.04815964920835798  accuracy =  0.96875\n",
      "now loss =  0.10267489270663716  accuracy =  0.828125\n",
      "now loss =  0.07705143471002074  accuracy =  0.90625\n",
      "now loss =  0.10345520966190697  accuracy =  0.859375\n",
      "now loss =  0.10920569410015112  accuracy =  0.84375\n",
      "now loss =  0.09905102026085844  accuracy =  0.859375\n",
      "now loss =  0.10392402458006295  accuracy =  0.84375\n",
      "now loss =  0.08065506816794238  accuracy =  0.9375\n",
      "now loss =  0.08916604313948992  accuracy =  0.875\n",
      "now loss =  0.09955866315215983  accuracy =  0.859375\n",
      "now loss =  0.054886024973622924  accuracy =  0.953125\n",
      "now loss =  0.09081790649152655  accuracy =  0.890625\n",
      "now loss =  0.08997665281545383  accuracy =  0.875\n",
      "now loss =  0.06359021970919732  accuracy =  0.90625\n",
      "now loss =  0.08077775385282117  accuracy =  0.859375\n",
      "now loss =  0.07946558206364204  accuracy =  0.9\n",
      "now loss =  0.05105175625427957  accuracy =  0.9375\n",
      "now loss =  0.07288573760989622  accuracy =  0.921875\n",
      "now loss =  0.1110163861903868  accuracy =  0.859375\n",
      "now loss =  0.07961078545891526  accuracy =  0.9375\n",
      "now loss =  0.07561029119844428  accuracy =  0.90625\n",
      "now loss =  0.08266201175048965  accuracy =  0.890625\n",
      "now loss =  0.055502288281290474  accuracy =  0.953125\n",
      "now loss =  0.08405036833717446  accuracy =  0.84375\n",
      "now loss =  0.10346405882161425  accuracy =  0.84375\n",
      "now loss =  0.10354560438839785  accuracy =  0.84375\n",
      "now loss =  0.09312216368889537  accuracy =  0.859375\n",
      "now loss =  0.08065670543938258  accuracy =  0.875\n",
      "now loss =  0.11681398642458485  accuracy =  0.8125\n",
      "now loss =  0.09151894393754247  accuracy =  0.875\n",
      "now loss =  0.08301986157081374  accuracy =  0.890625\n",
      "now loss =  0.1174079006047997  accuracy =  0.825\n",
      "now loss =  0.0955511316421832  accuracy =  0.828125\n",
      "now loss =  0.0650310643353908  accuracy =  0.921875\n",
      "now loss =  0.11311957330963657  accuracy =  0.828125\n",
      "now loss =  0.08134849536577024  accuracy =  0.859375\n",
      "now loss =  0.09733161769147025  accuracy =  0.859375\n",
      "now loss =  0.09802148958951862  accuracy =  0.875\n",
      "now loss =  0.06618000777785107  accuracy =  0.921875\n",
      "now loss =  0.1019821419644602  accuracy =  0.859375\n",
      "now loss =  0.09418181354256219  accuracy =  0.890625\n",
      "now loss =  0.09948177645103232  accuracy =  0.859375\n",
      "now loss =  0.08984155481319962  accuracy =  0.859375\n",
      "now loss =  0.07754115108791008  accuracy =  0.890625\n",
      "now loss =  0.06222875857715311  accuracy =  0.921875\n",
      "now loss =  0.07686043857082464  accuracy =  0.890625\n",
      "now loss =  0.05044398195549857  accuracy =  0.984375\n",
      "now loss =  0.11527940050649017  accuracy =  0.8\n",
      "now loss =  0.08605628338914628  accuracy =  0.875\n",
      "now loss =  0.08218598722179027  accuracy =  0.875\n",
      "now loss =  0.07833169957487796  accuracy =  0.90625\n",
      "now loss =  0.10498334512155645  accuracy =  0.828125\n",
      "now loss =  0.07177972378908354  accuracy =  0.90625\n",
      "now loss =  0.09759209084511627  accuracy =  0.859375\n",
      "now loss =  0.08124733152481317  accuracy =  0.875\n",
      "now loss =  0.06941749851868038  accuracy =  0.9375\n",
      "now loss =  0.0847048359234422  accuracy =  0.921875\n",
      "now loss =  0.10032485196845652  accuracy =  0.796875\n",
      "now loss =  0.0844940594143122  accuracy =  0.90625\n",
      "now loss =  0.07834345964686272  accuracy =  0.921875\n",
      "now loss =  0.10407875169928478  accuracy =  0.828125\n",
      "now loss =  0.09807439142749574  accuracy =  0.859375\n",
      "now loss =  0.08778018797882635  accuracy =  0.921875\n",
      "now loss =  0.044178990700152965  accuracy =  0.975\n",
      "now loss =  0.10891254762387775  accuracy =  0.828125\n",
      "now loss =  0.09504279023628678  accuracy =  0.84375\n",
      "now loss =  0.059315991778885566  accuracy =  0.96875\n",
      "now loss =  0.07875638938897597  accuracy =  0.921875\n",
      "now loss =  0.06310807879353982  accuracy =  0.953125\n",
      "now loss =  0.06470460615241527  accuracy =  0.90625\n",
      "now loss =  0.09101581730134578  accuracy =  0.84375\n",
      "now loss =  0.08892195964217464  accuracy =  0.875\n",
      "now loss =  0.06832738906501037  accuracy =  0.90625\n",
      "now loss =  0.10653568371443259  accuracy =  0.84375\n",
      "now loss =  0.08269850097247392  accuracy =  0.875\n",
      "now loss =  0.0962500223028712  accuracy =  0.90625\n",
      "now loss =  0.09288829301171338  accuracy =  0.859375\n",
      "now loss =  0.07780340060602595  accuracy =  0.90625\n",
      "now loss =  0.09831037503812678  accuracy =  0.859375\n",
      "now loss =  0.11797716909963696  accuracy =  0.825\n",
      "now loss =  0.09836472682523972  accuracy =  0.859375\n",
      "now loss =  0.11122921367807725  accuracy =  0.828125\n",
      "now loss =  0.08721932253663742  accuracy =  0.90625\n",
      "now loss =  0.08229985136462381  accuracy =  0.859375\n",
      "now loss =  0.09540898218049337  accuracy =  0.84375\n",
      "now loss =  0.10730446377255284  accuracy =  0.859375\n",
      "now loss =  0.07791705326087958  accuracy =  0.921875\n",
      "now loss =  0.05584675419364777  accuracy =  0.953125\n",
      "now loss =  0.09075911218374212  accuracy =  0.84375\n",
      "now loss =  0.07584614404089615  accuracy =  0.90625\n",
      "now loss =  0.09044190880605366  accuracy =  0.875\n",
      "now loss =  0.09625403710489559  accuracy =  0.875\n",
      "now loss =  0.069759454739471  accuracy =  0.90625\n",
      "now loss =  0.08047563973849006  accuracy =  0.890625\n",
      "now loss =  0.06637425934794347  accuracy =  0.9375\n",
      "now loss =  0.08397577974144459  accuracy =  0.9\n",
      "now loss =  0.0712424572116829  accuracy =  0.953125\n",
      "now loss =  0.0861728976883771  accuracy =  0.90625\n",
      "now loss =  0.045401651442803545  accuracy =  0.9375\n",
      "now loss =  0.04970618122906502  accuracy =  0.921875\n",
      "now loss =  0.10072733220990117  accuracy =  0.875\n",
      "now loss =  0.1043115195294859  accuracy =  0.84375\n",
      "now loss =  0.08921782946568947  accuracy =  0.859375\n",
      "now loss =  0.09561206889768625  accuracy =  0.875\n",
      "now loss =  0.07987049438519638  accuracy =  0.890625\n",
      "now loss =  0.08113960795501232  accuracy =  0.890625\n",
      "now loss =  0.08779244980585985  accuracy =  0.875\n",
      "now loss =  0.13181118112146842  accuracy =  0.765625\n",
      "now loss =  0.07899514752667536  accuracy =  0.921875\n",
      "now loss =  0.08948419742325463  accuracy =  0.875\n",
      "now loss =  0.08984259006569027  accuracy =  0.859375\n",
      "now loss =  0.08997948199828454  accuracy =  0.925\n",
      "now loss =  0.09050442555896616  accuracy =  0.921875\n",
      "now loss =  0.08135613127061933  accuracy =  0.90625\n",
      "now loss =  0.08835819364133765  accuracy =  0.890625\n",
      "now loss =  0.06876095304419577  accuracy =  0.90625\n",
      "now loss =  0.08804424074117964  accuracy =  0.890625\n",
      "now loss =  0.07579708599849305  accuracy =  0.9375\n",
      "now loss =  0.10175742882005415  accuracy =  0.84375\n",
      "now loss =  0.09020317529787691  accuracy =  0.875\n",
      "now loss =  0.057748652289254396  accuracy =  0.921875\n",
      "now loss =  0.09851460987435505  accuracy =  0.859375\n",
      "now loss =  0.08125516335729725  accuracy =  0.90625\n",
      "now loss =  0.09104644235407873  accuracy =  0.875\n",
      "now loss =  0.08095247864623374  accuracy =  0.890625\n",
      "now loss =  0.09534177432276314  accuracy =  0.84375\n",
      "now loss =  0.07679616614485874  accuracy =  0.859375\n",
      "now loss =  0.11592578994120162  accuracy =  0.85\n",
      "now loss =  0.09016547094959353  accuracy =  0.875\n",
      "now loss =  0.09614975353646327  accuracy =  0.859375\n",
      "now loss =  0.10149429354815842  accuracy =  0.859375\n",
      "now loss =  0.10366869073389515  accuracy =  0.84375\n",
      "now loss =  0.09379582255944854  accuracy =  0.859375\n",
      "now loss =  0.05844015850065937  accuracy =  0.9375\n",
      "now loss =  0.08339939997946227  accuracy =  0.921875\n",
      "now loss =  0.07787936968279718  accuracy =  0.890625\n",
      "now loss =  0.075338813045453  accuracy =  0.890625\n",
      "now loss =  0.08985257307900146  accuracy =  0.859375\n",
      "now loss =  0.06752928950328173  accuracy =  0.921875\n",
      "now loss =  0.08683838083087386  accuracy =  0.890625\n",
      "now loss =  0.10917468240043277  accuracy =  0.796875\n",
      "now loss =  0.08866247485773118  accuracy =  0.90625\n",
      "now loss =  0.07193274315995528  accuracy =  0.953125\n",
      "now loss =  0.08200649853130264  accuracy =  0.9\n",
      "now loss =  0.08180804394572125  accuracy =  0.875\n",
      "now loss =  0.08509188369201892  accuracy =  0.90625\n",
      "now loss =  0.05149482059997266  accuracy =  0.9375\n",
      "now loss =  0.114488179375559  accuracy =  0.796875\n",
      "now loss =  0.09718117480452003  accuracy =  0.84375\n",
      "now loss =  0.0774811616318834  accuracy =  0.90625\n",
      "now loss =  0.09183107038003253  accuracy =  0.90625\n",
      "now loss =  0.0811006984305857  accuracy =  0.875\n",
      "now loss =  0.08895511973643902  accuracy =  0.875\n",
      "now loss =  0.09135717221456154  accuracy =  0.875\n",
      "now loss =  0.09112410816337574  accuracy =  0.859375\n",
      "now loss =  0.09096922597916443  accuracy =  0.890625\n",
      "now loss =  0.08799041340223372  accuracy =  0.90625\n",
      "now loss =  0.07409666759596356  accuracy =  0.890625\n",
      "now loss =  0.06665643449459133  accuracy =  0.9375\n",
      "now loss =  0.12910550127994927  accuracy =  0.75\n",
      "now loss =  0.11924487073735611  accuracy =  0.84375\n",
      "now loss =  0.08319474221232026  accuracy =  0.90625\n",
      "now loss =  0.0757014911661068  accuracy =  0.875\n",
      "now loss =  0.05631410494122156  accuracy =  0.921875\n",
      "now loss =  0.09049360417207  accuracy =  0.875\n",
      "now loss =  0.07784077415622587  accuracy =  0.875\n",
      "now loss =  0.09174745512891552  accuracy =  0.875\n",
      "now loss =  0.07741124623156605  accuracy =  0.921875\n",
      "now loss =  0.07350127999798797  accuracy =  0.9375\n",
      "now loss =  0.07097458342851842  accuracy =  0.921875\n",
      "now loss =  0.1064270421384533  accuracy =  0.84375\n",
      "now loss =  0.10593910821363643  accuracy =  0.84375\n",
      "now loss =  0.08376720691582298  accuracy =  0.84375\n",
      "now loss =  0.09219861641282576  accuracy =  0.859375\n",
      "now loss =  0.08653744331342006  accuracy =  0.890625\n",
      "now loss =  0.07736301409165358  accuracy =  0.925\n",
      "now loss =  0.059723431386057756  accuracy =  0.953125\n",
      "now loss =  0.0911341286780571  accuracy =  0.890625\n",
      "now loss =  0.0740607106553154  accuracy =  0.890625\n",
      "now loss =  0.10670139047905028  accuracy =  0.859375\n",
      "now loss =  0.06720792724809954  accuracy =  0.921875\n",
      "now loss =  0.09610196524011604  accuracy =  0.875\n",
      "now loss =  0.08694893340166848  accuracy =  0.921875\n",
      "now loss =  0.08145089267420352  accuracy =  0.890625\n",
      "now loss =  0.08181242274937552  accuracy =  0.859375\n",
      "now loss =  0.08071953505536719  accuracy =  0.90625\n",
      "now loss =  0.06484394486277452  accuracy =  0.890625\n",
      "now loss =  0.1306110021687571  accuracy =  0.765625\n",
      "now loss =  0.08960598367585418  accuracy =  0.890625\n",
      "now loss =  0.09837711951914814  accuracy =  0.859375\n",
      "now loss =  0.08417122240983527  accuracy =  0.90625\n",
      "now loss =  0.08920001030206325  accuracy =  0.85\n",
      "now loss =  0.10210590819309087  accuracy =  0.859375\n",
      "now loss =  0.0678326621706003  accuracy =  0.9375\n",
      "now loss =  0.09409785808336887  accuracy =  0.890625\n",
      "now loss =  0.07484528895005585  accuracy =  0.90625\n",
      "now loss =  0.10168821014061769  accuracy =  0.84375\n",
      "now loss =  0.08975966697344487  accuracy =  0.84375\n",
      "now loss =  0.09332441076884011  accuracy =  0.828125\n",
      "now loss =  0.09835415070038295  accuracy =  0.859375\n",
      "now loss =  0.09581702530112818  accuracy =  0.875\n",
      "now loss =  0.11548503677074451  accuracy =  0.828125\n",
      "now loss =  0.06850268510620118  accuracy =  0.890625\n",
      "now loss =  0.06676931748924478  accuracy =  0.90625\n",
      "now loss =  0.08103665558023306  accuracy =  0.921875\n",
      "now loss =  0.06623636209488773  accuracy =  0.953125\n",
      "now loss =  0.08969536109236954  accuracy =  0.90625\n",
      "now loss =  0.05466195496395756  accuracy =  0.95\n",
      "now loss =  0.06257589198133157  accuracy =  0.9375\n",
      "now loss =  0.08333725970026554  accuracy =  0.890625\n",
      "now loss =  0.08878940770161742  accuracy =  0.875\n",
      "now loss =  0.06342086724463394  accuracy =  0.9375\n",
      "now loss =  0.07328026919522033  accuracy =  0.90625\n",
      "now loss =  0.1018528127458568  accuracy =  0.828125\n",
      "now loss =  0.07405631351494697  accuracy =  0.890625\n",
      "now loss =  0.054675630135761155  accuracy =  0.953125\n",
      "now loss =  0.09725012039856473  accuracy =  0.875\n",
      "now loss =  0.09066966498677806  accuracy =  0.890625\n",
      "now loss =  0.0670844306635657  accuracy =  0.921875\n",
      "now loss =  0.07806028111206333  accuracy =  0.90625\n",
      "now loss =  0.09432901857858714  accuracy =  0.875\n",
      "now loss =  0.10250830380909304  accuracy =  0.828125\n",
      "now loss =  0.1446009477881019  accuracy =  0.75\n",
      "now loss =  0.10722569544109213  accuracy =  0.85\n",
      "now loss =  0.11483726414903617  accuracy =  0.8125\n",
      "now loss =  0.09806765950984214  accuracy =  0.875\n",
      "now loss =  0.0781828780907679  accuracy =  0.859375\n",
      "now loss =  0.0846625442818921  accuracy =  0.890625\n",
      "now loss =  0.1253383657788567  accuracy =  0.765625\n",
      "now loss =  0.07224067594111942  accuracy =  0.90625\n",
      "now loss =  0.09092904513590461  accuracy =  0.84375\n",
      "now loss =  0.04032915450395272  accuracy =  0.96875\n",
      "now loss =  0.07663289007513499  accuracy =  0.921875\n",
      "now loss =  0.10519155054153498  accuracy =  0.84375\n",
      "now loss =  0.08386474768875889  accuracy =  0.921875\n",
      "now loss =  0.09971475950550676  accuracy =  0.859375\n",
      "now loss =  0.07601226211373857  accuracy =  0.890625\n",
      "now loss =  0.06169405503555707  accuracy =  0.96875\n",
      "now loss =  0.074973642323402  accuracy =  0.921875\n",
      "now loss =  0.09267892989689117  accuracy =  0.875\n",
      "now loss =  0.06834535814259257  accuracy =  0.921875\n",
      "now loss =  0.10679896178448355  accuracy =  0.859375\n",
      "now loss =  0.08819817836096855  accuracy =  0.890625\n",
      "now loss =  0.07404194294687533  accuracy =  0.90625\n",
      "now loss =  0.07538936749344531  accuracy =  0.921875\n",
      "now loss =  0.07738293163356388  accuracy =  0.90625\n",
      "now loss =  0.08321288469110424  accuracy =  0.890625\n",
      "now loss =  0.10727543492085416  accuracy =  0.84375\n",
      "now loss =  0.08974981328557868  accuracy =  0.84375\n",
      "now loss =  0.0876487903461548  accuracy =  0.875\n",
      "now loss =  0.061595712862060635  accuracy =  0.953125\n",
      "now loss =  0.09554138552377298  accuracy =  0.859375\n",
      "now loss =  0.06455511928752122  accuracy =  0.9375\n",
      "now loss =  0.11980416125978  accuracy =  0.78125\n",
      "now loss =  0.08997902332079524  accuracy =  0.890625\n",
      "now loss =  0.07683586369038822  accuracy =  0.875\n",
      "now loss =  0.09662930018022745  accuracy =  0.890625\n",
      "now loss =  0.08528012931219058  accuracy =  0.875\n",
      "now loss =  0.09539456083261474  accuracy =  0.84375\n",
      "now loss =  0.09031514326702739  accuracy =  0.90625\n",
      "now loss =  0.10784470198186669  accuracy =  0.796875\n",
      "now loss =  0.0941057776342216  accuracy =  0.875\n",
      "now loss =  0.07013446211253559  accuracy =  0.875\n",
      "now loss =  0.08142930087370459  accuracy =  0.90625\n",
      "now loss =  0.07378538446015306  accuracy =  0.90625\n",
      "now loss =  0.0720540396782883  accuracy =  0.9375\n",
      "now loss =  0.06444818915282505  accuracy =  0.9375\n",
      "now loss =  0.08209478821551482  accuracy =  0.90625\n",
      "now loss =  0.08776211987099129  accuracy =  0.875\n",
      "now loss =  0.09999750894033502  accuracy =  0.8125\n",
      "now loss =  0.0901129752269981  accuracy =  0.875\n",
      "now loss =  0.08199025269379126  accuracy =  0.925\n",
      "now loss =  0.08838519563638658  accuracy =  0.875\n",
      "now loss =  0.08005487828901346  accuracy =  0.921875\n",
      "now loss =  0.10906951014114157  accuracy =  0.84375\n",
      "now loss =  0.11877736801614383  accuracy =  0.828125\n",
      "now loss =  0.10104519592303127  accuracy =  0.828125\n",
      "now loss =  0.09554500053962647  accuracy =  0.90625\n",
      "now loss =  0.07577211889989957  accuracy =  0.875\n",
      "now loss =  0.08879588946988815  accuracy =  0.875\n",
      "now loss =  0.09434211571036315  accuracy =  0.890625\n",
      "now loss =  0.07725022417409827  accuracy =  0.875\n",
      "now loss =  0.06112974337987244  accuracy =  0.953125\n",
      "now loss =  0.05328358939983997  accuracy =  0.953125\n",
      "now loss =  0.059680930867026576  accuracy =  0.90625\n",
      "now loss =  0.08433683349166998  accuracy =  0.859375\n",
      "now loss =  0.08210208834420282  accuracy =  0.875\n",
      "now loss =  0.11379562747808163  accuracy =  0.875\n",
      "now loss =  0.10280173024387113  accuracy =  0.84375\n",
      "now loss =  0.07885492644571271  accuracy =  0.90625\n",
      "now loss =  0.07056243048120803  accuracy =  0.9375\n",
      "now loss =  0.07939779394204388  accuracy =  0.90625\n",
      "now loss =  0.06844319593686517  accuracy =  0.90625\n",
      "now loss =  0.080958472109045  accuracy =  0.875\n",
      "now loss =  0.11004429249354887  accuracy =  0.828125\n",
      "now loss =  0.07697545720563001  accuracy =  0.90625\n",
      "now loss =  0.09109245410703556  accuracy =  0.859375\n",
      "now loss =  0.09462360168036899  accuracy =  0.875\n",
      "now loss =  0.08120761204387208  accuracy =  0.859375\n",
      "now loss =  0.10029622215862466  accuracy =  0.859375\n",
      "now loss =  0.07567452939390794  accuracy =  0.90625\n",
      "now loss =  0.09877092296100881  accuracy =  0.875\n",
      "now loss =  0.0805867766741207  accuracy =  0.890625\n",
      "now loss =  0.07037531504731717  accuracy =  0.975\n",
      "now loss =  0.09133544279083544  accuracy =  0.875\n",
      "now loss =  0.08129616894472314  accuracy =  0.875\n",
      "now loss =  0.09357284340561375  accuracy =  0.859375\n",
      "now loss =  0.12208237506956726  accuracy =  0.8125\n",
      "now loss =  0.08781485538262579  accuracy =  0.90625\n",
      "now loss =  0.06402953355979324  accuracy =  0.921875\n",
      "now loss =  0.10167752304119375  accuracy =  0.875\n",
      "now loss =  0.11349314853128506  accuracy =  0.828125\n",
      "now loss =  0.07597032131687734  accuracy =  0.921875\n",
      "now loss =  0.07947192898567303  accuracy =  0.90625\n",
      "now loss =  0.07764680567668464  accuracy =  0.90625\n",
      "now loss =  0.05774249992893282  accuracy =  0.96875\n",
      "now loss =  0.07478447001087246  accuracy =  0.859375\n",
      "now loss =  0.08170545338702051  accuracy =  0.890625\n",
      "now loss =  0.08685873283732062  accuracy =  0.890625\n",
      "now loss =  0.078606306747862  accuracy =  0.9\n",
      "now loss =  0.09180771441747239  accuracy =  0.859375\n",
      "now loss =  0.09793020138475272  accuracy =  0.828125\n",
      "now loss =  0.09273905707677808  accuracy =  0.84375\n",
      "now loss =  0.08758622486804414  accuracy =  0.875\n",
      "now loss =  0.08953636695914785  accuracy =  0.890625\n",
      "now loss =  0.07268599299149213  accuracy =  0.921875\n",
      "now loss =  0.08116972113251694  accuracy =  0.890625\n",
      "now loss =  0.07621832084690883  accuracy =  0.890625\n",
      "now loss =  0.0798437923029117  accuracy =  0.90625\n",
      "now loss =  0.07503191965923289  accuracy =  0.90625\n",
      "now loss =  0.06498388731207222  accuracy =  0.921875\n",
      "now loss =  0.0983962700657013  accuracy =  0.875\n",
      "now loss =  0.11449330558156054  accuracy =  0.828125\n",
      "now loss =  0.10063191732496848  accuracy =  0.859375\n",
      "now loss =  0.0656064253838772  accuracy =  0.921875\n",
      "now loss =  0.09065430945477951  accuracy =  0.9\n",
      "now loss =  0.10630173229767353  accuracy =  0.84375\n",
      "now loss =  0.10204549706409963  accuracy =  0.859375\n",
      "now loss =  0.08884824276689055  accuracy =  0.90625\n",
      "now loss =  0.08079465064899038  accuracy =  0.859375\n",
      "now loss =  0.08387447264472765  accuracy =  0.890625\n",
      "now loss =  0.07888169278995957  accuracy =  0.90625\n",
      "now loss =  0.08911026082490534  accuracy =  0.890625\n",
      "now loss =  0.08072452279281882  accuracy =  0.875\n",
      "now loss =  0.07052226483731971  accuracy =  0.90625\n",
      "now loss =  0.08380272602861086  accuracy =  0.875\n",
      "now loss =  0.08904430380011225  accuracy =  0.890625\n",
      "now loss =  0.0652855082628597  accuracy =  0.921875\n",
      "now loss =  0.09692876858338861  accuracy =  0.859375\n",
      "now loss =  0.07874941951518397  accuracy =  0.921875\n",
      "now loss =  0.07835464611996179  accuracy =  0.921875\n",
      "now loss =  0.1069405034688025  accuracy =  0.775\n",
      "now loss =  0.08801615259277167  accuracy =  0.875\n",
      "now loss =  0.07342594910618652  accuracy =  0.90625\n",
      "now loss =  0.09146750613371143  accuracy =  0.84375\n",
      "now loss =  0.07723361447156103  accuracy =  0.90625\n",
      "now loss =  0.08684339236526568  accuracy =  0.890625\n",
      "now loss =  0.10118393836388064  accuracy =  0.828125\n",
      "now loss =  0.06451794713934128  accuracy =  0.9375\n",
      "now loss =  0.08560211952277208  accuracy =  0.890625\n",
      "now loss =  0.09666451712488848  accuracy =  0.84375\n",
      "now loss =  0.0624693896152066  accuracy =  0.953125\n",
      "now loss =  0.08869475365580953  accuracy =  0.859375\n",
      "now loss =  0.09382464655009726  accuracy =  0.875\n",
      "now loss =  0.08605680403476228  accuracy =  0.90625\n",
      "now loss =  0.07869421306984947  accuracy =  0.90625\n",
      "now loss =  0.1215538469093715  accuracy =  0.84375\n",
      "now loss =  0.07506119222566228  accuracy =  0.9\n",
      "now loss =  0.06025025233743615  accuracy =  0.9375\n",
      "now loss =  0.12140535292321125  accuracy =  0.796875\n",
      "now loss =  0.11055955352528661  accuracy =  0.84375\n",
      "now loss =  0.06306219953438164  accuracy =  0.921875\n",
      "now loss =  0.08655558963928546  accuracy =  0.875\n",
      "now loss =  0.07575667798812612  accuracy =  0.875\n",
      "now loss =  0.08738702519258756  accuracy =  0.890625\n",
      "now loss =  0.05477340028623809  accuracy =  0.96875\n",
      "now loss =  0.10112563121353638  accuracy =  0.859375\n",
      "now loss =  0.0962357898001201  accuracy =  0.84375\n",
      "now loss =  0.06792142560613308  accuracy =  0.9375\n",
      "now loss =  0.07112494428701457  accuracy =  0.921875\n",
      "now loss =  0.09135644568873366  accuracy =  0.875\n",
      "now loss =  0.09442560816164425  accuracy =  0.8125\n",
      "now loss =  0.09465808633107864  accuracy =  0.890625\n",
      "now loss =  0.10818049717836402  accuracy =  0.825\n",
      "now loss =  0.07410869137987365  accuracy =  0.90625\n",
      "now loss =  0.10329977347992386  accuracy =  0.84375\n",
      "now loss =  0.09910863045377483  accuracy =  0.84375\n",
      "now loss =  0.11586593638118728  accuracy =  0.84375\n",
      "now loss =  0.104963674999827  accuracy =  0.828125\n",
      "now loss =  0.09439937209004753  accuracy =  0.890625\n",
      "now loss =  0.09219337512200174  accuracy =  0.875\n",
      "now loss =  0.09060043114683955  accuracy =  0.875\n",
      "now loss =  0.07357640723338432  accuracy =  0.90625\n",
      "now loss =  0.08798011883544796  accuracy =  0.890625\n",
      "now loss =  0.05687922462022931  accuracy =  0.953125\n",
      "now loss =  0.07400876550551037  accuracy =  0.9375\n",
      "now loss =  0.0830701939309463  accuracy =  0.875\n",
      "now loss =  0.06458379663573338  accuracy =  0.953125\n",
      "now loss =  0.08543341634764257  accuracy =  0.890625\n",
      "now loss =  0.0656165402979914  accuracy =  0.9\n",
      "now loss =  0.0948316585855753  accuracy =  0.875\n",
      "now loss =  0.08164718618353346  accuracy =  0.890625\n",
      "now loss =  0.09211398933461741  accuracy =  0.859375\n",
      "now loss =  0.107763397956667  accuracy =  0.859375\n",
      "now loss =  0.08638940602343231  accuracy =  0.859375\n",
      "now loss =  0.07909224256877279  accuracy =  0.875\n",
      "now loss =  0.07941538914823806  accuracy =  0.890625\n",
      "now loss =  0.06969760898449605  accuracy =  0.9375\n",
      "now loss =  0.08226227418806117  accuracy =  0.890625\n",
      "now loss =  0.06449148532097834  accuracy =  0.890625\n",
      "now loss =  0.09117721941018922  accuracy =  0.875\n",
      "now loss =  0.12140804895633583  accuracy =  0.8125\n",
      "now loss =  0.06707991541631256  accuracy =  0.953125\n",
      "now loss =  0.07009884963191877  accuracy =  0.90625\n",
      "now loss =  0.08187838045001686  accuracy =  0.921875\n",
      "now loss =  0.11028083351254277  accuracy =  0.8\n",
      "now loss =  0.10602830611801353  accuracy =  0.828125\n",
      "now loss =  0.08468006295789032  accuracy =  0.875\n",
      "now loss =  0.07147784823735029  accuracy =  0.90625\n",
      "now loss =  0.06157854028661861  accuracy =  0.921875\n",
      "now loss =  0.09475160378444292  accuracy =  0.859375\n",
      "now loss =  0.10324398751906026  accuracy =  0.84375\n",
      "now loss =  0.09279777985751719  accuracy =  0.859375\n",
      "now loss =  0.08842660067483805  accuracy =  0.890625\n",
      "now loss =  0.07368796791537405  accuracy =  0.921875\n",
      "now loss =  0.06756266107348136  accuracy =  0.921875\n",
      "now loss =  0.07866239647150608  accuracy =  0.890625\n",
      "now loss =  0.07929275122015923  accuracy =  0.90625\n",
      "now loss =  0.07632221257100497  accuracy =  0.921875\n",
      "now loss =  0.08235681133880046  accuracy =  0.875\n",
      "now loss =  0.1048372893005865  accuracy =  0.84375\n",
      "now loss =  0.13206890476597363  accuracy =  0.8\n",
      "now loss =  0.08526632767024266  accuracy =  0.90625\n",
      "now loss =  0.10335895203834924  accuracy =  0.859375\n",
      "now loss =  0.07027125366378865  accuracy =  0.90625\n",
      "now loss =  0.08557369874275311  accuracy =  0.84375\n",
      "now loss =  0.07185533514669715  accuracy =  0.90625\n",
      "now loss =  0.08922292895681083  accuracy =  0.859375\n",
      "now loss =  0.10130358558596884  accuracy =  0.890625\n",
      "now loss =  0.06442005507537603  accuracy =  0.9375\n",
      "now loss =  0.09185252569999203  accuracy =  0.859375\n",
      "now loss =  0.06405963615753846  accuracy =  0.9375\n",
      "now loss =  0.0986223519433415  accuracy =  0.84375\n",
      "now loss =  0.07642067957595197  accuracy =  0.90625\n",
      "now loss =  0.08042070632386375  accuracy =  0.90625\n",
      "now loss =  0.104216851837308  accuracy =  0.84375\n",
      "now loss =  0.09912921568453606  accuracy =  0.84375\n",
      "now loss =  0.08189128999565867  accuracy =  0.9\n",
      "now loss =  0.07222761256054132  accuracy =  0.9375\n",
      "now loss =  0.08126652344949933  accuracy =  0.859375\n",
      "now loss =  0.10025624296303334  accuracy =  0.796875\n",
      "now loss =  0.09056701026794794  accuracy =  0.890625\n",
      "now loss =  0.10835661476583362  accuracy =  0.8125\n",
      "now loss =  0.06513711090756594  accuracy =  0.90625\n",
      "now loss =  0.09215934515043217  accuracy =  0.859375\n",
      "now loss =  0.06955104550441416  accuracy =  0.921875\n",
      "now loss =  0.07029544097860671  accuracy =  0.90625\n",
      "now loss =  0.11648930318769565  accuracy =  0.828125\n",
      "now loss =  0.07072474352600766  accuracy =  0.9375\n",
      "now loss =  0.09865683882587513  accuracy =  0.859375\n",
      "now loss =  0.08180684060018122  accuracy =  0.90625\n",
      "now loss =  0.07789144445067725  accuracy =  0.921875\n",
      "now loss =  0.08845240843629672  accuracy =  0.90625\n",
      "now loss =  0.08407678430912172  accuracy =  0.9\n",
      "now loss =  0.1029463486500668  accuracy =  0.84375\n",
      "now loss =  0.09707388742163382  accuracy =  0.84375\n",
      "now loss =  0.08532299814186878  accuracy =  0.90625\n",
      "now loss =  0.06394409487548641  accuracy =  0.90625\n",
      "now loss =  0.07334843706400364  accuracy =  0.9375\n",
      "now loss =  0.09783363274701026  accuracy =  0.859375\n",
      "now loss =  0.05905514761857203  accuracy =  0.9375\n",
      "now loss =  0.11013405188597183  accuracy =  0.78125\n",
      "now loss =  0.09929021999183743  accuracy =  0.84375\n",
      "now loss =  0.07654974628945185  accuracy =  0.9375\n",
      "now loss =  0.10478182730142441  accuracy =  0.859375\n",
      "now loss =  0.06274543960813492  accuracy =  0.921875\n",
      "now loss =  0.072848728860197  accuracy =  0.90625\n",
      "now loss =  0.05557618478907733  accuracy =  0.953125\n",
      "now loss =  0.10305167966647891  accuracy =  0.84375\n",
      "now loss =  0.12775299076481392  accuracy =  0.8\n",
      "now loss =  0.11625870083130796  accuracy =  0.859375\n",
      "now loss =  0.08109139703631765  accuracy =  0.875\n",
      "now loss =  0.06198189694652773  accuracy =  0.96875\n",
      "now loss =  0.06968111138927165  accuracy =  0.9375\n",
      "now loss =  0.10137346438011004  accuracy =  0.84375\n",
      "now loss =  0.10532529649880276  accuracy =  0.828125\n",
      "now loss =  0.09736335955789341  accuracy =  0.875\n",
      "now loss =  0.07503447186424925  accuracy =  0.921875\n",
      "now loss =  0.08380859350180908  accuracy =  0.90625\n",
      "now loss =  0.07814045518711657  accuracy =  0.921875\n",
      "now loss =  0.09405241579511625  accuracy =  0.828125\n",
      "now loss =  0.1000223003845264  accuracy =  0.828125\n",
      "now loss =  0.09002296504308861  accuracy =  0.90625\n",
      "now loss =  0.06508005839433645  accuracy =  0.9375\n",
      "now loss =  0.06322591372880285  accuracy =  0.9375\n",
      "now loss =  0.08604138092214195  accuracy =  0.875\n",
      "now loss =  0.06560316539374571  accuracy =  0.953125\n",
      "now loss =  0.10480019112967667  accuracy =  0.828125\n",
      "now loss =  0.11181184538434705  accuracy =  0.8125\n",
      "now loss =  0.08776354441279002  accuracy =  0.890625\n",
      "now loss =  0.08164874021374798  accuracy =  0.890625\n",
      "now loss =  0.06889787755557672  accuracy =  0.921875\n",
      "now loss =  0.09448582037349251  accuracy =  0.828125\n",
      "now loss =  0.06679883494040605  accuracy =  0.9375\n",
      "now loss =  0.07799116531903967  accuracy =  0.90625\n",
      "now loss =  0.11784534938293448  accuracy =  0.796875\n",
      "now loss =  0.062343064698176784  accuracy =  0.921875\n",
      "now loss =  0.09860459224170467  accuracy =  0.875\n",
      "now loss =  0.07686222927060254  accuracy =  0.9375\n",
      "now loss =  0.08576567307130185  accuracy =  0.875\n",
      "now loss =  0.0731395667595659  accuracy =  0.953125\n",
      "now loss =  0.11020689654191104  accuracy =  0.825\n",
      "now loss =  0.08771124468995958  accuracy =  0.890625\n",
      "now loss =  0.06899676927965201  accuracy =  0.953125\n",
      "now loss =  0.09033795861096687  accuracy =  0.859375\n",
      "now loss =  0.07272715631776538  accuracy =  0.90625\n",
      "now loss =  0.08294247832777477  accuracy =  0.90625\n",
      "now loss =  0.08710660940388852  accuracy =  0.90625\n",
      "now loss =  0.06433901831934236  accuracy =  0.921875\n",
      "now loss =  0.10063028946925781  accuracy =  0.84375\n",
      "now loss =  0.07846782718665446  accuracy =  0.90625\n",
      "now loss =  0.11432105371640477  accuracy =  0.84375\n",
      "now loss =  0.05793040260296256  accuracy =  0.921875\n",
      "now loss =  0.08462543090156394  accuracy =  0.875\n",
      "now loss =  0.10943674906438228  accuracy =  0.78125\n",
      "now loss =  0.11657762543020109  accuracy =  0.796875\n",
      "now loss =  0.08244077801026808  accuracy =  0.921875\n",
      "now loss =  0.0639471002316913  accuracy =  0.95\n",
      "now loss =  0.07683652051845616  accuracy =  0.90625\n",
      "now loss =  0.07707662824549524  accuracy =  0.859375\n",
      "now loss =  0.08390200417426436  accuracy =  0.890625\n",
      "now loss =  0.12048193512347163  accuracy =  0.796875\n",
      "now loss =  0.0873354883760371  accuracy =  0.921875\n",
      "now loss =  0.08932456097736155  accuracy =  0.859375\n",
      "now loss =  0.08128471228734527  accuracy =  0.890625\n",
      "now loss =  0.09040908840242391  accuracy =  0.90625\n",
      "now loss =  0.07574893035720034  accuracy =  0.90625\n",
      "now loss =  0.07305408199977649  accuracy =  0.890625\n",
      "now loss =  0.05940178933414633  accuracy =  0.953125\n",
      "now loss =  0.09047131336048769  accuracy =  0.875\n",
      "now loss =  0.10016961256330367  accuracy =  0.84375\n",
      "now loss =  0.08360630612415978  accuracy =  0.921875\n",
      "now loss =  0.0866010189758948  accuracy =  0.890625\n",
      "now loss =  0.11025653747849022  accuracy =  0.875\n",
      "now loss =  0.1010803084387468  accuracy =  0.859375\n",
      "now loss =  0.11987265633749002  accuracy =  0.8125\n",
      "now loss =  0.06153923884303624  accuracy =  0.9375\n",
      "now loss =  0.08209314754499594  accuracy =  0.875\n",
      "now loss =  0.08115398354236772  accuracy =  0.890625\n",
      "now loss =  0.07984266445278945  accuracy =  0.921875\n",
      "now loss =  0.07917807342864241  accuracy =  0.875\n",
      "now loss =  0.07549621303173419  accuracy =  0.90625\n",
      "now loss =  0.08517381075932981  accuracy =  0.859375\n",
      "now loss =  0.1095213757388429  accuracy =  0.828125\n",
      "now loss =  0.09497877262740731  accuracy =  0.859375\n",
      "now loss =  0.0849054765868366  accuracy =  0.890625\n",
      "now loss =  0.08427818531105957  accuracy =  0.90625\n",
      "now loss =  0.064956117319417  accuracy =  0.921875\n",
      "now loss =  0.07472428352297703  accuracy =  0.890625\n",
      "now loss =  0.1068453695312425  accuracy =  0.875\n",
      "now loss =  0.0800396412162731  accuracy =  0.890625\n",
      "now loss =  0.059013434370647336  accuracy =  0.953125\n",
      "now loss =  0.08070537519237889  accuracy =  0.90625\n",
      "now loss =  0.0835679436900183  accuracy =  0.890625\n",
      "now loss =  0.09397658519797869  accuracy =  0.828125\n",
      "now loss =  0.08839015957324803  accuracy =  0.890625\n",
      "now loss =  0.11389155577325695  accuracy =  0.84375\n",
      "now loss =  0.06934560834266498  accuracy =  0.875\n",
      "now loss =  0.09054097524666815  accuracy =  0.875\n",
      "now loss =  0.09893938112783401  accuracy =  0.859375\n",
      "now loss =  0.1030112700289465  accuracy =  0.828125\n",
      "now loss =  0.07031392543253653  accuracy =  0.9375\n",
      "now loss =  0.08271468996514472  accuracy =  0.921875\n",
      "now loss =  0.06987037166846093  accuracy =  0.90625\n",
      "now loss =  0.11027624892116775  accuracy =  0.84375\n",
      "now loss =  0.07267670792886463  accuracy =  0.875\n",
      "now loss =  0.11616707304056786  accuracy =  0.859375\n",
      "now loss =  0.08884315702743534  accuracy =  0.859375\n",
      "now loss =  0.11674854254843961  accuracy =  0.84375\n",
      "now loss =  0.05885266463166119  accuracy =  0.953125\n",
      "now loss =  0.07883157248621142  accuracy =  0.890625\n",
      "now loss =  0.08249447740408557  accuracy =  0.90625\n",
      "now loss =  0.10355377259290327  accuracy =  0.859375\n",
      "now loss =  0.06461418221925548  accuracy =  0.90625\n",
      "now loss =  0.12275086583636143  accuracy =  0.84375\n",
      "now loss =  0.06605896222826352  accuracy =  0.921875\n",
      "now loss =  0.09855062969107012  accuracy =  0.84375\n",
      "now loss =  0.08089401016525175  accuracy =  0.875\n",
      "now loss =  0.077164859440658  accuracy =  0.90625\n",
      "now loss =  0.06316142394131333  accuracy =  0.890625\n",
      "now loss =  0.09508249212220636  accuracy =  0.859375\n",
      "now loss =  0.0445479522323874  accuracy =  0.95\n",
      "now loss =  0.0835490519103549  accuracy =  0.890625\n",
      "now loss =  0.06723055290972033  accuracy =  0.9375\n",
      "now loss =  0.07523422148296782  accuracy =  0.90625\n",
      "now loss =  0.07953077952947168  accuracy =  0.90625\n",
      "now loss =  0.07341934950340515  accuracy =  0.90625\n",
      "now loss =  0.0849555298728858  accuracy =  0.875\n",
      "now loss =  0.07112783999843689  accuracy =  0.9375\n",
      "now loss =  0.11340065328525167  accuracy =  0.828125\n",
      "now loss =  0.06401920258378424  accuracy =  0.890625\n",
      "now loss =  0.08901936016303327  accuracy =  0.875\n",
      "now loss =  0.10367431302190809  accuracy =  0.84375\n",
      "now loss =  0.08933899981835236  accuracy =  0.859375\n",
      "now loss =  0.11833323581226965  accuracy =  0.8125\n",
      "now loss =  0.09193588973661959  accuracy =  0.859375\n",
      "now loss =  0.08167755261624299  accuracy =  0.90625\n",
      "now loss =  0.08145134382320209  accuracy =  0.875\n",
      "now loss =  0.08024004518657446  accuracy =  0.921875\n",
      "now loss =  0.0956203439870636  accuracy =  0.859375\n",
      "now loss =  0.10360959400216903  accuracy =  0.859375\n",
      "now loss =  0.07135973965927733  accuracy =  0.90625\n",
      "now loss =  0.06492521983577554  accuracy =  0.921875\n",
      "now loss =  0.08823413683545066  accuracy =  0.875\n",
      "now loss =  0.08439594500659792  accuracy =  0.875\n",
      "now loss =  0.08797673105324685  accuracy =  0.875\n",
      "now loss =  0.061017706142936994  accuracy =  0.90625\n",
      "now loss =  0.09703074553722772  accuracy =  0.875\n",
      "now loss =  0.07750923413325092  accuracy =  0.890625\n",
      "now loss =  0.07092717251832806  accuracy =  0.90625\n",
      "now loss =  0.13011646837113977  accuracy =  0.796875\n",
      "now loss =  0.07930930017654528  accuracy =  0.875\n",
      "now loss =  0.07541001298736426  accuracy =  0.890625\n",
      "now loss =  0.10615275118337938  accuracy =  0.825\n",
      "now loss =  0.09525132508780859  accuracy =  0.859375\n",
      "now loss =  0.07506314951524157  accuracy =  0.90625\n",
      "now loss =  0.059238033988194036  accuracy =  0.890625\n",
      "now loss =  0.08391722512657127  accuracy =  0.875\n",
      "now loss =  0.0724199290632029  accuracy =  0.890625\n",
      "now loss =  0.07950992240591082  accuracy =  0.921875\n",
      "now loss =  0.06164124326352084  accuracy =  0.9375\n",
      "now loss =  0.08116652822290152  accuracy =  0.890625\n",
      "now loss =  0.102301833276918  accuracy =  0.859375\n",
      "now loss =  0.0883939890295567  accuracy =  0.921875\n",
      "now loss =  0.11923759215862792  accuracy =  0.84375\n",
      "now loss =  0.11555232317405897  accuracy =  0.828125\n",
      "now loss =  0.07221221465698038  accuracy =  0.921875\n",
      "now loss =  0.09457107637441181  accuracy =  0.859375\n",
      "now loss =  0.0757085397612909  accuracy =  0.875\n",
      "now loss =  0.10426454495770292  accuracy =  0.875\n",
      "now loss =  0.10818454210620852  accuracy =  0.8125\n",
      "now loss =  0.06980548894886657  accuracy =  0.921875\n",
      "now loss =  0.10768336082763232  accuracy =  0.8125\n",
      "now loss =  0.06909924905394979  accuracy =  0.890625\n",
      "now loss =  0.08196860483835948  accuracy =  0.90625\n",
      "now loss =  0.08159839959396178  accuracy =  0.890625\n",
      "now loss =  0.1164902797210184  accuracy =  0.8125\n",
      "now loss =  0.07657342012235967  accuracy =  0.9375\n",
      "now loss =  0.07538024394310294  accuracy =  0.90625\n",
      "now loss =  0.08686790444266991  accuracy =  0.90625\n",
      "now loss =  0.09309833026227127  accuracy =  0.875\n",
      "now loss =  0.08575974265191091  accuracy =  0.875\n",
      "now loss =  0.06324603028129162  accuracy =  0.953125\n",
      "now loss =  0.06633551335163033  accuracy =  0.9375\n",
      "now loss =  0.12324965254746997  accuracy =  0.828125\n",
      "now loss =  0.06623392238218273  accuracy =  0.95\n",
      "now loss =  0.04886566656327361  accuracy =  0.953125\n",
      "now loss =  0.09807658293156825  accuracy =  0.84375\n",
      "now loss =  0.09220859059323613  accuracy =  0.875\n",
      "now loss =  0.07191396233921343  accuracy =  0.90625\n",
      "now loss =  0.10107686703013438  accuracy =  0.875\n",
      "now loss =  0.08298615069490314  accuracy =  0.875\n",
      "now loss =  0.08726966120100801  accuracy =  0.921875\n",
      "now loss =  0.07576806268381933  accuracy =  0.890625\n",
      "now loss =  0.10825137296932427  accuracy =  0.84375\n",
      "now loss =  0.08235862560706991  accuracy =  0.875\n",
      "now loss =  0.07317834785729879  accuracy =  0.90625\n",
      "now loss =  0.08310171365203922  accuracy =  0.9375\n",
      "now loss =  0.0778128717884338  accuracy =  0.875\n",
      "now loss =  0.09695811645727229  accuracy =  0.84375\n",
      "now loss =  0.08585415305858624  accuracy =  0.90625\n",
      "now loss =  0.12957452624708762  accuracy =  0.775\n",
      "now loss =  0.11170339194660775  accuracy =  0.828125\n",
      "now loss =  0.0957274304256712  accuracy =  0.859375\n",
      "now loss =  0.07994242022141633  accuracy =  0.890625\n",
      "now loss =  0.0865886818295727  accuracy =  0.875\n",
      "now loss =  0.0965840268497526  accuracy =  0.890625\n",
      "now loss =  0.06728538828407393  accuracy =  0.921875\n",
      "now loss =  0.06744279076928911  accuracy =  0.90625\n",
      "now loss =  0.07991237217823152  accuracy =  0.890625\n",
      "now loss =  0.08708607351662553  accuracy =  0.859375\n",
      "now loss =  0.10088104219349443  accuracy =  0.875\n",
      "now loss =  0.08596121471487583  accuracy =  0.859375\n",
      "now loss =  0.08881320329900812  accuracy =  0.875\n",
      "now loss =  0.07242647438018185  accuracy =  0.921875\n",
      "now loss =  0.09047490729738963  accuracy =  0.859375\n",
      "now loss =  0.0696255673635755  accuracy =  0.953125\n",
      "now loss =  0.09581935920022815  accuracy =  0.825\n",
      "now loss =  0.07509389223446428  accuracy =  0.875\n",
      "now loss =  0.08197603050231783  accuracy =  0.875\n",
      "now loss =  0.09084190169249415  accuracy =  0.859375\n",
      "now loss =  0.11965135939626995  accuracy =  0.828125\n",
      "now loss =  0.08884720943047655  accuracy =  0.890625\n",
      "now loss =  0.09465506747749591  accuracy =  0.828125\n",
      "now loss =  0.12216778370497199  accuracy =  0.8125\n",
      "now loss =  0.09316443980118452  accuracy =  0.875\n",
      "now loss =  0.06786822595473102  accuracy =  0.9375\n",
      "now loss =  0.06091673655833955  accuracy =  0.921875\n",
      "now loss =  0.08095351385200542  accuracy =  0.890625\n",
      "now loss =  0.08668250041487124  accuracy =  0.890625\n",
      "now loss =  0.06686962459831203  accuracy =  0.9375\n",
      "now loss =  0.09084620212760591  accuracy =  0.90625\n",
      "now loss =  0.07477568672174913  accuracy =  0.9375\n",
      "now loss =  0.07623308192227145  accuracy =  0.9\n",
      "now loss =  0.07365471209226944  accuracy =  0.921875\n",
      "now loss =  0.07630179187063303  accuracy =  0.890625\n",
      "now loss =  0.08970883785274944  accuracy =  0.890625\n",
      "now loss =  0.08961586814111405  accuracy =  0.859375\n",
      "now loss =  0.10673941958603236  accuracy =  0.84375\n",
      "now loss =  0.09727052115320234  accuracy =  0.828125\n",
      "now loss =  0.057745311228495744  accuracy =  0.96875\n",
      "now loss =  0.09549439662692251  accuracy =  0.84375\n",
      "now loss =  0.06876333352185314  accuracy =  0.921875\n",
      "now loss =  0.0992721772995224  accuracy =  0.84375\n",
      "now loss =  0.08825359259845801  accuracy =  0.875\n",
      "now loss =  0.1032816751862875  accuracy =  0.84375\n",
      "now loss =  0.0708939910184353  accuracy =  0.9375\n",
      "now loss =  0.07812492082101372  accuracy =  0.90625\n",
      "now loss =  0.09092648615070371  accuracy =  0.890625\n",
      "now loss =  0.09029005094890609  accuracy =  0.825\n",
      "now loss =  0.07446178526376429  accuracy =  0.90625\n",
      "now loss =  0.08300306265410468  accuracy =  0.921875\n",
      "now loss =  0.06535256796590054  accuracy =  0.890625\n",
      "now loss =  0.10029167209310899  accuracy =  0.859375\n",
      "now loss =  0.10446619543277566  accuracy =  0.8125\n",
      "now loss =  0.0827065387908571  accuracy =  0.90625\n",
      "now loss =  0.06289909689035528  accuracy =  0.953125\n",
      "now loss =  0.09136874185627451  accuracy =  0.875\n",
      "now loss =  0.10415186875643972  accuracy =  0.8125\n",
      "now loss =  0.07728911501703299  accuracy =  0.9375\n",
      "now loss =  0.10553650931455796  accuracy =  0.84375\n",
      "now loss =  0.07843058875909514  accuracy =  0.9375\n",
      "now loss =  0.08722290735868041  accuracy =  0.890625\n",
      "now loss =  0.08651010728999248  accuracy =  0.890625\n",
      "now loss =  0.0679691680868594  accuracy =  0.90625\n",
      "now loss =  0.103665983771811  accuracy =  0.85\n",
      "now loss =  0.0729414422067569  accuracy =  0.921875\n",
      "now loss =  0.09597981657428581  accuracy =  0.859375\n",
      "now loss =  0.08788858528880181  accuracy =  0.90625\n",
      "now loss =  0.09498492018477209  accuracy =  0.875\n",
      "now loss =  0.1054314016808933  accuracy =  0.84375\n",
      "now loss =  0.04966839062923544  accuracy =  0.953125\n",
      "now loss =  0.10868703812595157  accuracy =  0.828125\n",
      "now loss =  0.06704499780322326  accuracy =  0.953125\n",
      "now loss =  0.072302308335168  accuracy =  0.890625\n",
      "now loss =  0.0662351290918544  accuracy =  0.921875\n",
      "now loss =  0.08578258032051288  accuracy =  0.875\n",
      "now loss =  0.07934407628579493  accuracy =  0.90625\n",
      "now loss =  0.08656063768289399  accuracy =  0.875\n",
      "now loss =  0.1027433904258789  accuracy =  0.875\n",
      "now loss =  0.07956733693900271  accuracy =  0.90625\n",
      "now loss =  0.13851116862082846  accuracy =  0.775\n",
      "now loss =  0.10644003319215703  accuracy =  0.78125\n",
      "now loss =  0.08673602170212552  accuracy =  0.875\n",
      "now loss =  0.09257248167059551  accuracy =  0.890625\n",
      "now loss =  0.0884624970930506  accuracy =  0.875\n",
      "now loss =  0.06522667650648362  accuracy =  0.9375\n",
      "now loss =  0.10118071838755768  accuracy =  0.859375\n",
      "now loss =  0.08886836889313943  accuracy =  0.875\n",
      "now loss =  0.0761672953355436  accuracy =  0.890625\n",
      "now loss =  0.0696753001072673  accuracy =  0.921875\n",
      "now loss =  0.07717760575724164  accuracy =  0.9375\n",
      "now loss =  0.10615247277679737  accuracy =  0.875\n",
      "now loss =  0.07823526513460038  accuracy =  0.890625\n",
      "now loss =  0.10017538297164225  accuracy =  0.84375\n",
      "now loss =  0.09471064199336153  accuracy =  0.84375\n",
      "now loss =  0.07358938877076893  accuracy =  0.890625\n",
      "now loss =  0.0596542162655346  accuracy =  0.95\n",
      "now loss =  0.07546737068127826  accuracy =  0.921875\n",
      "now loss =  0.08298240535201706  accuracy =  0.890625\n",
      "now loss =  0.049857988311419923  accuracy =  0.953125\n",
      "now loss =  0.09491878369217573  accuracy =  0.890625\n",
      "now loss =  0.08119955985477684  accuracy =  0.875\n",
      "now loss =  0.06938976891980762  accuracy =  0.9375\n",
      "now loss =  0.0892306805249849  accuracy =  0.890625\n",
      "now loss =  0.10376627324147036  accuracy =  0.828125\n",
      "now loss =  0.08255374837803238  accuracy =  0.890625\n",
      "now loss =  0.07831179585936449  accuracy =  0.828125\n",
      "now loss =  0.12459862795728122  accuracy =  0.828125\n",
      "now loss =  0.08609189155818861  accuracy =  0.875\n",
      "now loss =  0.08249592427368345  accuracy =  0.890625\n",
      "now loss =  0.08220495964027147  accuracy =  0.921875\n",
      "now loss =  0.0989317398406595  accuracy =  0.859375\n",
      "now loss =  0.09934852145459779  accuracy =  0.85\n",
      "now loss =  0.10513858299840492  accuracy =  0.84375\n",
      "now loss =  0.07581322031955309  accuracy =  0.90625\n",
      "now loss =  0.11838428843277651  accuracy =  0.8125\n",
      "now loss =  0.07249997959066608  accuracy =  0.921875\n",
      "now loss =  0.1147650104315462  accuracy =  0.8125\n",
      "now loss =  0.05052461102533437  accuracy =  0.953125\n",
      "now loss =  0.09362075487402959  accuracy =  0.84375\n",
      "now loss =  0.058971727730179266  accuracy =  0.953125\n",
      "now loss =  0.0866785475705997  accuracy =  0.890625\n",
      "now loss =  0.08907704596078564  accuracy =  0.90625\n",
      "now loss =  0.0874055913422428  accuracy =  0.90625\n",
      "now loss =  0.06782563524614274  accuracy =  0.953125\n",
      "now loss =  0.09435352390225607  accuracy =  0.875\n",
      "now loss =  0.07633438770081805  accuracy =  0.875\n",
      "now loss =  0.1068416169383478  accuracy =  0.828125\n",
      "now loss =  0.07417550777565315  accuracy =  0.875\n",
      "now loss =  0.08645186715153301  accuracy =  0.875\n",
      "now loss =  0.0924557296568282  accuracy =  0.875\n",
      "now loss =  0.07609324684224364  accuracy =  0.921875\n",
      "now loss =  0.059681143698275416  accuracy =  0.953125\n",
      "now loss =  0.06704952903892239  accuracy =  0.953125\n",
      "now loss =  0.07446196589669224  accuracy =  0.90625\n",
      "now loss =  0.09360154195277667  accuracy =  0.859375\n",
      "now loss =  0.10753144764495037  accuracy =  0.828125\n",
      "now loss =  0.08159214809985318  accuracy =  0.890625\n",
      "now loss =  0.08820835383649323  accuracy =  0.90625\n",
      "now loss =  0.07928688578469736  accuracy =  0.890625\n",
      "now loss =  0.08957132694148104  accuracy =  0.90625\n",
      "now loss =  0.10861550877396131  accuracy =  0.828125\n",
      "now loss =  0.07034428596904918  accuracy =  0.890625\n",
      "now loss =  0.10545671811360591  accuracy =  0.84375\n",
      "now loss =  0.09025958966577077  accuracy =  0.875\n",
      "now loss =  0.07760103937043625  accuracy =  0.921875\n",
      "now loss =  0.09171292358038147  accuracy =  0.875\n",
      "now loss =  0.11655175733264586  accuracy =  0.796875\n",
      "now loss =  0.09323297256085673  accuracy =  0.875\n",
      "now loss =  0.07195602691874789  accuracy =  0.921875\n",
      "now loss =  0.09073517746668877  accuracy =  0.84375\n",
      "now loss =  0.08914496016123234  accuracy =  0.890625\n",
      "now loss =  0.10396065140740474  accuracy =  0.859375\n",
      "now loss =  0.09604627370281935  accuracy =  0.859375\n",
      "now loss =  0.08943365504088523  accuracy =  0.875\n",
      "now loss =  0.061932534127908404  accuracy =  0.9375\n",
      "now loss =  0.0676906752907274  accuracy =  0.90625\n",
      "now loss =  0.07327454313717432  accuracy =  0.890625\n",
      "now loss =  0.08631713021806162  accuracy =  0.890625\n",
      "now loss =  0.10276099826816226  accuracy =  0.890625\n",
      "now loss =  0.04976093583241538  accuracy =  0.95\n",
      "now loss =  0.10317790528977108  accuracy =  0.828125\n",
      "now loss =  0.08427742548156489  accuracy =  0.90625\n",
      "now loss =  0.10475876275613497  accuracy =  0.84375\n",
      "now loss =  0.07920004648833126  accuracy =  0.90625\n",
      "now loss =  0.06419304490321312  accuracy =  0.9375\n",
      "now loss =  0.08064123213523205  accuracy =  0.90625\n",
      "now loss =  0.07783252576628105  accuracy =  0.875\n",
      "now loss =  0.09039868665647366  accuracy =  0.84375\n",
      "now loss =  0.07407853112615737  accuracy =  0.9375\n",
      "now loss =  0.09938140523032749  accuracy =  0.859375\n",
      "now loss =  0.07724229429011475  accuracy =  0.90625\n",
      "now loss =  0.09341459999770428  accuracy =  0.84375\n",
      "now loss =  0.07294524027003438  accuracy =  0.90625\n",
      "now loss =  0.08867423901092655  accuracy =  0.875\n",
      "now loss =  0.09405823021858423  accuracy =  0.90625\n",
      "now loss =  0.08932751769743687  accuracy =  0.875\n",
      "now loss =  0.08518437380214941  accuracy =  0.84375\n",
      "now loss =  0.10100576633948773  accuracy =  0.875\n",
      "now loss =  0.08806222113278403  accuracy =  0.875\n",
      "now loss =  0.09359013220916335  accuracy =  0.875\n",
      "now loss =  0.08319508196063854  accuracy =  0.90625\n",
      "now loss =  0.1269478784284815  accuracy =  0.796875\n",
      "now loss =  0.06453593466262045  accuracy =  0.9375\n",
      "now loss =  0.08954441075666983  accuracy =  0.890625\n",
      "now loss =  0.07583459861510083  accuracy =  0.921875\n",
      "now loss =  0.10704629695982976  accuracy =  0.828125\n",
      "now loss =  0.08576751864183035  accuracy =  0.875\n",
      "now loss =  0.07746136503973583  accuracy =  0.890625\n",
      "now loss =  0.06252965502807824  accuracy =  0.921875\n",
      "now loss =  0.07853212475466848  accuracy =  0.90625\n",
      "now loss =  0.0889502797845799  accuracy =  0.875\n",
      "now loss =  0.059217510397814574  accuracy =  0.925\n",
      "now loss =  0.09759660988084738  accuracy =  0.859375\n",
      "now loss =  0.08334344042235414  accuracy =  0.90625\n",
      "now loss =  0.0838870001853735  accuracy =  0.90625\n",
      "now loss =  0.05755232068064729  accuracy =  0.953125\n",
      "now loss =  0.08536741226072295  accuracy =  0.890625\n",
      "now loss =  0.0745778922818647  accuracy =  0.921875\n",
      "now loss =  0.0818327261452282  accuracy =  0.890625\n",
      "now loss =  0.08421092364779799  accuracy =  0.859375\n",
      "now loss =  0.09553540842270535  accuracy =  0.828125\n",
      "now loss =  0.060953404433909474  accuracy =  0.96875\n",
      "now loss =  0.09838797039630941  accuracy =  0.84375\n",
      "now loss =  0.08550240168344823  accuracy =  0.859375\n",
      "now loss =  0.11706492457690106  accuracy =  0.828125\n",
      "now loss =  0.07639726072683173  accuracy =  0.890625\n",
      "now loss =  0.09490460046317495  accuracy =  0.875\n",
      "now loss =  0.10367944779552216  accuracy =  0.85\n",
      "now loss =  0.07094481560831069  accuracy =  0.9375\n",
      "now loss =  0.13397607121233096  accuracy =  0.78125\n",
      "now loss =  0.09930887646451572  accuracy =  0.84375\n",
      "now loss =  0.08529246487212945  accuracy =  0.859375\n",
      "now loss =  0.1204801554967145  accuracy =  0.796875\n",
      "now loss =  0.11277351040905999  accuracy =  0.828125\n",
      "now loss =  0.1123788452186883  accuracy =  0.859375\n",
      "now loss =  0.06588626869390232  accuracy =  0.9375\n",
      "now loss =  0.0781011502552732  accuracy =  0.875\n",
      "now loss =  0.06815720134807658  accuracy =  0.90625\n",
      "now loss =  0.06012689328079158  accuracy =  0.953125\n",
      "now loss =  0.07188088207834319  accuracy =  0.921875\n",
      "now loss =  0.06887497885547957  accuracy =  0.953125\n",
      "now loss =  0.07326381475571925  accuracy =  0.921875\n",
      "now loss =  0.08137822380119823  accuracy =  0.90625\n",
      "now loss =  0.05206977749725167  accuracy =  0.925\n",
      "now loss =  0.112006422637459  accuracy =  0.828125\n",
      "now loss =  0.052522620126435285  accuracy =  0.953125\n",
      "now loss =  0.10653484535847844  accuracy =  0.84375\n",
      "now loss =  0.08106948563454244  accuracy =  0.9375\n",
      "now loss =  0.0819900657436081  accuracy =  0.890625\n",
      "now loss =  0.08161688649523191  accuracy =  0.890625\n",
      "now loss =  0.07178904830802366  accuracy =  0.921875\n",
      "now loss =  0.09301609003886144  accuracy =  0.859375\n",
      "now loss =  0.10847874585448204  accuracy =  0.796875\n",
      "now loss =  0.0701439450217818  accuracy =  0.921875\n",
      "now loss =  0.09269207690288811  accuracy =  0.875\n",
      "now loss =  0.08568951515128706  accuracy =  0.875\n",
      "now loss =  0.10091912333897862  accuracy =  0.84375\n",
      "now loss =  0.07724820857089365  accuracy =  0.90625\n",
      "now loss =  0.06153815662383946  accuracy =  0.9375\n",
      "now loss =  0.11861405332551991  accuracy =  0.75\n",
      "now loss =  0.07676109666092087  accuracy =  0.90625\n",
      "now loss =  0.09840873552794689  accuracy =  0.890625\n",
      "now loss =  0.11489000317943078  accuracy =  0.859375\n",
      "now loss =  0.07638093169653673  accuracy =  0.90625\n",
      "now loss =  0.06746485844923239  accuracy =  0.9375\n",
      "now loss =  0.11305109763979053  accuracy =  0.84375\n",
      "now loss =  0.06116120582058104  accuracy =  0.953125\n",
      "now loss =  0.07830611239535742  accuracy =  0.90625\n",
      "now loss =  0.12555214482613783  accuracy =  0.796875\n",
      "now loss =  0.09487900536100187  accuracy =  0.859375\n",
      "now loss =  0.0802315761151984  accuracy =  0.875\n",
      "now loss =  0.08345072883401508  accuracy =  0.859375\n",
      "now loss =  0.07933514444672077  accuracy =  0.875\n",
      "now loss =  0.06609811685009188  accuracy =  0.890625\n",
      "now loss =  0.06849982228720214  accuracy =  0.890625\n",
      "now loss =  0.0892621012496114  accuracy =  0.825\n",
      "now loss =  0.10301170124278122  accuracy =  0.890625\n",
      "now loss =  0.083295470994068  accuracy =  0.890625\n",
      "now loss =  0.08203614800280778  accuracy =  0.859375\n",
      "now loss =  0.09522992084316578  accuracy =  0.859375\n",
      "now loss =  0.1187509730583172  accuracy =  0.828125\n",
      "now loss =  0.08128365349190732  accuracy =  0.890625\n",
      "now loss =  0.09817784440664816  accuracy =  0.859375\n",
      "now loss =  0.09443462854157121  accuracy =  0.859375\n",
      "now loss =  0.06686997817492338  accuracy =  0.90625\n",
      "now loss =  0.08661744954825831  accuracy =  0.890625\n",
      "now loss =  0.06848201371473799  accuracy =  0.9375\n",
      "now loss =  0.10229834805495716  accuracy =  0.859375\n",
      "now loss =  0.07021831353649167  accuracy =  0.90625\n",
      "now loss =  0.08334268247014028  accuracy =  0.890625\n",
      "now loss =  0.047038456167689494  accuracy =  0.953125\n",
      "now loss =  0.10707494988303586  accuracy =  0.85\n",
      "now loss =  0.08070741342426434  accuracy =  0.890625\n",
      "now loss =  0.07872479877783843  accuracy =  0.890625\n",
      "now loss =  0.08521440140364525  accuracy =  0.859375\n",
      "now loss =  0.0864070671803186  accuracy =  0.90625\n",
      "now loss =  0.07707859033517186  accuracy =  0.90625\n",
      "now loss =  0.06622145327969654  accuracy =  0.9375\n",
      "now loss =  0.09764998322495526  accuracy =  0.84375\n",
      "now loss =  0.08619574554743184  accuracy =  0.921875\n",
      "now loss =  0.07914873971309783  accuracy =  0.90625\n",
      "now loss =  0.086953314689368  accuracy =  0.859375\n",
      "now loss =  0.07606910141377397  accuracy =  0.90625\n",
      "now loss =  0.10614731626298579  accuracy =  0.8125\n",
      "now loss =  0.06311550648155796  accuracy =  0.921875\n",
      "now loss =  0.10719868506997599  accuracy =  0.859375\n",
      "now loss =  0.09426871522344756  accuracy =  0.875\n",
      "now loss =  0.10981777784213136  accuracy =  0.8\n",
      "now loss =  0.09397931581877977  accuracy =  0.859375\n",
      "now loss =  0.06874252220551083  accuracy =  0.890625\n",
      "now loss =  0.0846726517615058  accuracy =  0.90625\n",
      "now loss =  0.11555520638849334  accuracy =  0.8125\n",
      "now loss =  0.06734882003944828  accuracy =  0.921875\n",
      "now loss =  0.09232206504130472  accuracy =  0.859375\n",
      "now loss =  0.13329161033972636  accuracy =  0.8125\n",
      "now loss =  0.08161003469500357  accuracy =  0.921875\n",
      "now loss =  0.08844236279558157  accuracy =  0.859375\n",
      "now loss =  0.07258724190081559  accuracy =  0.890625\n",
      "now loss =  0.07241721384014116  accuracy =  0.921875\n",
      "now loss =  0.0760287393925938  accuracy =  0.90625\n",
      "now loss =  0.0933262397566955  accuracy =  0.890625\n",
      "now loss =  0.08148713316956573  accuracy =  0.890625\n",
      "now loss =  0.078682577342716  accuracy =  0.921875\n",
      "now loss =  0.06601622714941544  accuracy =  0.95\n",
      "now loss =  0.08432781755143068  accuracy =  0.890625\n",
      "now loss =  0.08921508347580225  accuracy =  0.828125\n",
      "now loss =  0.09406267429152682  accuracy =  0.859375\n",
      "now loss =  0.09967391329170529  accuracy =  0.859375\n",
      "now loss =  0.06794246689221031  accuracy =  0.921875\n",
      "now loss =  0.11527362643210054  accuracy =  0.828125\n",
      "now loss =  0.12392405184074647  accuracy =  0.78125\n",
      "now loss =  0.06565287605813483  accuracy =  0.9375\n",
      "now loss =  0.08192203232348882  accuracy =  0.875\n",
      "now loss =  0.08042652606175009  accuracy =  0.921875\n",
      "now loss =  0.10394987187547368  accuracy =  0.890625\n",
      "now loss =  0.07819634274898335  accuracy =  0.921875\n",
      "now loss =  0.07525994469011307  accuracy =  0.921875\n",
      "now loss =  0.06374675143579336  accuracy =  0.953125\n",
      "now loss =  0.060085753539447326  accuracy =  0.921875\n",
      "now loss =  0.08564801766126676  accuracy =  0.85\n",
      "now loss =  0.08428632586133192  accuracy =  0.90625\n",
      "now loss =  0.08946325625265733  accuracy =  0.890625\n",
      "now loss =  0.0721414991168853  accuracy =  0.90625\n",
      "now loss =  0.08178149814781632  accuracy =  0.90625\n",
      "now loss =  0.10757491376922597  accuracy =  0.875\n",
      "now loss =  0.0682768448609035  accuracy =  0.9375\n",
      "now loss =  0.10941608758564877  accuracy =  0.8125\n",
      "now loss =  0.07544118626894697  accuracy =  0.921875\n",
      "now loss =  0.10810801339650532  accuracy =  0.8125\n",
      "now loss =  0.09698126369484311  accuracy =  0.84375\n",
      "now loss =  0.0911183433317811  accuracy =  0.859375\n",
      "now loss =  0.09219102635433582  accuracy =  0.84375\n",
      "now loss =  0.0721050418035052  accuracy =  0.890625\n",
      "now loss =  0.07876717076921355  accuracy =  0.921875\n",
      "now loss =  0.07272207828792726  accuracy =  0.921875\n",
      "now loss =  0.06377521996923666  accuracy =  0.9\n",
      "now loss =  0.08969924869319038  accuracy =  0.875\n",
      "now loss =  0.08757479818567182  accuracy =  0.875\n",
      "now loss =  0.0862221117180646  accuracy =  0.90625\n",
      "now loss =  0.0911026050531333  accuracy =  0.859375\n",
      "now loss =  0.07931321893570367  accuracy =  0.890625\n",
      "now loss =  0.09494895463145331  accuracy =  0.890625\n",
      "now loss =  0.0703170095748171  accuracy =  0.9375\n",
      "now loss =  0.10768205942764736  accuracy =  0.828125\n",
      "now loss =  0.08803205126316638  accuracy =  0.890625\n",
      "now loss =  0.07688053260809047  accuracy =  0.90625\n",
      "now loss =  0.11258436190475167  accuracy =  0.84375\n",
      "now loss =  0.08531357916765675  accuracy =  0.875\n",
      "now loss =  0.07098200878461922  accuracy =  0.90625\n",
      "now loss =  0.08802448530385312  accuracy =  0.90625\n",
      "now loss =  0.06917129542364814  accuracy =  0.90625\n",
      "now loss =  0.08391275288839642  accuracy =  0.85\n",
      "now loss =  0.07327690573968482  accuracy =  0.921875\n",
      "now loss =  0.0835105661213533  accuracy =  0.90625\n",
      "now loss =  0.09595404779251622  accuracy =  0.859375\n",
      "now loss =  0.09686529659175075  accuracy =  0.859375\n",
      "now loss =  0.1216282138497577  accuracy =  0.84375\n",
      "now loss =  0.07299816257139534  accuracy =  0.90625\n",
      "now loss =  0.06790768944459598  accuracy =  0.9375\n",
      "now loss =  0.07389946108099402  accuracy =  0.90625\n",
      "now loss =  0.0715770186279794  accuracy =  0.921875\n",
      "now loss =  0.06924106330324589  accuracy =  0.90625\n",
      "now loss =  0.09610760956781048  accuracy =  0.859375\n",
      "now loss =  0.07399085911073233  accuracy =  0.90625\n",
      "now loss =  0.09021073925642828  accuracy =  0.875\n",
      "now loss =  0.09676420297290678  accuracy =  0.828125\n",
      "now loss =  0.09901886194400736  accuracy =  0.859375\n",
      "now loss =  0.08775114540888365  accuracy =  0.875\n",
      "now loss =  0.08666380981337407  accuracy =  0.875\n",
      "now loss =  0.10896788102118439  accuracy =  0.8125\n",
      "now loss =  0.11491542293555808  accuracy =  0.828125\n",
      "now loss =  0.09608941162136955  accuracy =  0.890625\n",
      "now loss =  0.0826666785733102  accuracy =  0.890625\n",
      "now loss =  0.08756523796994947  accuracy =  0.90625\n",
      "now loss =  0.0629254491754426  accuracy =  0.921875\n",
      "now loss =  0.07458761731249328  accuracy =  0.9375\n",
      "now loss =  0.08610186444600303  accuracy =  0.875\n",
      "now loss =  0.10370017203351437  accuracy =  0.84375\n",
      "now loss =  0.07551086550361893  accuracy =  0.90625\n",
      "now loss =  0.08564248151527014  accuracy =  0.890625\n",
      "now loss =  0.09484703856876017  accuracy =  0.875\n",
      "now loss =  0.0872040380480222  accuracy =  0.84375\n",
      "now loss =  0.08206953681954592  accuracy =  0.875\n",
      "now loss =  0.040518073951016705  accuracy =  1.0\n",
      "now loss =  0.07487581966834417  accuracy =  0.90625\n",
      "now loss =  0.09832326925692053  accuracy =  0.875\n",
      "now loss =  0.07575610441160954  accuracy =  0.9375\n",
      "now loss =  0.08873573419751435  accuracy =  0.859375\n",
      "now loss =  0.07118355977219433  accuracy =  0.9375\n",
      "now loss =  0.09391958016232371  accuracy =  0.890625\n",
      "now loss =  0.11659205134515772  accuracy =  0.828125\n",
      "now loss =  0.061482971242703334  accuracy =  0.921875\n",
      "now loss =  0.08354539365270092  accuracy =  0.875\n",
      "now loss =  0.07727695468183027  accuracy =  0.921875\n",
      "now loss =  0.08670057005267409  accuracy =  0.875\n",
      "now loss =  0.07257954433011302  accuracy =  0.90625\n",
      "now loss =  0.07709236272546874  accuracy =  0.890625\n",
      "now loss =  0.1045081391005547  accuracy =  0.84375\n",
      "now loss =  0.0837179605696425  accuracy =  0.890625\n",
      "now loss =  0.13375550915301032  accuracy =  0.75\n",
      "now loss =  0.07126007326709213  accuracy =  0.90625\n",
      "now loss =  0.11047959993686693  accuracy =  0.828125\n",
      "now loss =  0.09437387371403458  accuracy =  0.875\n",
      "now loss =  0.06931030778626904  accuracy =  0.90625\n",
      "now loss =  0.08178427079911044  accuracy =  0.890625\n",
      "now loss =  0.07092118638458075  accuracy =  0.9375\n",
      "now loss =  0.07313440665394223  accuracy =  0.90625\n",
      "now loss =  0.07026748686844375  accuracy =  0.90625\n",
      "now loss =  0.10889023086616217  accuracy =  0.828125\n",
      "now loss =  0.10390253580813072  accuracy =  0.859375\n",
      "now loss =  0.06291134188665698  accuracy =  0.9375\n",
      "now loss =  0.09931335821305802  accuracy =  0.875\n",
      "now loss =  0.11829045871695851  accuracy =  0.84375\n",
      "now loss =  0.07405547943807825  accuracy =  0.875\n",
      "now loss =  0.0785638254575215  accuracy =  0.890625\n",
      "now loss =  0.08223876312545908  accuracy =  0.875\n",
      "now loss =  0.062175813598728646  accuracy =  0.90625\n",
      "now loss =  0.10280951644322565  accuracy =  0.875\n",
      "now loss =  0.05319565321801311  accuracy =  0.953125\n",
      "now loss =  0.1056020640788423  accuracy =  0.859375\n",
      "now loss =  0.07104652290534455  accuracy =  0.90625\n",
      "now loss =  0.09887000079264355  accuracy =  0.84375\n",
      "now loss =  0.08934566575806341  accuracy =  0.90625\n",
      "now loss =  0.10850459291161162  accuracy =  0.84375\n",
      "now loss =  0.06600113961867485  accuracy =  0.921875\n",
      "now loss =  0.09427671061855628  accuracy =  0.890625\n",
      "now loss =  0.07104656203940853  accuracy =  0.90625\n",
      "now loss =  0.09389842404810564  accuracy =  0.890625\n",
      "now loss =  0.08955700681877823  accuracy =  0.890625\n",
      "now loss =  0.0777179785084203  accuracy =  0.890625\n",
      "now loss =  0.07766467950542341  accuracy =  0.859375\n",
      "now loss =  0.12374893621472483  accuracy =  0.8\n",
      "now loss =  0.08730119081022189  accuracy =  0.859375\n",
      "now loss =  0.06926267899020128  accuracy =  0.921875\n",
      "now loss =  0.09417589336110264  accuracy =  0.875\n",
      "now loss =  0.0915238963856783  accuracy =  0.890625\n",
      "now loss =  0.1001096687221899  accuracy =  0.84375\n",
      "now loss =  0.08902050503208919  accuracy =  0.859375\n",
      "now loss =  0.07499715949184796  accuracy =  0.921875\n",
      "now loss =  0.06261210217159906  accuracy =  0.96875\n",
      "now loss =  0.1103695667969081  accuracy =  0.828125\n",
      "now loss =  0.0767895766887673  accuracy =  0.90625\n",
      "now loss =  0.0753719198247414  accuracy =  0.890625\n",
      "now loss =  0.08509266910463137  accuracy =  0.90625\n",
      "now loss =  0.09947052474325607  accuracy =  0.84375\n",
      "now loss =  0.07784771209973862  accuracy =  0.90625\n",
      "now loss =  0.09425498177537006  accuracy =  0.859375\n",
      "now loss =  0.08410432666095777  accuracy =  0.825\n",
      "now loss =  0.1007636485431217  accuracy =  0.859375\n",
      "now loss =  0.05708260474708472  accuracy =  0.953125\n",
      "now loss =  0.06101477604517144  accuracy =  0.921875\n",
      "now loss =  0.0988695402699596  accuracy =  0.84375\n",
      "now loss =  0.06265813154550048  accuracy =  0.921875\n",
      "now loss =  0.10521179345820086  accuracy =  0.828125\n",
      "now loss =  0.11229008812067566  accuracy =  0.828125\n",
      "now loss =  0.08861928376123994  accuracy =  0.859375\n",
      "now loss =  0.0697081318290284  accuracy =  0.9375\n",
      "now loss =  0.07585414576668598  accuracy =  0.875\n",
      "now loss =  0.08319385292181951  accuracy =  0.90625\n",
      "now loss =  0.08446211547751356  accuracy =  0.890625\n",
      "now loss =  0.10334020616774922  accuracy =  0.84375\n",
      "now loss =  0.08229507320349398  accuracy =  0.90625\n",
      "now loss =  0.0894935238274982  accuracy =  0.875\n",
      "now loss =  0.11419045088524989  accuracy =  0.825\n",
      "now loss =  0.08389265682750766  accuracy =  0.859375\n",
      "now loss =  0.1192548757126689  accuracy =  0.8125\n",
      "now loss =  0.06054947296477355  accuracy =  0.953125\n",
      "now loss =  0.10784919620931738  accuracy =  0.84375\n",
      "now loss =  0.09009999854108648  accuracy =  0.84375\n",
      "now loss =  0.06561210965000472  accuracy =  0.953125\n",
      "now loss =  0.08869792570350646  accuracy =  0.875\n",
      "now loss =  0.09617055324660115  accuracy =  0.828125\n",
      "now loss =  0.09563147866299015  accuracy =  0.859375\n",
      "now loss =  0.06253132984164629  accuracy =  0.953125\n",
      "now loss =  0.08948944117053596  accuracy =  0.859375\n",
      "now loss =  0.06079415006481253  accuracy =  0.90625\n",
      "now loss =  0.0743864918047563  accuracy =  0.890625\n",
      "now loss =  0.09851349832607026  accuracy =  0.875\n",
      "now loss =  0.0967239314909728  accuracy =  0.875\n",
      "now loss =  0.08390798757356446  accuracy =  0.9\n",
      "now loss =  0.09175308284094258  accuracy =  0.84375\n",
      "now loss =  0.06813812181145815  accuracy =  0.921875\n",
      "now loss =  0.0787190307533134  accuracy =  0.890625\n",
      "now loss =  0.07360313577361528  accuracy =  0.875\n",
      "now loss =  0.0752594699030522  accuracy =  0.90625\n",
      "now loss =  0.12151442087916259  accuracy =  0.8125\n",
      "now loss =  0.10600072568632131  accuracy =  0.875\n",
      "now loss =  0.09107438438687754  accuracy =  0.859375\n",
      "now loss =  0.09629786162057688  accuracy =  0.859375\n",
      "now loss =  0.08930255638147953  accuracy =  0.90625\n",
      "now loss =  0.06853565808790035  accuracy =  0.9375\n",
      "now loss =  0.09181668688973979  accuracy =  0.84375\n",
      "now loss =  0.07632797756772426  accuracy =  0.875\n",
      "now loss =  0.07131281298990401  accuracy =  0.921875\n",
      "now loss =  0.09354842945437217  accuracy =  0.875\n",
      "now loss =  0.08501303064797205  accuracy =  0.85\n",
      "now loss =  0.11652630356144006  accuracy =  0.84375\n",
      "now loss =  0.10028023597918284  accuracy =  0.828125\n",
      "now loss =  0.10359576892352321  accuracy =  0.84375\n",
      "now loss =  0.0951213332907132  accuracy =  0.90625\n",
      "now loss =  0.07196505084487767  accuracy =  0.890625\n",
      "now loss =  0.07985146070080237  accuracy =  0.859375\n",
      "now loss =  0.06308615913493382  accuracy =  0.9375\n",
      "now loss =  0.08683933122740384  accuracy =  0.890625\n",
      "now loss =  0.06778606578749885  accuracy =  0.921875\n",
      "now loss =  0.07425247623554941  accuracy =  0.890625\n",
      "now loss =  0.07322881032803127  accuracy =  0.890625\n",
      "now loss =  0.09170236771210763  accuracy =  0.875\n",
      "now loss =  0.0976872206247715  accuracy =  0.875\n",
      "now loss =  0.08992813142234772  accuracy =  0.859375\n",
      "now loss =  0.08170109293390637  accuracy =  0.90625\n",
      "now loss =  0.08552269865117827  accuracy =  0.925\n",
      "now loss =  0.09639342082611298  accuracy =  0.875\n",
      "now loss =  0.12075579520820652  accuracy =  0.84375\n",
      "now loss =  0.09461235201037024  accuracy =  0.84375\n",
      "now loss =  0.06853621284730999  accuracy =  0.921875\n",
      "now loss =  0.08447959787973734  accuracy =  0.90625\n",
      "now loss =  0.08594093809330994  accuracy =  0.90625\n",
      "now loss =  0.07918961694609762  accuracy =  0.921875\n",
      "now loss =  0.09235929400561028  accuracy =  0.875\n",
      "now loss =  0.08321491072817197  accuracy =  0.890625\n",
      "now loss =  0.07502676868261077  accuracy =  0.921875\n",
      "now loss =  0.08258125241673511  accuracy =  0.84375\n",
      "now loss =  0.06558767743712277  accuracy =  0.921875\n",
      "now loss =  0.1057703981638668  accuracy =  0.828125\n",
      "now loss =  0.09016902852191996  accuracy =  0.859375\n",
      "now loss =  0.08168260163561958  accuracy =  0.890625\n",
      "now loss =  0.06108348931064711  accuracy =  0.95\n",
      "now loss =  0.10002491362519919  accuracy =  0.84375\n",
      "now loss =  0.0784635447549156  accuracy =  0.90625\n",
      "now loss =  0.07419089126650733  accuracy =  0.90625\n",
      "now loss =  0.08236119068396536  accuracy =  0.921875\n",
      "now loss =  0.0679720175442315  accuracy =  0.921875\n",
      "now loss =  0.1090659603604088  accuracy =  0.828125\n",
      "now loss =  0.11111884402451117  accuracy =  0.859375\n",
      "now loss =  0.1024092703954591  accuracy =  0.859375\n",
      "now loss =  0.08249058434037375  accuracy =  0.859375\n",
      "now loss =  0.07662032948781292  accuracy =  0.921875\n",
      "now loss =  0.08146509068586065  accuracy =  0.875\n",
      "now loss =  0.0819520640004768  accuracy =  0.875\n",
      "now loss =  0.0958767267913258  accuracy =  0.875\n",
      "now loss =  0.08053901732022081  accuracy =  0.890625\n",
      "now loss =  0.07291014330898662  accuracy =  0.921875\n",
      "now loss =  0.07486911243950996  accuracy =  0.9\n",
      "now loss =  0.09637624077797136  accuracy =  0.84375\n",
      "now loss =  0.06911543836123102  accuracy =  0.9375\n",
      "now loss =  0.08534299344539631  accuracy =  0.859375\n",
      "now loss =  0.08920185509161385  accuracy =  0.875\n",
      "now loss =  0.06993101911432548  accuracy =  0.9375\n",
      "now loss =  0.08892486079522648  accuracy =  0.890625\n",
      "now loss =  0.07300652852672598  accuracy =  0.90625\n",
      "now loss =  0.09551526516894376  accuracy =  0.890625\n",
      "now loss =  0.0747367839361391  accuracy =  0.90625\n",
      "now loss =  0.10232230463306062  accuracy =  0.828125\n",
      "now loss =  0.08002623541378937  accuracy =  0.859375\n",
      "now loss =  0.09825904523000992  accuracy =  0.84375\n",
      "now loss =  0.06647547121556077  accuracy =  0.90625\n",
      "now loss =  0.07113738458404845  accuracy =  0.90625\n",
      "now loss =  0.1311397024306729  accuracy =  0.8125\n",
      "now loss =  0.07300545705861194  accuracy =  0.925\n",
      "now loss =  0.11218327469744993  accuracy =  0.78125\n",
      "now loss =  0.09604177717070765  accuracy =  0.84375\n",
      "now loss =  0.09726363985620126  accuracy =  0.875\n",
      "now loss =  0.09373384934565077  accuracy =  0.84375\n",
      "now loss =  0.08063369612614085  accuracy =  0.859375\n",
      "now loss =  0.10452898467183601  accuracy =  0.84375\n",
      "now loss =  0.05310890090719128  accuracy =  0.9375\n",
      "now loss =  0.0772439483687594  accuracy =  0.90625\n",
      "now loss =  0.08253045735626652  accuracy =  0.890625\n",
      "now loss =  0.07881071067965598  accuracy =  0.875\n",
      "now loss =  0.10045266641411915  accuracy =  0.875\n",
      "now loss =  0.08327336618346382  accuracy =  0.90625\n",
      "now loss =  0.06786592892125713  accuracy =  0.921875\n",
      "now loss =  0.06951203700659736  accuracy =  0.9375\n",
      "now loss =  0.09111725217904083  accuracy =  0.90625\n",
      "now loss =  0.10495594839864353  accuracy =  0.85\n",
      "now loss =  0.0949358698426599  accuracy =  0.859375\n",
      "now loss =  0.07278423263725574  accuracy =  0.890625\n",
      "now loss =  0.07808722461494677  accuracy =  0.90625\n",
      "now loss =  0.10338424071847169  accuracy =  0.84375\n",
      "now loss =  0.09284390870071843  accuracy =  0.859375\n",
      "now loss =  0.06752730080868519  accuracy =  0.921875\n",
      "now loss =  0.07597552388236523  accuracy =  0.890625\n",
      "now loss =  0.0625207450146819  accuracy =  0.921875\n",
      "now loss =  0.0995182070383053  accuracy =  0.859375\n",
      "now loss =  0.07074622430580174  accuracy =  0.921875\n",
      "now loss =  0.07008710784572769  accuracy =  0.9375\n",
      "now loss =  0.08311573169651548  accuracy =  0.90625\n",
      "now loss =  0.09056297363371943  accuracy =  0.859375\n",
      "now loss =  0.08417254134589985  accuracy =  0.90625\n",
      "now loss =  0.1445393016990733  accuracy =  0.75\n",
      "now loss =  0.07895468525451102  accuracy =  0.85\n",
      "now loss =  0.09252792212471048  accuracy =  0.84375\n",
      "now loss =  0.0678242447655912  accuracy =  0.921875\n",
      "now loss =  0.09141962578959466  accuracy =  0.90625\n",
      "now loss =  0.07553258809539873  accuracy =  0.921875\n",
      "now loss =  0.0795571774184361  accuracy =  0.875\n",
      "now loss =  0.07833973265024435  accuracy =  0.890625\n",
      "now loss =  0.05530802854851569  accuracy =  0.953125\n",
      "now loss =  0.09783347675599306  accuracy =  0.90625\n",
      "now loss =  0.08370558989039045  accuracy =  0.890625\n",
      "now loss =  0.09684080653254706  accuracy =  0.859375\n",
      "now loss =  0.11759274486459462  accuracy =  0.796875\n",
      "now loss =  0.0871099828813264  accuracy =  0.890625\n",
      "now loss =  0.10096019590688979  accuracy =  0.890625\n",
      "now loss =  0.08030321053835118  accuracy =  0.890625\n",
      "now loss =  0.08270185318453414  accuracy =  0.875\n",
      "now loss =  0.07443440335472125  accuracy =  0.9\n",
      "now loss =  0.10312814392503415  accuracy =  0.84375\n",
      "now loss =  0.09813735559881254  accuracy =  0.875\n",
      "now loss =  0.07268466884949043  accuracy =  0.890625\n",
      "now loss =  0.06692737903537149  accuracy =  0.90625\n",
      "now loss =  0.11864628461930868  accuracy =  0.8125\n",
      "now loss =  0.0745263156972076  accuracy =  0.9375\n",
      "now loss =  0.08301786854608505  accuracy =  0.890625\n",
      "now loss =  0.08618268593592016  accuracy =  0.875\n",
      "now loss =  0.0929221699518763  accuracy =  0.921875\n",
      "now loss =  0.0667896403093115  accuracy =  0.921875\n",
      "now loss =  0.0764321218368961  accuracy =  0.921875\n",
      "now loss =  0.09784281032187687  accuracy =  0.828125\n",
      "now loss =  0.07686358611972184  accuracy =  0.875\n",
      "now loss =  0.05916995435131282  accuracy =  0.953125\n",
      "now loss =  0.10451069209959105  accuracy =  0.859375\n",
      "now loss =  0.09091892211367744  accuracy =  0.825\n",
      "now loss =  0.08617570702157902  accuracy =  0.890625\n",
      "now loss =  0.083917788381065  accuracy =  0.859375\n",
      "now loss =  0.09576471671067394  accuracy =  0.890625\n",
      "now loss =  0.09647902190664462  accuracy =  0.859375\n",
      "now loss =  0.08446000998492502  accuracy =  0.890625\n",
      "now loss =  0.0746968882022498  accuracy =  0.90625\n",
      "now loss =  0.09628644792109428  accuracy =  0.84375\n",
      "now loss =  0.08271597997129872  accuracy =  0.84375\n",
      "now loss =  0.08628021053974595  accuracy =  0.90625\n",
      "now loss =  0.10510718872718024  accuracy =  0.828125\n",
      "now loss =  0.08884620992187486  accuracy =  0.875\n",
      "now loss =  0.09856090124134803  accuracy =  0.890625\n",
      "now loss =  0.07598098196220679  accuracy =  0.90625\n",
      "now loss =  0.06162547758858789  accuracy =  0.9375\n",
      "now loss =  0.09790758717756852  accuracy =  0.84375\n",
      "now loss =  0.049680106463749756  accuracy =  1.0\n",
      "now loss =  0.09995047748038177  accuracy =  0.90625\n",
      "now loss =  0.07050121238871856  accuracy =  0.875\n",
      "now loss =  0.0816161898606664  accuracy =  0.90625\n",
      "now loss =  0.09485387490739867  accuracy =  0.875\n",
      "now loss =  0.055383906432158  accuracy =  0.96875\n",
      "now loss =  0.10105066868015405  accuracy =  0.84375\n",
      "now loss =  0.0813009219551336  accuracy =  0.875\n",
      "now loss =  0.08363004084978495  accuracy =  0.90625\n",
      "now loss =  0.06591818807045766  accuracy =  0.9375\n",
      "now loss =  0.08638318454354967  accuracy =  0.859375\n",
      "now loss =  0.09591022145281614  accuracy =  0.859375\n",
      "now loss =  0.07587396795447766  accuracy =  0.890625\n",
      "now loss =  0.12055926418040105  accuracy =  0.765625\n",
      "now loss =  0.09236133748714506  accuracy =  0.84375\n",
      "now loss =  0.08865042705598111  accuracy =  0.90625\n",
      "now loss =  0.07881735021038988  accuracy =  0.875\n",
      "now loss =  0.06068461425926693  accuracy =  0.953125\n",
      "now loss =  0.08325609570743733  accuracy =  0.875\n",
      "now loss =  0.060318806919670016  accuracy =  0.984375\n",
      "now loss =  0.0839152917936999  accuracy =  0.890625\n",
      "now loss =  0.12283594912811996  accuracy =  0.828125\n",
      "now loss =  0.08158143595734973  accuracy =  0.875\n",
      "now loss =  0.0916423382034619  accuracy =  0.859375\n",
      "now loss =  0.07190018760174376  accuracy =  0.9375\n",
      "now loss =  0.10174682679321181  accuracy =  0.859375\n",
      "now loss =  0.09584466740972  accuracy =  0.8125\n",
      "now loss =  0.10188646904478742  accuracy =  0.859375\n",
      "now loss =  0.07438939747264076  accuracy =  0.890625\n",
      "now loss =  0.06682850019131387  accuracy =  0.9375\n",
      "now loss =  0.0826757319570943  accuracy =  0.921875\n",
      "now loss =  0.1106286331624018  accuracy =  0.796875\n",
      "now loss =  0.0891363528013575  accuracy =  0.85\n",
      "now loss =  0.10800095410860591  accuracy =  0.828125\n",
      "now loss =  0.07486664037406429  accuracy =  0.890625\n",
      "now loss =  0.08282945785212789  accuracy =  0.859375\n",
      "now loss =  0.0748983252813136  accuracy =  0.9375\n",
      "now loss =  0.06306879792892835  accuracy =  0.921875\n",
      "now loss =  0.07343160226057731  accuracy =  0.9375\n",
      "now loss =  0.08888589510568518  accuracy =  0.859375\n",
      "now loss =  0.09670427308976413  accuracy =  0.859375\n",
      "now loss =  0.11062361319503008  accuracy =  0.828125\n",
      "now loss =  0.10715479424188955  accuracy =  0.859375\n",
      "now loss =  0.08240033801439309  accuracy =  0.890625\n",
      "now loss =  0.08504601813905172  accuracy =  0.90625\n",
      "now loss =  0.058764953318712024  accuracy =  0.9375\n",
      "now loss =  0.09182033441422002  accuracy =  0.875\n",
      "now loss =  0.08687676681662601  accuracy =  0.875\n",
      "now loss =  0.0970541685152648  accuracy =  0.9\n",
      "now loss =  0.08021154790267304  accuracy =  0.859375\n",
      "now loss =  0.09046242161268347  accuracy =  0.859375\n",
      "now loss =  0.0991392163900756  accuracy =  0.875\n",
      "now loss =  0.10012280180553321  accuracy =  0.84375\n",
      "now loss =  0.09406779566328605  accuracy =  0.859375\n",
      "now loss =  0.08095083101944955  accuracy =  0.921875\n",
      "now loss =  0.0746804543076715  accuracy =  0.90625\n",
      "now loss =  0.09302442317373219  accuracy =  0.890625\n",
      "now loss =  0.07103224318423025  accuracy =  0.9375\n",
      "now loss =  0.06637241100884139  accuracy =  0.9375\n",
      "now loss =  0.06726030508167012  accuracy =  0.90625\n",
      "now loss =  0.11807989414229252  accuracy =  0.8125\n",
      "now loss =  0.062453983419607985  accuracy =  0.921875\n",
      "now loss =  0.11358349390039495  accuracy =  0.84375\n",
      "now loss =  0.07853393410076456  accuracy =  0.90625\n",
      "now loss =  0.08623566319038203  accuracy =  0.9\n",
      "now loss =  0.11132914168410388  accuracy =  0.84375\n",
      "now loss =  0.11891452049189281  accuracy =  0.828125\n",
      "now loss =  0.09245542081103902  accuracy =  0.859375\n",
      "now loss =  0.09933985233467596  accuracy =  0.84375\n",
      "now loss =  0.062408445079532526  accuracy =  0.921875\n",
      "now loss =  0.093795535472104  accuracy =  0.875\n",
      "now loss =  0.06815088599389295  accuracy =  0.890625\n",
      "now loss =  0.08623389267878365  accuracy =  0.84375\n",
      "now loss =  0.09065263936690136  accuracy =  0.859375\n",
      "now loss =  0.09856575334370764  accuracy =  0.890625\n",
      "now loss =  0.06817442498109694  accuracy =  0.90625\n",
      "now loss =  0.07287968186022543  accuracy =  0.90625\n",
      "now loss =  0.08871081442556031  accuracy =  0.875\n",
      "now loss =  0.06665669994340498  accuracy =  0.921875\n",
      "now loss =  0.09436635412820163  accuracy =  0.859375\n",
      "now loss =  0.050775092569544336  accuracy =  0.95\n",
      "now loss =  0.07068687189981467  accuracy =  0.890625\n",
      "now loss =  0.07974382003679172  accuracy =  0.890625\n",
      "now loss =  0.10641802632287548  accuracy =  0.8125\n",
      "now loss =  0.09504707867843487  accuracy =  0.84375\n",
      "now loss =  0.09541380558777525  accuracy =  0.90625\n",
      "now loss =  0.09891310585353454  accuracy =  0.875\n",
      "now loss =  0.0703926768415579  accuracy =  0.90625\n",
      "now loss =  0.09594268329708358  accuracy =  0.859375\n",
      "now loss =  0.07305166937410956  accuracy =  0.9375\n",
      "now loss =  0.08558787871102155  accuracy =  0.875\n",
      "now loss =  0.09162374514401711  accuracy =  0.859375\n",
      "now loss =  0.08383019332217542  accuracy =  0.890625\n",
      "now loss =  0.07945673034901826  accuracy =  0.90625\n",
      "now loss =  0.07780487639936456  accuracy =  0.90625\n",
      "now loss =  0.0942028752697238  accuracy =  0.90625\n",
      "now loss =  0.0682587753557143  accuracy =  0.925\n",
      "now loss =  0.0755670163204645  accuracy =  0.921875\n",
      "now loss =  0.08746063825955933  accuracy =  0.890625\n",
      "now loss =  0.0990451404104109  accuracy =  0.859375\n",
      "now loss =  0.07672528813769083  accuracy =  0.921875\n",
      "now loss =  0.09783053132278519  accuracy =  0.859375\n",
      "now loss =  0.08719190831636472  accuracy =  0.921875\n",
      "now loss =  0.08306501529661864  accuracy =  0.859375\n",
      "now loss =  0.07667328668889892  accuracy =  0.90625\n",
      "now loss =  0.15139989550318808  accuracy =  0.734375\n",
      "now loss =  0.07566520820247598  accuracy =  0.890625\n",
      "now loss =  0.06665788283570531  accuracy =  0.9375\n",
      "now loss =  0.0660661255369179  accuracy =  0.921875\n",
      "now loss =  0.07463441472212592  accuracy =  0.890625\n",
      "now loss =  0.09774898099876245  accuracy =  0.828125\n",
      "now loss =  0.0797984924825573  accuracy =  0.875\n",
      "now loss =  0.0798537145445319  accuracy =  0.925\n",
      "now loss =  0.08662353618777988  accuracy =  0.890625\n",
      "now loss =  0.09301349528449085  accuracy =  0.875\n",
      "now loss =  0.09211185470269129  accuracy =  0.875\n",
      "now loss =  0.07823366307761286  accuracy =  0.921875\n",
      "now loss =  0.09300222220924592  accuracy =  0.859375\n",
      "now loss =  0.09833435782428215  accuracy =  0.84375\n",
      "now loss =  0.08351767250644626  accuracy =  0.90625\n",
      "now loss =  0.08179503151778847  accuracy =  0.890625\n",
      "now loss =  0.07902374985548478  accuracy =  0.890625\n",
      "now loss =  0.04528570496236083  accuracy =  0.953125\n",
      "now loss =  0.10173065790929817  accuracy =  0.859375\n",
      "now loss =  0.07145092139543757  accuracy =  0.890625\n",
      "now loss =  0.0854167032722471  accuracy =  0.890625\n",
      "now loss =  0.10448275043944102  accuracy =  0.8125\n",
      "now loss =  0.11494329734727032  accuracy =  0.8125\n",
      "now loss =  0.06181670255603329  accuracy =  0.925\n",
      "now loss =  0.0877230699790077  accuracy =  0.890625\n",
      "now loss =  0.08298254015416559  accuracy =  0.90625\n",
      "now loss =  0.0954291580607719  accuracy =  0.859375\n",
      "now loss =  0.08437300433568191  accuracy =  0.890625\n",
      "now loss =  0.08007918103002981  accuracy =  0.875\n",
      "now loss =  0.09845386671683093  accuracy =  0.828125\n",
      "now loss =  0.08531895149740071  accuracy =  0.890625\n",
      "now loss =  0.09955940509782249  accuracy =  0.875\n",
      "now loss =  0.06921685779401643  accuracy =  0.9375\n",
      "now loss =  0.0632638252045109  accuracy =  0.90625\n",
      "now loss =  0.0933179081292558  accuracy =  0.859375\n",
      "now loss =  0.08792410854644607  accuracy =  0.90625\n",
      "now loss =  0.10879945158459567  accuracy =  0.828125\n",
      "now loss =  0.06305656306839513  accuracy =  0.953125\n",
      "now loss =  0.08377678973923489  accuracy =  0.859375\n",
      "now loss =  0.0889861847470823  accuracy =  0.875\n",
      "now loss =  0.06151446694243959  accuracy =  0.921875\n",
      "now loss =  0.09719969054405131  accuracy =  0.875\n",
      "now loss =  0.07100822955922086  accuracy =  0.9375\n",
      "now loss =  0.06771785291682976  accuracy =  0.9375\n",
      "now loss =  0.09642724889379176  accuracy =  0.875\n",
      "now loss =  0.10109253645290806  accuracy =  0.84375\n",
      "now loss =  0.09585715959661151  accuracy =  0.90625\n",
      "now loss =  0.08371800700791959  accuracy =  0.875\n",
      "now loss =  0.09313178409942016  accuracy =  0.890625\n",
      "now loss =  0.1019570349028319  accuracy =  0.84375\n",
      "now loss =  0.11015380022632043  accuracy =  0.828125\n",
      "now loss =  0.0843868907957799  accuracy =  0.90625\n",
      "now loss =  0.08707491021270951  accuracy =  0.859375\n",
      "now loss =  0.06158850013126335  accuracy =  0.9375\n",
      "now loss =  0.06515805309026754  accuracy =  0.90625\n",
      "now loss =  0.09970007780248295  accuracy =  0.825\n",
      "now loss =  0.08865824874825476  accuracy =  0.875\n",
      "now loss =  0.05452252532693117  accuracy =  0.96875\n",
      "now loss =  0.09038755575070334  accuracy =  0.890625\n",
      "now loss =  0.07247829157773307  accuracy =  0.90625\n",
      "now loss =  0.10990462296092182  accuracy =  0.84375\n",
      "now loss =  0.09934898479173795  accuracy =  0.84375\n",
      "now loss =  0.08548293617853683  accuracy =  0.875\n",
      "now loss =  0.09222069212159356  accuracy =  0.890625\n",
      "now loss =  0.12149030277295694  accuracy =  0.84375\n",
      "now loss =  0.07617082352264484  accuracy =  0.921875\n",
      "now loss =  0.09312038440846501  accuracy =  0.859375\n",
      "now loss =  0.08285835815435462  accuracy =  0.875\n",
      "now loss =  0.07201118039355826  accuracy =  0.90625\n",
      "now loss =  0.10061719775811678  accuracy =  0.84375\n",
      "now loss =  0.07107864193877718  accuracy =  0.9375\n",
      "now loss =  0.057966556744323695  accuracy =  0.925\n",
      "now loss =  0.05651444401844285  accuracy =  0.9375\n",
      "now loss =  0.07689818845704888  accuracy =  0.90625\n",
      "now loss =  0.09155599137775713  accuracy =  0.90625\n",
      "now loss =  0.08227977964666054  accuracy =  0.921875\n",
      "now loss =  0.07726222502085245  accuracy =  0.890625\n",
      "now loss =  0.06808554350482224  accuracy =  0.890625\n",
      "now loss =  0.0713370042274643  accuracy =  0.890625\n",
      "now loss =  0.08089043415140518  accuracy =  0.890625\n",
      "now loss =  0.0823459853969101  accuracy =  0.90625\n",
      "now loss =  0.09049014775338302  accuracy =  0.890625\n",
      "now loss =  0.0901285013925048  accuracy =  0.859375\n",
      "now loss =  0.10055255308908208  accuracy =  0.875\n",
      "now loss =  0.11407653005661925  accuracy =  0.828125\n",
      "now loss =  0.11916949642613206  accuracy =  0.796875\n",
      "now loss =  0.08488403640313966  accuracy =  0.859375\n",
      "now loss =  0.07637102062708942  accuracy =  0.9\n",
      "now loss =  0.07723025075183475  accuracy =  0.921875\n",
      "now loss =  0.09251033840905609  accuracy =  0.859375\n",
      "now loss =  0.1223357364187529  accuracy =  0.796875\n",
      "now loss =  0.09752220337880148  accuracy =  0.890625\n",
      "now loss =  0.10447826452251253  accuracy =  0.859375\n",
      "now loss =  0.05733231808267725  accuracy =  0.9375\n",
      "now loss =  0.06972801322650203  accuracy =  0.90625\n",
      "now loss =  0.07381038332675656  accuracy =  0.890625\n",
      "now loss =  0.0702154870640539  accuracy =  0.90625\n",
      "now loss =  0.0992956352020785  accuracy =  0.84375\n",
      "now loss =  0.11098603512050448  accuracy =  0.859375\n",
      "now loss =  0.07089441649313852  accuracy =  0.90625\n",
      "now loss =  0.07013218541714215  accuracy =  0.921875\n",
      "now loss =  0.08228368233179782  accuracy =  0.890625\n",
      "now loss =  0.08650641210664867  accuracy =  0.890625\n",
      "now loss =  0.09856268924001757  accuracy =  0.85\n",
      "now loss =  0.08178135734404482  accuracy =  0.90625\n",
      "now loss =  0.07587950238862717  accuracy =  0.921875\n",
      "now loss =  0.10536496660890543  accuracy =  0.828125\n",
      "now loss =  0.08954830374319389  accuracy =  0.875\n",
      "now loss =  0.1057933841810352  accuracy =  0.84375\n",
      "now loss =  0.10838075712254458  accuracy =  0.828125\n",
      "now loss =  0.09654170293484043  accuracy =  0.875\n",
      "now loss =  0.08613409899565772  accuracy =  0.875\n",
      "now loss =  0.07519867590191201  accuracy =  0.90625\n",
      "now loss =  0.06084331093827812  accuracy =  0.9375\n",
      "now loss =  0.07051694391190039  accuracy =  0.90625\n",
      "now loss =  0.09548366669310533  accuracy =  0.875\n",
      "now loss =  0.060013142791975296  accuracy =  0.921875\n",
      "now loss =  0.07084843716254184  accuracy =  0.890625\n",
      "now loss =  0.11448956753173578  accuracy =  0.828125\n",
      "now loss =  0.06947825784527148  accuracy =  0.925\n",
      "now loss =  0.08317600196697589  accuracy =  0.90625\n",
      "now loss =  0.09937755269887827  accuracy =  0.875\n",
      "now loss =  0.07096042100346363  accuracy =  0.890625\n",
      "now loss =  0.059900698721655946  accuracy =  0.921875\n",
      "now loss =  0.09779856121224685  accuracy =  0.859375\n",
      "now loss =  0.07690472541811075  accuracy =  0.921875\n",
      "now loss =  0.09663070910885013  accuracy =  0.8125\n",
      "now loss =  0.0801150687328549  accuracy =  0.921875\n",
      "now loss =  0.07722989122739154  accuracy =  0.90625\n",
      "now loss =  0.11764797384230855  accuracy =  0.828125\n",
      "now loss =  0.10886844432291348  accuracy =  0.84375\n",
      "now loss =  0.10913527032247057  accuracy =  0.8125\n",
      "now loss =  0.06950451861392289  accuracy =  0.9375\n",
      "now loss =  0.05390603453324199  accuracy =  0.96875\n",
      "now loss =  0.10869390029092361  accuracy =  0.8125\n",
      "now loss =  0.05642679299717383  accuracy =  0.975\n",
      "now loss =  0.1022736109576006  accuracy =  0.859375\n",
      "now loss =  0.05722915329739599  accuracy =  0.921875\n",
      "now loss =  0.10344314556192964  accuracy =  0.875\n",
      "now loss =  0.08010090642195092  accuracy =  0.875\n",
      "now loss =  0.08749312038069021  accuracy =  0.859375\n",
      "now loss =  0.07591628730523142  accuracy =  0.90625\n",
      "now loss =  0.07727798558841359  accuracy =  0.90625\n",
      "now loss =  0.08198133113696543  accuracy =  0.875\n",
      "now loss =  0.08493911516544327  accuracy =  0.890625\n",
      "now loss =  0.058675062567929016  accuracy =  0.953125\n",
      "now loss =  0.06471021525902967  accuracy =  0.921875\n",
      "now loss =  0.09137293752683391  accuracy =  0.859375\n",
      "now loss =  0.12229340010407719  accuracy =  0.828125\n",
      "now loss =  0.08994378614426651  accuracy =  0.875\n",
      "now loss =  0.10098028436084186  accuracy =  0.890625\n",
      "now loss =  0.10017676376410604  accuracy =  0.825\n",
      "now loss =  0.08231174953877252  accuracy =  0.890625\n",
      "now loss =  0.06863928632785762  accuracy =  0.921875\n",
      "now loss =  0.06054502299357154  accuracy =  0.921875\n",
      "now loss =  0.09143129353429807  accuracy =  0.859375\n",
      "now loss =  0.10259924819601912  accuracy =  0.875\n",
      "now loss =  0.07961415738941663  accuracy =  0.875\n",
      "now loss =  0.08755365288224241  accuracy =  0.859375\n",
      "now loss =  0.09559417819441599  accuracy =  0.875\n",
      "now loss =  0.07910041464702852  accuracy =  0.90625\n",
      "now loss =  0.08851071910552497  accuracy =  0.859375\n",
      "now loss =  0.07363345784119182  accuracy =  0.921875\n",
      "now loss =  0.07609404786690281  accuracy =  0.921875\n",
      "now loss =  0.08751872514975308  accuracy =  0.890625\n",
      "now loss =  0.07750189752058244  accuracy =  0.90625\n",
      "now loss =  0.11095685164350647  accuracy =  0.859375\n",
      "now loss =  0.12520262057892836  accuracy =  0.8\n",
      "now loss =  0.11924650102478014  accuracy =  0.859375\n",
      "now loss =  0.062078002365987435  accuracy =  0.90625\n",
      "now loss =  0.09461674449673942  accuracy =  0.875\n",
      "now loss =  0.0984708108125984  accuracy =  0.859375\n",
      "now loss =  0.07680144799568484  accuracy =  0.90625\n",
      "now loss =  0.10698105831131674  accuracy =  0.8125\n",
      "now loss =  0.08194401422278665  accuracy =  0.890625\n",
      "now loss =  0.06928080397197202  accuracy =  0.921875\n",
      "now loss =  0.07787387601625435  accuracy =  0.890625\n",
      "now loss =  0.07238373005923082  accuracy =  0.921875\n",
      "now loss =  0.09215860757125487  accuracy =  0.859375\n",
      "now loss =  0.07836794859165513  accuracy =  0.890625\n",
      "now loss =  0.07617185333257218  accuracy =  0.890625\n",
      "now loss =  0.07598312813164988  accuracy =  0.921875\n",
      "now loss =  0.09069857877378143  accuracy =  0.90625\n",
      "now loss =  0.10963970662563524  accuracy =  0.8\n",
      "now loss =  0.06810855925748258  accuracy =  0.921875\n",
      "now loss =  0.09211194800005967  accuracy =  0.84375\n",
      "now loss =  0.1008984863070556  accuracy =  0.859375\n",
      "now loss =  0.07815302217912863  accuracy =  0.890625\n",
      "now loss =  0.07185184620411103  accuracy =  0.921875\n",
      "now loss =  0.10657890943063103  accuracy =  0.8125\n",
      "now loss =  0.06917071701420369  accuracy =  0.921875\n",
      "now loss =  0.07735292358885315  accuracy =  0.90625\n",
      "now loss =  0.06507716283056679  accuracy =  0.9375\n",
      "now loss =  0.10299437542595163  accuracy =  0.828125\n",
      "now loss =  0.10867182325761368  accuracy =  0.90625\n",
      "now loss =  0.08723731730357433  accuracy =  0.859375\n",
      "now loss =  0.08872124192147854  accuracy =  0.859375\n",
      "now loss =  0.09450564541844567  accuracy =  0.890625\n",
      "now loss =  0.08277853612345432  accuracy =  0.90625\n",
      "now loss =  0.07887195354107338  accuracy =  0.875\n",
      "now loss =  0.0923312401932979  accuracy =  0.859375\n",
      "now loss =  0.08969779748068563  accuracy =  0.875\n",
      "now loss =  0.11064865733612492  accuracy =  0.859375\n",
      "now loss =  0.08494787767381376  accuracy =  0.890625\n",
      "now loss =  0.07556071439169885  accuracy =  0.890625\n",
      "now loss =  0.08021860238508467  accuracy =  0.875\n",
      "now loss =  0.09309341868823971  accuracy =  0.90625\n",
      "now loss =  0.05254495816961282  accuracy =  0.96875\n",
      "now loss =  0.08495521540599264  accuracy =  0.890625\n",
      "now loss =  0.08670614409543356  accuracy =  0.875\n",
      "now loss =  0.08328659854713084  accuracy =  0.890625\n",
      "now loss =  0.07373917287389287  accuracy =  0.890625\n",
      "now loss =  0.0665956097211758  accuracy =  0.9375\n",
      "now loss =  0.0951571670043782  accuracy =  0.84375\n",
      "now loss =  0.10353086846964424  accuracy =  0.859375\n",
      "now loss =  0.11161047289668447  accuracy =  0.85\n",
      "now loss =  0.09287775316732011  accuracy =  0.875\n",
      "now loss =  0.07305451917668328  accuracy =  0.9375\n",
      "now loss =  0.10406771043064617  accuracy =  0.828125\n",
      "now loss =  0.09689060026306918  accuracy =  0.859375\n",
      "now loss =  0.0796869364192488  accuracy =  0.921875\n",
      "now loss =  0.10422271122840848  accuracy =  0.875\n",
      "now loss =  0.07401709618628735  accuracy =  0.90625\n",
      "now loss =  0.12514334819218606  accuracy =  0.78125\n",
      "now loss =  0.06686860649585397  accuracy =  0.90625\n",
      "now loss =  0.07294174791484079  accuracy =  0.90625\n",
      "now loss =  0.09242079803968756  accuracy =  0.890625\n",
      "now loss =  0.05180226564904996  accuracy =  0.9375\n",
      "now loss =  0.09960697352275755  accuracy =  0.84375\n",
      "now loss =  0.0838918976287781  accuracy =  0.875\n",
      "now loss =  0.07894749397677646  accuracy =  0.875\n",
      "now loss =  0.07837673242257351  accuracy =  0.9\n",
      "now loss =  0.04923145871353578  accuracy =  0.96875\n",
      "now loss =  0.0751822191638279  accuracy =  0.921875\n",
      "now loss =  0.09348843739972419  accuracy =  0.828125\n",
      "now loss =  0.11693132268077236  accuracy =  0.84375\n",
      "now loss =  0.1000805078866327  accuracy =  0.859375\n",
      "now loss =  0.07721108481297019  accuracy =  0.921875\n",
      "now loss =  0.07681079979835123  accuracy =  0.890625\n",
      "now loss =  0.07718234647906085  accuracy =  0.921875\n",
      "now loss =  0.10654028753940903  accuracy =  0.828125\n",
      "now loss =  0.06212599849928786  accuracy =  0.9375\n",
      "now loss =  0.08798210276464286  accuracy =  0.875\n",
      "now loss =  0.08125961992019806  accuracy =  0.890625\n",
      "now loss =  0.07980984989686576  accuracy =  0.90625\n",
      "now loss =  0.11425185134646892  accuracy =  0.84375\n",
      "now loss =  0.08761903483036111  accuracy =  0.875\n",
      "now loss =  0.0932173588455768  accuracy =  0.85\n",
      "now loss =  0.08358589223630017  accuracy =  0.875\n",
      "now loss =  0.10435698122196949  accuracy =  0.859375\n",
      "now loss =  0.10351726298724298  accuracy =  0.828125\n",
      "now loss =  0.09036135187037028  accuracy =  0.859375\n",
      "now loss =  0.08353961629716741  accuracy =  0.90625\n",
      "now loss =  0.08634985980601956  accuracy =  0.875\n",
      "now loss =  0.06597666483645315  accuracy =  0.921875\n",
      "now loss =  0.0942668111582961  accuracy =  0.890625\n",
      "now loss =  0.07160477671330448  accuracy =  0.90625\n",
      "now loss =  0.07387378549000653  accuracy =  0.890625\n",
      "now loss =  0.08740987287271534  accuracy =  0.890625\n",
      "now loss =  0.1021363747969797  accuracy =  0.859375\n",
      "now loss =  0.11149530274190628  accuracy =  0.828125\n",
      "now loss =  0.07972241141165484  accuracy =  0.90625\n",
      "now loss =  0.048489187682115034  accuracy =  0.96875\n",
      "now loss =  0.0833250507238894  accuracy =  0.875\n",
      "now loss =  0.058225810216902686  accuracy =  0.921875\n",
      "now loss =  0.06025519776485962  accuracy =  0.953125\n",
      "now loss =  0.07691074705431862  accuracy =  0.90625\n",
      "now loss =  0.08009634887138312  accuracy =  0.890625\n",
      "now loss =  0.0738749966926333  accuracy =  0.875\n",
      "now loss =  0.11181193255226755  accuracy =  0.8125\n",
      "now loss =  0.12057972920818387  accuracy =  0.859375\n",
      "now loss =  0.08770603413527531  accuracy =  0.875\n",
      "now loss =  0.10983995420401357  accuracy =  0.8125\n",
      "now loss =  0.07058482552219122  accuracy =  0.875\n",
      "now loss =  0.11135354664458816  accuracy =  0.828125\n",
      "now loss =  0.09510219844964264  accuracy =  0.890625\n",
      "now loss =  0.05235729191754973  accuracy =  0.96875\n",
      "now loss =  0.08658346221119909  accuracy =  0.890625\n",
      "now loss =  0.08595943828647325  accuracy =  0.875\n",
      "now loss =  0.10353294595730245  accuracy =  0.875\n",
      "now loss =  0.058817971436300145  accuracy =  0.953125\n",
      "now loss =  0.11745405716338811  accuracy =  0.84375\n",
      "now loss =  0.10400825063295199  accuracy =  0.84375\n",
      "now loss =  0.07382785566956844  accuracy =  0.9375\n",
      "now loss =  0.08343478587321018  accuracy =  0.90625\n",
      "now loss =  0.07389426348482361  accuracy =  0.921875\n",
      "now loss =  0.10047113461993647  accuracy =  0.828125\n",
      "now loss =  0.07188872676951448  accuracy =  0.875\n",
      "now loss =  0.10382142673625905  accuracy =  0.828125\n",
      "now loss =  0.08271913928147206  accuracy =  0.90625\n",
      "now loss =  0.0829021601099867  accuracy =  0.90625\n",
      "now loss =  0.08023033386397643  accuracy =  0.890625\n",
      "now loss =  0.06819163709067841  accuracy =  0.890625\n",
      "now loss =  0.09906860847460337  accuracy =  0.84375\n",
      "now loss =  0.1030258415394622  accuracy =  0.84375\n",
      "now loss =  0.06050330601307049  accuracy =  0.925\n",
      "now loss =  0.10485390870929728  accuracy =  0.890625\n",
      "now loss =  0.12001936473940056  accuracy =  0.828125\n",
      "now loss =  0.08553518537016078  accuracy =  0.875\n",
      "now loss =  0.0727280488778654  accuracy =  0.90625\n",
      "now loss =  0.07802308323846288  accuracy =  0.859375\n",
      "now loss =  0.08690984558281047  accuracy =  0.875\n",
      "now loss =  0.09236277803396457  accuracy =  0.859375\n",
      "now loss =  0.06853854198347815  accuracy =  0.9375\n",
      "now loss =  0.10084778898703949  accuracy =  0.84375\n",
      "now loss =  0.06093810986541236  accuracy =  0.96875\n",
      "now loss =  0.05498895746510913  accuracy =  0.953125\n",
      "now loss =  0.10768778447002958  accuracy =  0.859375\n",
      "now loss =  0.1122983850511764  accuracy =  0.828125\n",
      "now loss =  0.057031147512992854  accuracy =  0.921875\n",
      "now loss =  0.09204365658106325  accuracy =  0.84375\n",
      "now loss =  0.0714222981414521  accuracy =  0.925\n",
      "now loss =  0.053383468942648005  accuracy =  0.96875\n",
      "now loss =  0.09991622575023734  accuracy =  0.84375\n",
      "now loss =  0.10374851361062185  accuracy =  0.84375\n",
      "now loss =  0.07677561416547826  accuracy =  0.921875\n",
      "now loss =  0.08562331020123001  accuracy =  0.890625\n",
      "now loss =  0.08744958074162223  accuracy =  0.90625\n",
      "now loss =  0.07468312087552895  accuracy =  0.90625\n",
      "now loss =  0.09279869581788831  accuracy =  0.84375\n",
      "now loss =  0.07524908162584608  accuracy =  0.921875\n",
      "now loss =  0.08170354636508106  accuracy =  0.890625\n",
      "now loss =  0.08603549903119112  accuracy =  0.890625\n",
      "now loss =  0.09709867179221929  accuracy =  0.875\n",
      "now loss =  0.08595816453714061  accuracy =  0.890625\n",
      "now loss =  0.08385119465873432  accuracy =  0.859375\n",
      "now loss =  0.10257066088171195  accuracy =  0.828125\n",
      "now loss =  0.10195866260541546  accuracy =  0.85\n",
      "now loss =  0.07505066208800579  accuracy =  0.9375\n",
      "now loss =  0.08106739144609505  accuracy =  0.875\n",
      "now loss =  0.11179363371979636  accuracy =  0.859375\n",
      "now loss =  0.09095092648629971  accuracy =  0.90625\n",
      "now loss =  0.0990728303199989  accuracy =  0.875\n",
      "now loss =  0.06018792700326307  accuracy =  0.9375\n",
      "now loss =  0.07730089106069288  accuracy =  0.890625\n",
      "now loss =  0.10285888506544892  accuracy =  0.859375\n",
      "now loss =  0.1059898453968762  accuracy =  0.828125\n",
      "now loss =  0.07959820961017894  accuracy =  0.90625\n",
      "now loss =  0.08347972354056835  accuracy =  0.875\n",
      "now loss =  0.12678008844662106  accuracy =  0.78125\n",
      "now loss =  0.055337314166781414  accuracy =  0.953125\n",
      "now loss =  0.08721139058927975  accuracy =  0.890625\n",
      "now loss =  0.06836810880866973  accuracy =  0.9375\n",
      "now loss =  0.07969476883975811  accuracy =  0.925\n",
      "now loss =  0.0782175589575455  accuracy =  0.921875\n",
      "now loss =  0.08886563528978791  accuracy =  0.875\n",
      "now loss =  0.07045606671870533  accuracy =  0.921875\n",
      "now loss =  0.0847101031796383  accuracy =  0.875\n",
      "now loss =  0.08732268746955722  accuracy =  0.875\n",
      "now loss =  0.06983187349916391  accuracy =  0.90625\n",
      "now loss =  0.07523056735965253  accuracy =  0.890625\n",
      "now loss =  0.11608263006733119  accuracy =  0.828125\n",
      "now loss =  0.08660066715780605  accuracy =  0.84375\n",
      "now loss =  0.08307389724473778  accuracy =  0.90625\n",
      "now loss =  0.10599481132608987  accuracy =  0.828125\n",
      "now loss =  0.08701895990621246  accuracy =  0.875\n",
      "now loss =  0.10391179431269536  accuracy =  0.84375\n",
      "now loss =  0.09534767613690273  accuracy =  0.875\n",
      "now loss =  0.07446148529370672  accuracy =  0.90625\n",
      "now loss =  0.0669988629690597  accuracy =  0.95\n",
      "now loss =  0.06331955848047394  accuracy =  0.9375\n",
      "now loss =  0.07231040997758659  accuracy =  0.890625\n",
      "now loss =  0.08042314119116079  accuracy =  0.890625\n",
      "now loss =  0.09866311254373424  accuracy =  0.859375\n",
      "now loss =  0.07811845861157453  accuracy =  0.90625\n",
      "now loss =  0.10350335829240893  accuracy =  0.84375\n",
      "now loss =  0.08848337209144458  accuracy =  0.828125\n",
      "now loss =  0.125082170318647  accuracy =  0.859375\n",
      "now loss =  0.08697753396325814  accuracy =  0.875\n",
      "now loss =  0.09205675417106957  accuracy =  0.875\n",
      "now loss =  0.067287730924655  accuracy =  0.90625\n",
      "now loss =  0.11142158291601822  accuracy =  0.828125\n",
      "now loss =  0.08427978977214984  accuracy =  0.9375\n",
      "now loss =  0.07068066944334467  accuracy =  0.921875\n",
      "now loss =  0.06886534300367975  accuracy =  0.90625\n",
      "now loss =  0.08786309406991077  accuracy =  0.9\n",
      "now loss =  0.06736853312306451  accuracy =  0.921875\n",
      "now loss =  0.08423224074022392  accuracy =  0.84375\n",
      "now loss =  0.08114058036475597  accuracy =  0.90625\n",
      "now loss =  0.08081638662503178  accuracy =  0.90625\n",
      "now loss =  0.08760276187161326  accuracy =  0.859375\n",
      "now loss =  0.10244528002928564  accuracy =  0.875\n",
      "now loss =  0.09550595689685681  accuracy =  0.875\n",
      "now loss =  0.063329167720248  accuracy =  0.90625\n",
      "now loss =  0.09394219891850245  accuracy =  0.859375\n",
      "now loss =  0.0838435133849597  accuracy =  0.90625\n",
      "now loss =  0.09891099080781643  accuracy =  0.859375\n",
      "now loss =  0.0803656476922443  accuracy =  0.90625\n",
      "now loss =  0.08012541496521747  accuracy =  0.90625\n",
      "now loss =  0.1238328401421297  accuracy =  0.8125\n",
      "now loss =  0.08204564889534792  accuracy =  0.859375\n",
      "now loss =  0.05752109838585584  accuracy =  0.95\n",
      "now loss =  0.10591007002797934  accuracy =  0.859375\n",
      "now loss =  0.07510798508842814  accuracy =  0.90625\n",
      "now loss =  0.08669146575149846  accuracy =  0.921875\n",
      "now loss =  0.06990505447740013  accuracy =  0.90625\n",
      "now loss =  0.10063610257130678  accuracy =  0.828125\n",
      "now loss =  0.09845190788689104  accuracy =  0.828125\n",
      "now loss =  0.06825219542263253  accuracy =  0.890625\n",
      "now loss =  0.08889329239577212  accuracy =  0.859375\n",
      "now loss =  0.09188834829339249  accuracy =  0.859375\n",
      "now loss =  0.07059706651856595  accuracy =  0.953125\n",
      "now loss =  0.0992739405166378  accuracy =  0.84375\n",
      "now loss =  0.08328223310931335  accuracy =  0.921875\n",
      "now loss =  0.11007387926545129  accuracy =  0.828125\n",
      "now loss =  0.0859218863923605  accuracy =  0.890625\n",
      "now loss =  0.05343666904468038  accuracy =  0.953125\n",
      "now loss =  0.08856597491238412  accuracy =  0.9\n",
      "now loss =  0.09711126989629501  accuracy =  0.84375\n",
      "now loss =  0.06606254714745702  accuracy =  0.90625\n",
      "now loss =  0.1044003185319507  accuracy =  0.875\n",
      "now loss =  0.0966106909229272  accuracy =  0.875\n",
      "now loss =  0.10160428639611213  accuracy =  0.8125\n",
      "now loss =  0.10736466013042542  accuracy =  0.859375\n",
      "now loss =  0.08027861427066654  accuracy =  0.890625\n",
      "now loss =  0.1210823411862645  accuracy =  0.8125\n",
      "now loss =  0.09247592102469938  accuracy =  0.875\n",
      "now loss =  0.07111022163562469  accuracy =  0.921875\n",
      "now loss =  0.06127283333995289  accuracy =  0.953125\n",
      "now loss =  0.07486965616414229  accuracy =  0.9375\n",
      "now loss =  0.06524029341565045  accuracy =  0.90625\n",
      "now loss =  0.057313242597954596  accuracy =  0.953125\n",
      "now loss =  0.07748025506525608  accuracy =  0.90625\n",
      "now loss =  0.10118477406332993  accuracy =  0.825\n",
      "now loss =  0.06870275078076371  accuracy =  0.921875\n",
      "now loss =  0.08777174090910164  accuracy =  0.890625\n",
      "now loss =  0.1212067772737134  accuracy =  0.796875\n",
      "now loss =  0.10278548160383472  accuracy =  0.828125\n",
      "now loss =  0.07184486000723915  accuracy =  0.9375\n",
      "now loss =  0.0830842300590846  accuracy =  0.921875\n",
      "now loss =  0.08322858824171765  accuracy =  0.90625\n",
      "now loss =  0.08740358930572467  accuracy =  0.90625\n",
      "now loss =  0.08846261452272014  accuracy =  0.875\n",
      "now loss =  0.10435462534247616  accuracy =  0.828125\n",
      "now loss =  0.06584047828015199  accuracy =  0.890625\n",
      "now loss =  0.09493909796946545  accuracy =  0.84375\n",
      "now loss =  0.07104285124508085  accuracy =  0.921875\n",
      "now loss =  0.08089035786724416  accuracy =  0.890625\n",
      "now loss =  0.10442632161456855  accuracy =  0.796875\n",
      "now loss =  0.05061851490366158  accuracy =  0.975\n",
      "now loss =  0.07135359068047753  accuracy =  0.875\n",
      "now loss =  0.06608190174306186  accuracy =  0.90625\n",
      "now loss =  0.09523431026530343  accuracy =  0.84375\n",
      "now loss =  0.07985879029522322  accuracy =  0.90625\n",
      "now loss =  0.06915297395606548  accuracy =  0.921875\n",
      "now loss =  0.09914682521918823  accuracy =  0.875\n",
      "now loss =  0.08991724663952198  accuracy =  0.890625\n",
      "now loss =  0.09458112542851049  accuracy =  0.875\n",
      "now loss =  0.08231707491307999  accuracy =  0.921875\n",
      "now loss =  0.08939508329009357  accuracy =  0.859375\n",
      "now loss =  0.07582335625344534  accuracy =  0.90625\n",
      "now loss =  0.09187413872514542  accuracy =  0.859375\n",
      "now loss =  0.06915829832698842  accuracy =  0.921875\n",
      "now loss =  0.11513337923605219  accuracy =  0.828125\n",
      "now loss =  0.09032724742452045  accuracy =  0.921875\n",
      "now loss =  0.11266795350585415  accuracy =  0.85\n",
      "now loss =  0.07553906355080195  accuracy =  0.875\n",
      "now loss =  0.09662782540019653  accuracy =  0.828125\n",
      "now loss =  0.07094905057451456  accuracy =  0.921875\n",
      "now loss =  0.07215225085088872  accuracy =  0.90625\n",
      "now loss =  0.08664744267681822  accuracy =  0.90625\n",
      "now loss =  0.08119612450953292  accuracy =  0.90625\n",
      "now loss =  0.062423413780377496  accuracy =  0.9375\n",
      "now loss =  0.09715061467602154  accuracy =  0.859375\n",
      "now loss =  0.0761371724293075  accuracy =  0.90625\n",
      "now loss =  0.11595513814275825  accuracy =  0.859375\n",
      "now loss =  0.07667413037430738  accuracy =  0.890625\n",
      "now loss =  0.08951322815116541  accuracy =  0.890625\n",
      "now loss =  0.08277360649131107  accuracy =  0.890625\n",
      "now loss =  0.07245535473217626  accuracy =  0.921875\n",
      "now loss =  0.11653043041248584  accuracy =  0.84375\n",
      "now loss =  0.12120472173453183  accuracy =  0.775\n",
      "now loss =  0.13033386417533332  accuracy =  0.8125\n",
      "now loss =  0.059576455865894815  accuracy =  0.9375\n",
      "now loss =  0.062263906412978694  accuracy =  0.953125\n",
      "now loss =  0.07787368970008596  accuracy =  0.90625\n",
      "now loss =  0.10081586991644119  accuracy =  0.84375\n",
      "now loss =  0.09144682555331886  accuracy =  0.859375\n",
      "now loss =  0.0996547438157615  accuracy =  0.84375\n",
      "now loss =  0.08418554880095898  accuracy =  0.890625\n",
      "now loss =  0.09520361555704562  accuracy =  0.84375\n",
      "now loss =  0.061146421844425425  accuracy =  0.921875\n",
      "now loss =  0.09628347837282364  accuracy =  0.875\n",
      "now loss =  0.0960451038902393  accuracy =  0.875\n",
      "now loss =  0.06583998929245913  accuracy =  0.9375\n",
      "now loss =  0.08986153455076334  accuracy =  0.859375\n",
      "now loss =  0.07395823458348398  accuracy =  0.90625\n",
      "now loss =  0.0831544106372091  accuracy =  0.9\n",
      "now loss =  0.06615524899072933  accuracy =  0.9375\n",
      "now loss =  0.08414842527626942  accuracy =  0.859375\n",
      "now loss =  0.07809480296520974  accuracy =  0.90625\n",
      "now loss =  0.09291516290362142  accuracy =  0.875\n",
      "now loss =  0.09880237125246494  accuracy =  0.84375\n",
      "now loss =  0.0890431304797567  accuracy =  0.84375\n",
      "now loss =  0.10443192579667743  accuracy =  0.875\n",
      "now loss =  0.0830688977361882  accuracy =  0.875\n",
      "now loss =  0.11204013363501118  accuracy =  0.8125\n",
      "now loss =  0.08227911671372032  accuracy =  0.9375\n",
      "now loss =  0.07956557310657306  accuracy =  0.921875\n",
      "now loss =  0.06988005808712298  accuracy =  0.921875\n",
      "now loss =  0.07194785022446348  accuracy =  0.921875\n",
      "now loss =  0.08489053617476136  accuracy =  0.921875\n",
      "now loss =  0.1057954922247881  accuracy =  0.828125\n",
      "now loss =  0.06363643480170669  accuracy =  0.95\n",
      "now loss =  0.09695107988437172  accuracy =  0.828125\n",
      "now loss =  0.10024655086745926  accuracy =  0.828125\n",
      "now loss =  0.08198685484361937  accuracy =  0.90625\n",
      "now loss =  0.07027335799262038  accuracy =  0.9375\n",
      "now loss =  0.09131330104584368  accuracy =  0.84375\n",
      "now loss =  0.08978860387213743  accuracy =  0.90625\n",
      "now loss =  0.09187549224189884  accuracy =  0.875\n",
      "now loss =  0.07362968582391806  accuracy =  0.921875\n",
      "now loss =  0.09503131887726302  accuracy =  0.875\n",
      "now loss =  0.06401051757337192  accuracy =  0.90625\n",
      "now loss =  0.06690890559091649  accuracy =  0.9375\n",
      "now loss =  0.08278531709141249  accuracy =  0.90625\n",
      "now loss =  0.08202561558758972  accuracy =  0.890625\n",
      "now loss =  0.12318910031749536  accuracy =  0.8125\n",
      "now loss =  0.07743625367996779  accuracy =  0.890625\n",
      "now loss =  0.0891229992407421  accuracy =  0.875\n",
      "now loss =  0.09714516789703012  accuracy =  0.84375\n",
      "now loss =  0.09554293984295874  accuracy =  0.875\n",
      "now loss =  0.08561862756373316  accuracy =  0.90625\n",
      "now loss =  0.07959185726215676  accuracy =  0.921875\n",
      "now loss =  0.09872251471490998  accuracy =  0.859375\n",
      "now loss =  0.09182858679696781  accuracy =  0.90625\n",
      "now loss =  0.09708545323183052  accuracy =  0.84375\n",
      "now loss =  0.08037685596820739  accuracy =  0.90625\n",
      "now loss =  0.08952680316330469  accuracy =  0.859375\n",
      "now loss =  0.06839535891364155  accuracy =  0.921875\n",
      "now loss =  0.10292182171254743  accuracy =  0.828125\n",
      "now loss =  0.09628792540244685  accuracy =  0.890625\n",
      "now loss =  0.07375781509729037  accuracy =  0.921875\n",
      "now loss =  0.06858796717857926  accuracy =  0.921875\n",
      "now loss =  0.07704034639644552  accuracy =  0.90625\n",
      "now loss =  0.07714527212436798  accuracy =  0.875\n",
      "now loss =  0.09263179305829794  accuracy =  0.890625\n",
      "now loss =  0.075898411424243  accuracy =  0.90625\n",
      "now loss =  0.07425993720208046  accuracy =  0.90625\n",
      "now loss =  0.08676284321681232  accuracy =  0.875\n",
      "now loss =  0.1045790083337576  accuracy =  0.84375\n",
      "now loss =  0.08478940296854065  accuracy =  0.859375\n",
      "now loss =  0.07989863689555644  accuracy =  0.890625\n",
      "now loss =  0.08056549073590344  accuracy =  0.90625\n",
      "now loss =  0.10668985725649285  accuracy =  0.859375\n",
      "now loss =  0.06341095994011878  accuracy =  0.890625\n",
      "now loss =  0.06885600214357847  accuracy =  0.90625\n",
      "now loss =  0.07410657762625414  accuracy =  0.90625\n",
      "now loss =  0.0721632820851223  accuracy =  0.890625\n",
      "now loss =  0.10181867513571619  accuracy =  0.84375\n",
      "now loss =  0.10093336120572036  accuracy =  0.859375\n",
      "now loss =  0.10190904707197741  accuracy =  0.875\n",
      "now loss =  0.0853924183255126  accuracy =  0.875\n",
      "now loss =  0.07529966373183297  accuracy =  0.9375\n",
      "now loss =  0.07588586646365085  accuracy =  0.921875\n",
      "now loss =  0.061191135505010374  accuracy =  0.921875\n",
      "now loss =  0.112753151795273  accuracy =  0.8125\n",
      "now loss =  0.07595040298313993  accuracy =  0.9375\n",
      "now loss =  0.08609311420890081  accuracy =  0.890625\n",
      "now loss =  0.08836931257504309  accuracy =  0.84375\n",
      "now loss =  0.13154210352391388  accuracy =  0.796875\n",
      "now loss =  0.08666262175130465  accuracy =  0.875\n",
      "now loss =  0.09233910815127211  accuracy =  0.890625\n",
      "now loss =  0.08806861968986038  accuracy =  0.875\n",
      "now loss =  0.06443178943993302  accuracy =  0.953125\n",
      "now loss =  0.09022639768000607  accuracy =  0.84375\n",
      "now loss =  0.08583687258837674  accuracy =  0.875\n",
      "now loss =  0.06664632137855966  accuracy =  0.9\n",
      "now loss =  0.08198904204563882  accuracy =  0.921875\n",
      "now loss =  0.09708203697719696  accuracy =  0.859375\n",
      "now loss =  0.07955939933057618  accuracy =  0.9375\n",
      "now loss =  0.08094342525360643  accuracy =  0.890625\n",
      "now loss =  0.09075027434909474  accuracy =  0.90625\n",
      "now loss =  0.08201751511509214  accuracy =  0.875\n",
      "now loss =  0.0848681275996386  accuracy =  0.890625\n",
      "now loss =  0.06878330090119639  accuracy =  0.9375\n",
      "now loss =  0.08751672246918454  accuracy =  0.859375\n",
      "now loss =  0.07492721512139602  accuracy =  0.890625\n",
      "now loss =  0.08538318079380167  accuracy =  0.875\n",
      "now loss =  0.08408157884906096  accuracy =  0.875\n",
      "now loss =  0.11204204038331288  accuracy =  0.8125\n",
      "now loss =  0.07408574790068569  accuracy =  0.890625\n",
      "now loss =  0.08514993296032503  accuracy =  0.828125\n",
      "now loss =  0.11583189797949114  accuracy =  0.825\n",
      "now loss =  0.11781283703421934  accuracy =  0.8125\n",
      "now loss =  0.07321487891033834  accuracy =  0.953125\n",
      "now loss =  0.10318379764079075  accuracy =  0.84375\n",
      "now loss =  0.09325834713813429  accuracy =  0.890625\n",
      "now loss =  0.08878838795858526  accuracy =  0.859375\n",
      "now loss =  0.05107532131293376  accuracy =  0.9375\n",
      "now loss =  0.06674268575674903  accuracy =  0.921875\n",
      "now loss =  0.10252599969367704  accuracy =  0.8125\n",
      "now loss =  0.09179490511306983  accuracy =  0.875\n",
      "now loss =  0.09488354439434957  accuracy =  0.84375\n",
      "now loss =  0.0733491197745439  accuracy =  0.90625\n",
      "now loss =  0.0888129303407827  accuracy =  0.890625\n",
      "now loss =  0.06411224778289946  accuracy =  0.9375\n",
      "now loss =  0.09014268910050854  accuracy =  0.875\n",
      "now loss =  0.0886252915116999  accuracy =  0.90625\n",
      "now loss =  0.07944107498497904  accuracy =  0.9\n",
      "now loss =  0.07301445694602085  accuracy =  0.921875\n",
      "now loss =  0.10041646800748119  accuracy =  0.859375\n",
      "now loss =  0.10634753228858915  accuracy =  0.828125\n",
      "now loss =  0.07810773854346223  accuracy =  0.890625\n",
      "now loss =  0.06362076555366492  accuracy =  0.921875\n",
      "now loss =  0.07115271034116989  accuracy =  0.921875\n",
      "now loss =  0.09597606458043356  accuracy =  0.890625\n",
      "now loss =  0.06983696465346519  accuracy =  0.921875\n",
      "now loss =  0.10028063868569434  accuracy =  0.859375\n",
      "now loss =  0.09206896134492419  accuracy =  0.875\n",
      "now loss =  0.10727197700184668  accuracy =  0.8125\n",
      "now loss =  0.07713092572832547  accuracy =  0.890625\n",
      "now loss =  0.09606211588531469  accuracy =  0.84375\n",
      "now loss =  0.08491303215297472  accuracy =  0.921875\n",
      "now loss =  0.0806274840482714  accuracy =  0.90625\n",
      "now loss =  0.07432339753482146  accuracy =  0.9\n",
      "now loss =  0.0699461051000799  accuracy =  0.953125\n",
      "now loss =  0.07003657423448159  accuracy =  0.953125\n",
      "now loss =  0.07356407279009677  accuracy =  0.9375\n",
      "now loss =  0.08190601410575743  accuracy =  0.921875\n",
      "now loss =  0.07829848179200365  accuracy =  0.875\n",
      "now loss =  0.10363751560894043  accuracy =  0.828125\n",
      "now loss =  0.06901849058472645  accuracy =  0.875\n",
      "now loss =  0.11690568034570367  accuracy =  0.828125\n",
      "now loss =  0.08167584619251675  accuracy =  0.84375\n",
      "now loss =  0.09064902446067652  accuracy =  0.859375\n",
      "now loss =  0.06008677304577051  accuracy =  0.90625\n",
      "now loss =  0.08340929664945962  accuracy =  0.890625\n",
      "now loss =  0.09754899540899567  accuracy =  0.859375\n",
      "now loss =  0.10824103627392417  accuracy =  0.84375\n",
      "now loss =  0.09144653765501443  accuracy =  0.875\n",
      "now loss =  0.10250386055463385  accuracy =  0.875\n",
      "now loss =  0.07420216985841727  accuracy =  0.9375\n",
      "now loss =  0.09230145782693158  accuracy =  0.90625\n",
      "now loss =  0.04850001928996023  accuracy =  0.953125\n",
      "now loss =  0.08705546999359935  accuracy =  0.890625\n",
      "now loss =  0.07986037130995614  accuracy =  0.921875\n",
      "now loss =  0.0909256294561893  accuracy =  0.875\n",
      "now loss =  0.07055208232381302  accuracy =  0.921875\n",
      "now loss =  0.07613282753133058  accuracy =  0.875\n",
      "now loss =  0.11300828033201803  accuracy =  0.828125\n",
      "now loss =  0.0600405432392344  accuracy =  0.921875\n",
      "now loss =  0.09404526937627684  accuracy =  0.890625\n",
      "now loss =  0.12506873269447522  accuracy =  0.75\n",
      "now loss =  0.0663727376215075  accuracy =  0.953125\n",
      "now loss =  0.0928465242352712  accuracy =  0.859375\n",
      "now loss =  0.10580750531471647  accuracy =  0.78125\n",
      "now loss =  0.10099208806977142  accuracy =  0.875\n",
      "now loss =  0.0962271837791058  accuracy =  0.8125\n",
      "now loss =  0.10675983790544549  accuracy =  0.84375\n",
      "now loss =  0.057650453157084  accuracy =  0.9375\n",
      "now loss =  0.064218505419305  accuracy =  0.953125\n",
      "now loss =  0.07839204080784207  accuracy =  0.890625\n",
      "now loss =  0.08491895386007964  accuracy =  0.890625\n",
      "now loss =  0.10422159595407171  accuracy =  0.859375\n",
      "now loss =  0.0939069474106348  accuracy =  0.875\n",
      "now loss =  0.08638236890271851  accuracy =  0.875\n",
      "now loss =  0.09801766221095476  accuracy =  0.84375\n",
      "now loss =  0.10029280456189188  accuracy =  0.8125\n",
      "now loss =  0.04937807661058555  accuracy =  0.96875\n",
      "now loss =  0.0976811074374431  accuracy =  0.84375\n",
      "now loss =  0.0909609405458081  accuracy =  0.921875\n",
      "now loss =  0.07722788030684585  accuracy =  0.921875\n",
      "now loss =  0.08590402295687506  accuracy =  0.85\n",
      "now loss =  0.08739005165975013  accuracy =  0.84375\n",
      "now loss =  0.08299647392219582  accuracy =  0.859375\n",
      "now loss =  0.10534517296734827  accuracy =  0.859375\n",
      "now loss =  0.09345166665392024  accuracy =  0.875\n",
      "now loss =  0.06865556229400122  accuracy =  0.953125\n",
      "now loss =  0.07353745381758339  accuracy =  0.921875\n",
      "now loss =  0.07712345241439175  accuracy =  0.921875\n",
      "now loss =  0.08513763605811295  accuracy =  0.890625\n",
      "now loss =  0.07741983408343889  accuracy =  0.90625\n",
      "now loss =  0.09116857142329252  accuracy =  0.875\n",
      "now loss =  0.07475194898545169  accuracy =  0.921875\n",
      "now loss =  0.06885284964973667  accuracy =  0.90625\n",
      "now loss =  0.09577373114474853  accuracy =  0.890625\n",
      "now loss =  0.08535766087007007  accuracy =  0.890625\n",
      "now loss =  0.10973776080110113  accuracy =  0.8125\n",
      "now loss =  0.09570082221532442  accuracy =  0.9\n",
      "now loss =  0.07811683304227897  accuracy =  0.921875\n",
      "now loss =  0.07376333514272065  accuracy =  0.921875\n",
      "now loss =  0.12562685419686181  accuracy =  0.8125\n",
      "now loss =  0.06151945440397993  accuracy =  0.9375\n",
      "now loss =  0.07474618225946508  accuracy =  0.875\n",
      "now loss =  0.09933512962106297  accuracy =  0.84375\n",
      "now loss =  0.11315673464883794  accuracy =  0.828125\n",
      "now loss =  0.06839558067939067  accuracy =  0.921875\n",
      "now loss =  0.09058819244886446  accuracy =  0.90625\n",
      "now loss =  0.10554828969313115  accuracy =  0.84375\n",
      "now loss =  0.08229848949354464  accuracy =  0.890625\n",
      "now loss =  0.08153911792022059  accuracy =  0.890625\n",
      "now loss =  0.07227726091550019  accuracy =  0.90625\n",
      "now loss =  0.09023270953024906  accuracy =  0.890625\n",
      "now loss =  0.06957113475556778  accuracy =  0.890625\n",
      "now loss =  0.09886810559069278  accuracy =  0.9\n",
      "now loss =  0.07853296804031251  accuracy =  0.90625\n",
      "now loss =  0.0877366647072807  accuracy =  0.921875\n",
      "now loss =  0.10887709718129665  accuracy =  0.84375\n",
      "now loss =  0.07700476017130939  accuracy =  0.90625\n",
      "now loss =  0.08422005308198982  accuracy =  0.890625\n",
      "now loss =  0.1003119300260239  accuracy =  0.828125\n",
      "now loss =  0.06223821815131995  accuracy =  0.9375\n",
      "now loss =  0.09630701613559194  accuracy =  0.875\n",
      "now loss =  0.1052887855810567  accuracy =  0.859375\n",
      "now loss =  0.0727740187916949  accuracy =  0.921875\n",
      "now loss =  0.07100613148280797  accuracy =  0.890625\n",
      "now loss =  0.10394598416852016  accuracy =  0.875\n",
      "now loss =  0.07956130140524952  accuracy =  0.890625\n",
      "now loss =  0.09037353631270148  accuracy =  0.859375\n",
      "now loss =  0.09030614858626679  accuracy =  0.859375\n",
      "now loss =  0.05366302908157068  accuracy =  0.975\n",
      "now loss =  0.06899956844848484  accuracy =  0.9375\n",
      "now loss =  0.09760500768616556  accuracy =  0.859375\n",
      "now loss =  0.07083727038454568  accuracy =  0.9375\n",
      "now loss =  0.08190044534072219  accuracy =  0.90625\n",
      "now loss =  0.07662153012887084  accuracy =  0.875\n",
      "now loss =  0.06719194495270746  accuracy =  0.90625\n",
      "now loss =  0.08964465800670644  accuracy =  0.84375\n",
      "now loss =  0.1013147922507027  accuracy =  0.875\n",
      "now loss =  0.08302296803295203  accuracy =  0.875\n",
      "now loss =  0.08439498636772741  accuracy =  0.875\n",
      "now loss =  0.06261016304179776  accuracy =  0.9375\n",
      "now loss =  0.08971430124460822  accuracy =  0.875\n",
      "now loss =  0.08806426915586932  accuracy =  0.859375\n",
      "now loss =  0.10468901337449965  accuracy =  0.828125\n",
      "now loss =  0.09630564961005234  accuracy =  0.859375\n",
      "now loss =  0.11937942244461415  accuracy =  0.85\n",
      "now loss =  0.08929153635081843  accuracy =  0.859375\n",
      "now loss =  0.08617986896001187  accuracy =  0.859375\n",
      "now loss =  0.11143289652156989  accuracy =  0.796875\n",
      "now loss =  0.10566560011795842  accuracy =  0.828125\n",
      "now loss =  0.08895182776090757  accuracy =  0.859375\n",
      "now loss =  0.06582306369996323  accuracy =  0.953125\n",
      "now loss =  0.07510670139177666  accuracy =  0.890625\n",
      "now loss =  0.09547794162066399  accuracy =  0.859375\n",
      "now loss =  0.08908694901508  accuracy =  0.875\n",
      "now loss =  0.11189869581237874  accuracy =  0.8125\n",
      "now loss =  0.05788250174171439  accuracy =  0.9375\n",
      "now loss =  0.07784677790643847  accuracy =  0.90625\n",
      "now loss =  0.07030204552822578  accuracy =  0.9375\n",
      "now loss =  0.08343831239164543  accuracy =  0.90625\n",
      "now loss =  0.06880721587408634  accuracy =  0.953125\n",
      "now loss =  0.09871770076218037  accuracy =  0.875\n",
      "now loss =  0.08856029739951485  accuracy =  0.859375\n",
      "now loss =  0.0735382277951287  accuracy =  0.890625\n",
      "now loss =  0.11531866706425183  accuracy =  0.84375\n",
      "now loss =  0.06648287226911725  accuracy =  0.953125\n",
      "now loss =  0.07870677617702329  accuracy =  0.890625\n",
      "now loss =  0.0715456653562995  accuracy =  0.9375\n",
      "now loss =  0.05764748040116751  accuracy =  0.9375\n",
      "now loss =  0.06185230238867216  accuracy =  0.953125\n",
      "now loss =  0.09363755175009421  accuracy =  0.859375\n",
      "now loss =  0.0819221845262005  accuracy =  0.90625\n",
      "now loss =  0.11487380633364896  accuracy =  0.8125\n",
      "now loss =  0.08224436595405821  accuracy =  0.890625\n",
      "now loss =  0.08849983268245612  accuracy =  0.84375\n",
      "now loss =  0.12629546734664882  accuracy =  0.765625\n",
      "now loss =  0.08552889588305185  accuracy =  0.9375\n",
      "now loss =  0.07958242171962722  accuracy =  0.875\n",
      "now loss =  0.07604802062598959  accuracy =  0.90625\n",
      "now loss =  0.0850573172196242  accuracy =  0.90625\n",
      "now loss =  0.11087209527518747  accuracy =  0.84375\n",
      "now loss =  0.11517500326184742  accuracy =  0.78125\n",
      "now loss =  0.050539089174123086  accuracy =  0.9375\n",
      "now loss =  0.1054745648932912  accuracy =  0.84375\n",
      "now loss =  0.09253726454949654  accuracy =  0.875\n",
      "now loss =  0.0759032510764827  accuracy =  0.890625\n",
      "now loss =  0.07831548602024212  accuracy =  0.90625\n",
      "now loss =  0.07571447389929639  accuracy =  0.890625\n",
      "now loss =  0.0746468546246753  accuracy =  0.921875\n",
      "now loss =  0.07652792329581481  accuracy =  0.9375\n",
      "now loss =  0.09001488427767954  accuracy =  0.875\n",
      "now loss =  0.09783383691147449  accuracy =  0.859375\n",
      "now loss =  0.09427536232341793  accuracy =  0.859375\n",
      "now loss =  0.07017098672213644  accuracy =  0.925\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 500x500 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from layers.affine import Affine\n",
    "from layers.model import Model\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.datasets import make_moons, make_blobs\n",
    "X, y = make_moons(n_samples=1000, noise=0.1)\n",
    "\n",
    "# visualize in 2D\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(X[:,0], X[:,1], c=y, s=20, cmap='jet')\n",
    "\n",
    "nn = Model(layers=[Affine(5), Affine(1)])\n",
    "\n",
    "targets = np.reshape(y, (y.shape[0], 1))\n",
    "nn.fit(X, targets, n_epochs=500)\n",
    "\n",
    "\n",
    "# Create a mesh grid for plotting decision boundary\n",
    "h = 0.02\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# Predict class for each point in the grid\n",
    "Z = nn.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "# Predict on the original data\n",
    "y_pred = nn.predict(X)\n",
    "# Threshold predictions to get binary labels\n",
    "y_pred_labels = (y_pred > 0.5).astype(int).flatten()\n",
    "\n",
    "# Find misclassified points\n",
    "misclassified = y_pred_labels != y\n",
    "\n",
    "# Plot the decision boundary\n",
    "plt.contourf(xx, yy, Z, alpha=0.8)\n",
    "# Plot correctly classified points\n",
    "plt.scatter(X[~misclassified, 0], X[~misclassified, 1], c=y[~misclassified], s=40, cmap=plt.cm.Spectral)\n",
    "# Highlight misclassified points\n",
    "plt.scatter(X[misclassified, 0], X[misclassified, 1], facecolors='none', edgecolors='r', s=80, marker='o')\n",
    "\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('Decision Boundary and Misclassified Points')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
